[00:01]
so let me ask you've kind of alluded to
it but let me ask again what is
intelligence underlying the discussion
we'll have with with jeopardy and beyond
how do you think about intelligence is

[00:15]
how do you think about intelligence is
it a sufficiently complicated problem
being able to reason your way through
solving that problem is that kind of how
you think about what it means to be
intelligent so I think of intelligence
to primarily two ways one is the ability
to predict so in other words if I have a

[00:32]
to predict so in other words if I have a
problem what's gonna can I predict
what's going to happen next whether it's
to you know predict the answer of a
question or to say look I'm looking at
all the market dynamics and I'm going to
tell you what's going to happen next or
you're in a in a room and somebody walks

[00:47]
you're in a in a room and somebody walks
in and you're going to predict what
they're going to do next or what they're
going to say next
doing that in a highly dynamic
environment full of uncertainty be able
to lots of large you know the more the
more variables the more complex the more
possibilities the more complex but can I

[01:02]
possibilities the more complex but can I
take a small amount of prior data and
learn the pattern and then predict
what's going to happen next accurately
and consistently that's a that's
certainly a form of intelligence what do

[01:15]
certainly a form of intelligence what do
you need for that by the way you need to
have an understanding of the way the
world works in order to be able to
unroll it into the future all right
thank you what thing is needed to
predict depends what you mean by
understanding I I need to be able to
find that function this is very much

[01:31]
find that function this is very much
like what function deep learning does
machine learning does is if you give me
enough prior data and you tell me what
the output variable is that matters I'm
going to sit there and be able to
predict it and if I can predict you
predict it accurately so that I can get

[01:46]
predict it accurately so that I can get
it right more often than not I'm smart
if I do that with less data and less
training time I'm even smarter
if I can figure out what's even worth
predicting I'm smarter meaning I'm

[02:00]
predicting I'm smarter meaning I'm
figuring out what path is gonna get me
toward a goal
what about picking a goal sized again
well that's interesting about picking
our goal sort of an interesting thing
and I think that's where you bring in
what do you pre-programmed to do we talk
about humans and humans a pre-programmed

[02:16]
about humans and humans a pre-programmed
to survive so sort of their primary you
know driving goal what do they have to
do to do that and that that could be
very complex right so it's not just it's
not just figuring out that you need to
run away from the ferocious tiger but we

[02:33]
run away from the ferocious tiger but we
survive in social context as an example
so understanding the subtleties of
social dynamics becomes something that's
important for surviving finding a mate
reproducing right so we're continually

[02:46]
reproducing right so we're continually
challenged with complex sets of
variables complex constraints rules if
you will that we we or patterns and we
learn how to find the functions and
predict the things the Lords represent
those patterns efficiently and be able

[03:02]
those patterns efficiently and be able
to predict what's going to happen in
that's a form of intelligence that
doesn't really really require anything
specific other than identity to find
that function and and predict that right
answer it's certainly a form of
intelligence but then when we when we

[03:17]
intelligence but then when we when we
say well do we understand each other in
other words do would you perceive me as
as intelligent beyond that ability to
predict so now I can predict but I can't

[03:31]
predict so now I can predict but I can't
really articulate how I'm going to that
process what my underlying theory is for
predicting and I can't get you to
understand what I'm doing so that you
can follow you can figure out how to do
this yourself if you hadn't if you did

[03:48]
this yourself if you hadn't if you did
not have for example the right pattern
matching machinery that I did and now we
have potentially have this breakdown or
in effect unintelligent but I'm sort of
an alien intelligence relative to to you

[04:00]
an alien intelligence relative to to you
you're intelligent but nobody knows
about it or died so I can see the eye I
can see the output knowing so so you're
saying said let's
to separate the two things one is you
explaining why you were able to predict
the future and and the second is me

[04:19]
the future and and the second is me
being able to like impressing me that
you're intelligent me being able to know
that you successfully predicted the
future do you think that's well it's not
a pressing you item intelligent in other
words you may be convinced that I'm

[04:32]
words you may be convinced that I'm
intelligent in some form so high because
of my ability to predict so I wouldn't
you met Hannah sister Wow Wow you're
right all here you're you're right more
times than I am you're doing something
interesting that's a form that's a form

[04:45]
interesting that's a form that's a form
of intelligence but then what happens is
if I say how are you doing that and you
can't communicate with me and you can't
describe that to me now I'm a label you
a savant I mean I may say well you're

[05:00]
a savant I mean I may say well you're
doing something weird and it's and it's
just not very interesting to me because
you and I can't really communicate and
and so now this is interesting right
because now this is you're in this weird
place where for you to be recognized as

[05:16]
place where for you to be recognized as
intelligent the way I'm intelligent then
you and I sort of have to be able to
communicate and then my we start to
understand each other and then my
respect and my my appreciation my

[05:31]
respect and my my appreciation my
ability to relate to you starts to
change so now you're not an alien
intelligence anymore yours you're our
human intelligence now because you and I
can communicate and so I think when we
look at when we look at when we look at

[05:45]
look at when we look at when we look at
animals for example animals can do
things we can't quite comprehend we
don't quite know how they do them but
they can't really communicate with us
they can't put what they're going
through in our terms and so we think of
them as sort of low they're these alien
intelligences and they're not really

[06:00]
intelligences and they're not really
worthless so what we're worth we don't
treat them the same way as a result of
that but it's it's hard because who
knows what you know what's going on so
just a quick elaboration on that the
explaining that you're intelligent the

[06:17]
explaining that you're intelligent the
explaining the the reasoning the one end
to the prediction
is not some kind of mathematical proof
if we look at humans look at political
debates and discourse on Twitter it's

[06:30]
debates and discourse on Twitter it's
mostly just telling stories so you
usually your task is sorry that your
task is not to tell an accurate
depiction of how you reason but to tell
a story real or not that convinces me

[06:47]
a story real or not that convinces me
that there was a mechanism by which you
ultimately that's what a proof is I mean
even a mathematical proof is is that
because ultimately the other
mathematicians have to be convinced by
your proof otherwise in fact there been

[07:01]
your proof otherwise in fact there been
that of the management success yeah yeah
there have been several proofs out there
where mathematicians would study for a
long time before they were convinced
that it actually proved anything right
you never know if it proved anything
until the community of mathematicians
decided that it did so I mean so it's
but it's it's a real thing yeah and and

[07:17]
but it's it's a real thing yeah and and
that's sort of the point right is that
ultimately on you know this notion of
understanding us understanding something
there's ultimately a social concept in
other words you I have to convince
enough people that I I did this in a

[07:31]
enough people that I I did this in a
reasonable way I could did this in a way
that other people can understand and and
replicate and that it make sense to them
so we're very human children's is bound
together in that way we're bound up in

[07:45]
together in that way we're bound up in
that sense we sort of never really get
away with it and so we can consider
convince others that our thinking
process you know make sense did you
think the general question of
intelligence is then also social
constructs so if we task ask questions

[08:03]
constructs so if we task ask questions
of an artificial intelligence system is
this system intelligent the answer will
ultimately be a socially constructed I
think I think so I so I think you're
making to be a mess I'm saying we can
try to define intelligence in a super

[08:16]
try to define intelligence in a super
objective way that says here here's this
data I want to predict this type of
thing learn this function and then if
you get it right often enough we
consider you intelligent but that's more

[08:30]
consider you intelligent but that's more
than a sergeant that I think it I think
it is it doesn't mean it's
use folds could be incredibly useful it
could be solving a problem we can't
otherwise solve and can solve it more
reliably than we can but then there's
this notion of can humans take

[08:47]
this notion of can humans take
responsibility for the decision that
you're that you're making can we make
those decisions ourselves can we relate
to the process that you're going through
and now you as an agent whether you're a
machine or another human frankly are now

[09:03]
machine or another human frankly are now
obliged to make me understand how it is
that you're arriving at that answer and
allow me mean me or the obviously a
community or a judge of people to decide
whether or not whether or not that makes

[09:15]
whether or not whether or not that makes
sense and by the way that happens with
the humans as well you're sitting down
with your staff for example and you ask
for suggestions about what to do next
and someone says well I think you should
buy and I think you should buy this much
or would have or sell or whatever it is

[09:30]
or would have or sell or whatever it is
or I think you should launch the product
today or tomorrow or launch this product
versus that product whatever decision
may be and you ask why and the person so
I just have a good feeling about it and
it's not you're not very satisfied now
that person would be you know you might

[09:46]
that person would be you know you might
say well you've been right you know
before but I'm gonna put the company on
the line can you explain to me why I
should believe this and that explanation
may have nothing to do with the truth
just the you know I'm convinced the

[10:01]
just the you know I'm convinced the
wrong yes they'll be wrong she's gotta
be convincing but it's ultimately gotta
be convinced and that's why I'm saying
it's we're bound together right our
intelligences are bound together in that
sense we have to understand each other
and and if for example you're giving me

[10:16]
and and if for example you're giving me
an explanation I mean this is a very
important point right you're giving me
an explanation
and I'm and I and I and I have Ayten I'm
not good
and then I'm not good at reasoning well

[10:30]
and then I'm not good at reasoning well
and being objective and following
logical paths and consistent paths and
I'm not good at measuring and sort of
computing probabilities across those
paths what happens is collectively we're

[10:45]
paths what happens is collectively we're
not going to do we're not going to do
well
how hard is that problem the second one
so we I think will talk quite a bit
about the the first on a specific
objective metric benchmark performing

[11:01]
objective metric benchmark performing
well but being able to explain the steps
the reasoning how hard is that problem
that's I think that's very hard I mean I
think that that's um well it's hard for
humans the thing that's hard for humans

[11:18]
humans the thing that's hard for humans
as you know may not necessarily be hard
for computers and vice versa
so sorry so how hard is that problem for
computers I think it's hard for

[11:30]
computers I think it's hard for
computers and the reason why are related
to or saying that it's also hard for
humans is because I think when we step
back and we say we want to design
computers to do that one of the things
we have to recognize is we're not sure

[11:46]
we have to recognize is we're not sure
how to do it well not sure we have a
recipe for that and even if you wanted
to learn it it's not clear exactly what
data we use and what judgments we use to

[12:00]
data we use and what judgments we use to
learn that well and so what I mean by
that is if you look at the entire
enterprise of science science is
supposed to be at a bad objective reason
and reason right so we think about she
who's the most intelligent person or

[12:16]
who's the most intelligent person or
group of people in the world do we think
about the savants who can close their
eyes and give you a number we'd think
about the think tanks or the scientists
of the philosophers who kind of work
through the details and write the papers

[12:31]
through the details and write the papers
and come up with the thoughtful logical
proves and use the scientific method and
I think it's the latter and my point is
that how do you train someone to do that
and that's what I mean by it's hard how

[12:45]
and that's what I mean by it's hard how
do you what's the process of training
people to do that well that's a hard
process we didn't work as a society we
work pretty hard to get other people to
understand our thinking and to convince
them of things now we could pursue

[13:01]
them of things now we could pursue
weighed them obviously talked about this
like human flaws or weaknesses we can
persuade through persuade them through
emotional means but to but to get them
to understand and connect to and follow
a logical argument is difficult we try

[13:18]
a logical argument is difficult we try
it we do it we do it as scientists we
try to do it as journalists we know we
try to do it as you know even artists in
many forms as writers as teachers we go
through a fairly significant training

[13:30]
through a fairly significant training
process to do that and then we could ask
what why is that so hard
but it's hard and for humans it takes a
lot of work and when we step back and
say whoa step back and say well how do
we get a machine - how do we get a

[13:46]
we get a machine - how do we get a
machine to do that
it's a vexing question how would you
begin to try to solve that and maybe
just a quick pause because there's an
optimistic notion in the things you're
describing which is being able to

[14:01]
describing which is being able to
explain something through reason but if
you look at algorithms that recommend
things that we look at next
well there's Facebook Google advertising
based companies you know their goal is

[14:15]
based companies you know their goal is
to convince you to buy things based on
anything so that could be reason because
the best of advertisement is showing you
things that you really do need and
explain why you need it but it could

[14:30]
explain why you need it but it could
also be through emotional manipulation
the algorithm that describes why a
certain reason a certain decision was
was made how hard is it to do it through
emotional manipulation and why is that a

[14:48]
emotional manipulation and why is that a
good or a bad thing so you've kind of
focused on reason logic really showing
in a clear way
why something is good one is that even a

[15:02]
why something is good one is that even a
thing that us humans do and and and -
how do you think of the differences in
the reasoning aspect and the emotional
manipulation okay you know so you call
it emotional manipulation

[15:15]
it emotional manipulation
more objectively is essentially saying
you know thing you know there are
certain features of things that seem to
attract your attention I mean kind of
give you more of that stuff I mean a
patient is a bad word yeah I mean I'm
not saying it's good right or wrong is
it it works to get your attention and it

[15:31]
it it works to get your attention and it
works to get you to buy stuff and when
you think about algorithms that look at
the patterns of the you know patterns of
features that you seem to be spending
your money on and is there going to give
you something with a similar pattern so
I'm going to learn that function because
the objective is to get you to click on

[15:46]
the objective is to get you to click on
and/or get you to buy and or whatever it
is I don't know I mean that it is like
it is what it is I mean that's what the
algorithm does you can argue whether
it's good or bad it depends what your
you know what your what your goal is
I guess this seems to very useful for

[16:00]
I guess this seems to very useful for
convincing telling us no I think for
advancing humans yeah it's good because
he gives again this goes back to how
does a union you know what is the human
behavior like how does a human you know
brain respond to things I think there's

[16:15]
brain respond to things I think there's
a more optimistic view of that too which
is that if you're searching for certain
kinds of things you've already reasoned
that you need them and these these
algorithms are saying look that's up to
you the reason whether you need
something or not that's your job you

[16:32]
something or not that's your job you
know you you may you may have an
unhealthy addiction to this stuff or you
may have a reasoned and thoughtful
explanation for why it's important to
you and the algorithms are saying hey
that's like whatever like that's your

[16:45]
that's like whatever like that's your
problem all I know is you're buying
stuff like that you're interested in
stuff like that could be a bad reason
could be a good reason that's up to you
I'm gonna show you more of that stuff
and so and I and I and I think that
that's it's not good or bad it it's not

[17:00]
that's it's not good or bad it it's not
reason or not reason the algorithm is
doing what it does which is saying you
seems to be interested in this I'm going
to show you more that stuff and I think
we're seeing it's not just in buying
stuff but even in social media you're
reading this kind of stuff I'm not
judging on whether it's good or bad I'm
not reasoning at all I'm just saying I'm

[17:15]
not reasoning at all I'm just saying I'm
gonna show you other stuff with similar
features and you know and like and
that's it and I wash my hands from it
and I say that's all you know that's all
what's going on you know there is you
know people are so harsh on AI systems
so one the bar of performance is

[17:31]
so one the bar of performance is
extremely high and yet we also asked
them to in the case of social media to
help find the better angels of our
nature and help make a better society so
what do you think about the role of a

[17:45]
what do you think about the role of a
bat so that agrees you that's that's the
interesting dichotomy right because on
one hand we're sitting there and we're
sort of doing the easy part which is
finding the patterns we're not building
the systems not building a theory that

[18:00]
the systems not building a theory that
it's consumable and understandable other
humans that could being explained and
justified and and so on one hand to say
oh you know AI is doing this why isn't
doing this other thing well those other
things a lot harder and it's interesting

[18:15]
things a lot harder and it's interesting
to think about why why why it's harder
and because you're interpreting you're
interpreting the data in the context of
prior models in other words
understandings of what's important in
the world what's not important what are
all the other abstract features that

[18:30]
all the other abstract features that
drive our decision-making
what's sensible what's not sensible
what's good what's bad what's moral
what's valuable what is it where is that
stuff no one's applying the
interpretation so when I when I see you
clicking on a bunch of stuff and I look

[18:45]
clicking on a bunch of stuff and I look
at these simple features the raw
features the features that are there in
a data like what words are being used
or how long the material is more other
very superficial features what colors
are being used in the material like I

[19:00]
are being used in the material like I
don't know why you're clicking on the
stuff you're looking or if it's products
what the price what the price is or what
the categories and stuff like that and I
just feed you more of the same stuff
that's very different than kind of
getting in there and saying what does
this mean what the stuff you're reading

[19:16]
this mean what the stuff you're reading
like why are you reading it what
assumptions are you bringing to the
table are those assumptions sensible is
the miss the material make any sense
does it does it lead you to thoughtful

[19:30]
does it does it lead you to thoughtful
good conclusions again there's judgment
this interpretation judgment involved in
that process that isn't really happening
in in in the AI today that's harder
right because you have to start getting

[19:45]
right because you have to start getting
at the meaning of this of the of the
stop of the content you have to get at
how humans interpret the content
relative to their value system and
deeper thought processes so that's what
meaning means is not just some kind of

[20:03]
meaning means is not just some kind of
deep timeless semantic thing that the
statement represents but also how a
large number of people are likely to
interpret so that's again even meaning

[20:15]
interpret so that's again even meaning
is a social construct it's so you have
to try to predict how most people would
understand this kind of statement yeah
meaning is often relative but meaning
implies that the connections go beneath
the surface of the artifact so if I show

[20:30]
the surface of the artifact so if I show
you a painting it's a bunch of colors in
a canvas what does it mean to you and it
may mean different things at different
people because of their different
experiences it may mean something even
different to the artist to who painted
it as we try to get more rigorous with

[20:47]
it as we try to get more rigorous with
our communication we try to really nail
down that meaning so we go from abstract
art to precise mathematics precise
engineering drawings and things like
that we're really trying to say I want

[21:02]
that we're really trying to say I want
to narrow that that space of possible
interpretations
because the precision of the
communication ends up becoming more and
more important and so that means that I
have to specify and I think that's why

[21:17]
have to specify and I think that's why
this becomes really hard because if I'm
just showing you an artifact and you're
looking at it superficially whether it's
a bunch of words on a page or whether
it's you know brushstrokes on a canvas

[21:30]
it's you know brushstrokes on a canvas
or pixels on a photograph you can sit
there and you can interpret lots of
different ways at many many different
levels but when I want to when I want to
align our understanding of that I have
to specify a lot more stuff that's

[21:46]
to specify a lot more stuff that's
actually not in it not directly in the
artifact and I have to say well how you
were how are you interpreting this image
and that image and what about the colors
and what do they mean to you what's what
perspective are you bringing to the
table

[22:00]
table
what are your prior experiences with
those artifacts
what are your fundamental assumptions
and values what what is your ability to
kind of reason to chain together logical
implication as you're sitting there and
saying well if this is the case then I
would conclude this and if that's the

[22:15]
would conclude this and if that's the
case then I would conclude that and it
so your reasoning processes and how they
work your prior models and what they are
your values and your assumptions all
those things now come together into the
interpretation getting in sick of that

[22:30]
interpretation getting in sick of that
is hard and yet humans able to intuit
some of that without any pre because
they have the shared experience me and
we're not talking about shared to people
have any share experience me as a
society that's correct we have this

[22:45]
society that's correct we have this
shared experience and we have similar
brains so we tend to Institute in other
words part of our shared experiences are
shared local experience like we may live
in the same culture we may live in the
same society and therefore we have
similar education we have similar what

[23:01]
similar education we have similar what
we like to call prior models about the
word prior experiences and we use that
as a think of it as a wide collection of
interrelated variables and they're all
bound to similar things and so we take
that as our background and we start
interpreting things similarly but as

[23:16]
interpreting things similarly but as
humans we have it we have a lot of
shared experience we
do have similar brains similar goals
similar emotions under similar
circumstances because we're both humans
so now one of the early questions you
how is biological and you know computer

[23:32]
how is biological and you know computer
information systems fundamentally
different well one is you know one is
commence come with a lot of
pre-programmed stuff yeah a ton of
program stuff and they were able to
communicate because they have a lot of

[23:46]
communicate because they have a lot of
because they share that stuff
you