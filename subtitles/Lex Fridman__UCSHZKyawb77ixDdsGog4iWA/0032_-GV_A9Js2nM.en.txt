[00:00]
welcome to course six as $0.99
artificial general intelligence we will
explore the nature of intelligence from
as much as possible and engineering
perspective you will hear many voices my

[00:18]
perspective you will hear many voices my
voice will be that of an engineer our
mission is to engineer intelligence the
MIT motto is mind in hand what that

[00:32]
MIT motto is mind in hand what that
means is we want to explore the
fundamental science of what makes an
intelligence system the core concepts
behind our understanding of what is

[00:48]
behind our understanding of what is
intelligence but we always want to
ground it in the creation of intelligent
systems we always want to be in the now
in today in understanding how today we

[01:01]
in today in understanding how today we
can build artificial intelligence
systems that can make for a better world
that is the core for us here at MIT
first and foremost we're scientists and
engineers our goal is to engineer

[01:15]
engineers our goal is to engineer
intelligence we want to provide with
this approach a balance to them very
important but over represented view of

[01:30]
important but over represented view of
artificial general intelligence the
black box reasoning view where the idea
is once we know how to create a human
level intelligence system how will
society be impacted will robots take

[01:46]
society be impacted will robots take
over and kill everyone will we achieve a
utopia that will remove the need to do
any of the messy jobs that will make us
all extremely happy those kinds of
beautiful philosophical concepts are

[02:02]
beautiful philosophical concepts are
interesting to explore but that's not
what we're interested in doing I believe
that from an engineering perspective we
want to focus on the black box of a GI
start to build insights and intuitions

[02:16]
start to build insights and intuitions
about how we create systems that
approach human level intelligence
I believe we're very far away from
creating anything resembling human level
intelligence however the dimension of

[02:34]
intelligence however the dimension of
the metric behind the word Farr may not
be time in time perhaps through a few

[02:47]
be time in time perhaps through a few
breakthroughs maybe even one
breakthrough everything can change but
as we stand now our current methods as
we will explore from the various ideas
and approaches and the guest speakers
coming here over the next two weeks and

[03:02]
coming here over the next two weeks and
beyond our best understanding our best
intuition and insights are not yet at
the level of reaching without a major
leap and breakthrough a paradigm shift

[03:15]
leap and breakthrough a paradigm shift
towards human level intelligence so it's
not constructive to consider the impact
of artificial intelligence to consider
questions of safety and ethics
fundamental extremely important

[03:32]
fundamental extremely important
questions we it's not constructive to
consider those questions without also
deeply considering the black box of the
actual methods of artificial
intelligence human level artificial

[03:45]
intelligence human level artificial
intelligence and that's what I see what
I hope this course can be its first
iteration its first exploratory attempt
to try to look at different approaches
of how we can engineer intelligence

[04:01]
of how we can engineer intelligence
that's the role of MIT it's tradition of
mine in hand it's to consider the big
picture the future impact of society 10
20 30 40 years out but fundamentally
grounded in what kind of methods do we

[04:16]
grounded in what kind of methods do we
have today and what are their
limitations and possibilities of
achieving that the black box of a GI
in the future impact on society of

[04:30]
in the future impact on society of
creating artificial intelligence systems
that get become increasingly more
intelligent the fundamental disagreement
lies in the fact the the very core of
that black box which is how hard is it

[04:45]
that black box which is how hard is it
to build an AGI system how hard is it to
create a human level artificial
intelligence system that's the open
question for all of us from from Josh
Tenenbaum to Andrey Carpathia to folks

[05:01]
Tenenbaum to Andrey Carpathia to folks
from open AI to Boston Dynamics to the
brilliant leaders in various fields of
artificial intelligence that will come
here that's the open question how hard
is it there's been a lot of incredibly
impressive results in deep learning in

[05:16]
impressive results in deep learning in
neuroscience and computational cognitive
science in robotics but how far are we
still to go to the AGI that's the
fundamental question that we need to

[05:30]
fundamental question that we need to
explore before we consider the questions
the future impact on society and the
goal for this class is to build
intuition one talk at a time a project
at a time build intuition about where we

[05:48]
at a time build intuition about where we
stand about what the limitations of
current approaches are how can we close
the gap a nice meme that I caught on
Twitter recently of the difference

[06:02]
Twitter recently of the difference
between the engineering approach at the
very simplest of a Google intern typing
a for loop that just does a grid search
on parameters for a neural network and
on the right is the way media would

[06:16]
on the right is the way media would
report this for loop the Google AI
created its own baby AI I think it's
easy for us to go one way or the other

[06:31]
easy for us to go one way or the other
but we'd like to do both our first goal
is to avoid the pitfalls of black box
thinking of the few
tourism thinking that results in hype
that's detached from scientific
engineering understanding of what the

[06:45]
engineering understanding of what the
actual systems are doing that's what the
media often reports that's what some of
our speakers will explore in a rigorous
way it's still an important topic to
explore Ray Kurzweil's on Wednesday

[07:01]
explore Ray Kurzweil's on Wednesday
we'll look we'll explore this topic next
week talking about AI safety and
autonomous weapon systems we'll explore
this topic the future impact 10 20 years
out how do we design systems today that
would lead to safe systems tomorrow

[07:16]
would lead to safe systems tomorrow
still very important but the reality is
a lot of us need to put a lot more
emphasis on the left on the four loops
on creating these systems at the same
time the second goal of what we're
trying to do here is not emphasize the

[07:32]
trying to do here is not emphasize the
silliness the simplicity the naive basic
nature of this for loop in the same way
as was the process in creating nuclear
weapons before during World War two

[07:47]
weapons before during World War two
the idea that as an engineer as a
scientist that I'm just the scientist is
also a flawed way of thinking we have to
consider the big picture impact the
near-term negative consequences that are

[08:01]
near-term negative consequences that are
preventable the low-hanging fruit that
can be prevented through that very
engineering process we have to do both
and in this engineering approach we

[08:15]
and in this engineering approach we
always have to be cautious that just
because we don't understand
we're just because we our intuition our
best understanding of the capabilities
of modern systems that learn that act in

[08:30]
of modern systems that learn that act in
this world seem limited seem far from
human level intelligence our ability to
learn and represent common sense
reasoning seems limited the exponential
potentially Exponential's could be
argued and he will growth of technology

[08:47]
argued and he will growth of technology
of these ideas means that just around
the corner is a singularity
is a breakthrough idea that will change
everything we have to be cautious of
that moreover we have to be cautious of

[09:02]
that moreover we have to be cautious of
the fact that every decade over the past
century our adoption of new technologies
has gotten faster and faster the the
rate at which a new technology from its

[09:15]
rate at which a new technology from its
birth to its wide mass adoption has
shortened and shortened and shortened
that means that new idea the moment it
drops into the world can have widespread

[09:30]
drops into the world can have widespread
effects overnight so as and I think the
in the engineering approach is
fundamentally cynical on artificial
general intelligence because every
aspect of its is so difficult we have to
always remember that overnight
everything can change through this

[09:48]
everything can change through this
question of beginning to approach from a
deep learning perspective deep
reinforcement learning from brain
simulation computational cognitive
science from computational neuroscience

[10:00]
science from computational neuroscience
from cognitive architectures from
robotics from legal perspectives and
autonomous weapon systems as we begin to
approach these questions we need to
start to build intuition how far away

[10:15]
start to build intuition how far away
are we from creating intelligent systems
the singularity here is that spark that
moment when we're truly surprised by the
intelligence of the systems we create
I'd like to visualize it by the by a

[10:34]
I'd like to visualize it by the by a
certain analogy that we're in this dark
room looking for a light switch with no
knowledge of where the light switch is
there's going to be people that say well

[10:45]
there's going to be people that say well
it's a smaller the rooms are all smaller
right there and say anywhere we'll be
able to find it in any time the reality
is we know very little so we have to
stumble around feel our way around to
build the intuition a far far away we
really are

[11:04]
many will speakers here will talk about
how we define intelligence how we can
begin to see intelligence what are the
fundamental impacts of creating
intelligence systems I'd like to sort of

[11:16]
intelligence systems I'd like to sort of
see the positive reason for this little
class and for these efforts that have
fascinated people throughout the century
of trying to create intelligent systems
is that there's something about human

[11:32]
is that there's something about human
beings that one that craves to explore
to uncover the mysteries of the universe
fundamental in itself a desire to

[11:45]
fundamental in itself a desire to
uncover the mysteries of the universe
not for a purpose and there's often an
underlying purpose of money of greed of
the power craving for power and so on
but there's seems to be an underlying
desire to explore nice little book an

[12:03]
desire to explore nice little book an
exploration a very short introduction by
Stewart Weaver he says for all the
different forms it takes in different
historical periods for all the worthy
and unworthy motives that lie behind it

[12:17]
and unworthy motives that lie behind it
exploration travel for the sake of
discovery and adventure is a human
compulsion a human obsession even it is
defining element of a distinctly human
identity and it will never rest at any

[12:32]
identity and it will never rest at any
frontier whether terrestrial or
extraterrestrial from 325 BCE with a
long 7500 mile journey on the ocean to

[12:48]
long 7500 mile journey on the ocean to
explore the Arctic to Christopher
Columbus and his flawed harshly
criticized the modern scholarship trip
that ultimately paved the way didn't

[13:00]
that ultimately paved the way didn't
discover pave the way to colonization of
the Americas to the DAR
trip the voyage of the Beagle whilst
this planet has gone cycling on

[13:15]
this planet has gone cycling on
according to the fixed law of gravity
from so simple a beginning endless forms
most beautiful and most wonderful have
been and are being evolved to the first
venture into space by Yuri Gagarin first

[13:36]
venture into space by Yuri Gagarin first
human in space in 1961 what he said over
the radio is the earth is blue it is
amazing this these are the words they

[13:47]
amazing this these are the words they
think drive our exploration in the
sciences in engineering and today an AI
and the first walk on the moon and now

[14:00]
and the first walk on the moon and now
the desire to colonize Mars and beyond
that's where I see this desire to create
intelligent systems talking about the

[14:17]
intelligent systems talking about the
positive or negative impact of AI on
society talking about the business case
of the jobs lost jobs gain jobs created
diseases cured the autonomous vehicles

[14:30]
diseases cured the autonomous vehicles
the ethical questions the safety of
autonomous weapons of the misuse of AI
in the financial markets underneath it
all and they're people many people are
spoken about this what drives myself and
many in the community is the desire to

[14:45]
many in the community is the desire to
explore to uncover the mystery of the
universe and I hope that you join me in
that very effort with the speakers that
come here in the next two weeks and
beyond the website for the course is a
GI that MIT died edu I am a part of an

[15:04]
GI that MIT died edu I am a part of an
amazing team many of whom you know AGI
at MIT that edu is the email where on
slack deep - MIT does slack for

[15:19]
slack deep - MIT does slack for
registered MIT students
you create account on the website and
submit five new links and vote on ten to
vote AI which is an aggregator of

[15:30]
vote AI which is an aggregator of
information a material we've put
together for the topic of AGI and submit
a entry to one of the competitions one
of the three competitions projects that
we have in this course and the projects

[15:46]
we have in this course and the projects
are dream vision I'll go over them in a
little bit dream vision angel ethical
car and the aggregator of material vote
AI we have guest speakers incredible
guest speakers I will go over them today
and as before with a deep learning for

[16:04]
and as before with a deep learning for
self-driving cars course we have shirts
and they're free for in-person for
people that attend in person for the
last lecture most likely or you can
order them online

[16:17]
order them online
okay dream vision we take the Google G
dream idea we explore the idea of
creativity where it is I ins view of
intelligence the mark of intelligence is

[16:30]
intelligence the mark of intelligence is
creativity this this idea is something
we explore by using neural networks and
interesting ways to visualize what the
networks see and in so doing create
beautiful visualizations in time through

[16:46]
beautiful visualizations in time through
video so taking the ideas of deep dream
and combining them together with
multiple video streams to mix dream and
reality and the competition is through

[17:01]
reality and the competition is through
Mechanical Turk we set up a competition
of who produces the most beautiful
visualization will provide code to
generate this visualization and ideas of
how you can make it more and more

[17:15]
how you can make it more and more
beautiful and how to submit it to the
competition angel the artificial neural
generator of emotion and language is a
different twist on the Turing test where

[17:32]
different twist on the Turing test where
we don't use words we all
using motions to speak expression of
those emotions and we create we use an
age a face customizable we're 26 muscles

[17:48]
age a face customizable we're 26 muscles
all of which can be controlled with an
LS TM we use a neural network to train
the generation of emotion and the
competition in you submitting the code

[18:03]
competition in you submitting the code
to the competition is you get 10 seconds
to impress with the these expressions of
emotion the viewer
it's a be testing your goal is to

[18:16]
it's a be testing your goal is to
impress the viewer enough to where they
choose your agent versus another agent
and those that are most loved the agents
most loved will be the ones that are
declared winners in a twist we will add

[18:33]
declared winners in a twist we will add
human beings into this mix so we've
created a system that map's our human
faces myself and the TAS to where we
ourselves enter an outcome in the

[18:45]
ourselves enter an outcome in the
competition and try to convince you to
keep us as your friend
that's the Turing test ethical car
building and the ideas of the trolley

[19:01]
building and the ideas of the trolley
problem and the moral machine done here
in the Media Lab the incredible
interesting work we take a machine
learning approach to it and take what
we've developed the deep reinforcement
learning competition for success 0 9 for

[19:15]
learning competition for success 0 9 for
the deep traffic and we add pedestrians
into it stochastic astok irrational
unpredictable pedestrians and we add
human life to the loss function where

[19:31]
human life to the loss function where
there's a trade-off between getting from
point A to point B so in deep traffic
the deep reinforcement learning
competition the goal was to go as fast
as possible here it's up to you to
decide what what your agents goal is

[19:47]
decide what what your agents goal is
there's a parade of front
trade-off between getting from point A
to point B as fast as possible and
hurting pedestrians this is not a

[20:09]
hurting pedestrians this is not a
ethical question it's an engineering
question and it's a serious one because

[20:20]
question and it's a serious one because
fundamentally in creating autonomous
vehicles that function in this world we
want them to get from point A to point B
as quickly as possible

[20:30]
as quickly as possible
the United States government insurance
companies put a price tag on human life
we put that power in your hands
in designing these agents to ask the
question of a how can we create machine

[20:47]
question of a how can we create machine
learning systems where the objective
function the loss function has human
life as part of it and vote AI is an
aggregator of different links different

[21:02]
aggregator of different links different
articles papers videos on the topic of
artificial general intelligence where
people vote on vote quality articles up
and down and choose on the sentiment of

[21:16]
and down and choose on the sentiment of
positive and negative we'd like to
explore the different ways to the
different arguments for and against
artificial general intelligence there is
an incredible list of speakers the best

[21:30]
an incredible list of speakers the best
in their disciplines from Josh Tenenbaum
PN MIT to Ray Kurzweil at Google to lisa
Feldman Barrett and Nader Pinsky from
Northeastern University
Andre karpati Stephen Wolfram Richard

[21:48]
Andre karpati Stephen Wolfram Richard
Moyes mark Robert
Ilya sutskever and myself Josh Tenenbaum
tomorrow I'd like to go through each of
these speakers and talk about the

[22:01]
these speakers and talk about the
perspectives they bring
that to try to see the approach the
ideas they bring to the table they're
not in most cases interested in the
discussion of the future impact on

[22:16]
discussion of the future impact on
society without grounding it into the
expertise into the actual engineering
into creating these intelligent systems
so josh is a computational cognitive
science expert professor faculty here at

[22:30]
science expert professor faculty here at
MIT he will talk about how we can create
common-sense understanding systems that
see a world of physical objects and
their interactions and our own
possibilities to act interact with
others the intuitive physics how do we

[22:46]
others the intuitive physics how do we
build into systems the intuitive physics
of the world more than just the deep
learning memorization engines that take
patterns and learn through supervised
way to map those patterns to
classification actually begin to

[23:02]
classification actually begin to
understand the intuitive the
common-sense physics of the world and
learn rapid model based learning learn
from nothing learn from very little just
like we do as children just like we do
as human being successfully often only

[23:16]
as human being successfully often only
need one example to learn a concept how
do we create systems that learn from
very few sometimes a single example and
integrate ideas from various disciplines
of course from neural networks but also

[23:31]
of course from neural networks but also
probabilistic generative models and
symbol processing architectures it's
going to be incredible of course from a
from a different area of the world
another incredible thinker intellectual

[23:46]
another incredible thinker intellectual
speaker is Ray Kurzweil he'll be here on
Wednesday and 1:00 p.m. and he will do a
whirlwind discussion of where we stand
with intelligence creating intelligent

[24:00]
with intelligence creating intelligent
systems how we see natural intelligence
our own human intelligence how we define
it how we understand it and how that
transfers to the increasing exponential
growth of development of artificial
general intelligence

[24:16]
something I'm myself very excited about
is Lisa Feldman Barrett coming here on
Thursday she's written a book I believe
how emotions are made she argues that

[24:31]
how emotions are made she argues that
emotions are created that there is a
distinction there's a detachment between
what we feel in our bodies the physical
state of our bodies and the expression
of emotion from from body to the

[24:47]
of emotion from from body to the
contextually grounded to the face
expressing that emotion which means now
why is there as a person who is
psychology person in a fundamental
engineering computer science topic like
AGI because if emotions are created in

[25:03]
AGI because if emotions are created in
the way she argues and she'll
systematically break it down
that means we're learning societal as
human beings were learning societal
norms of how to express emotion the idea
of emotional intelligence is learned

[25:16]
of emotional intelligence is learned
which means we can have machines learn
this idea it's a machine learn like it's
a human learning problem it's a machine
learning problem in a little bit of a
twist she asked that instead of giving
it talk I have a conversation with her

[25:32]
it talk I have a conversation with her
so it's going to be a little bit
challenging and fun and she's great
looking forward to it and we'll explore
different ways that we can get emotion

[25:45]
different ways that we can get emotion
expressed through video through audio
through the project the angel project
that I mentioned so there's been worked
in reenacting intelligence so well
reenacting mapping face to face mapping

[26:00]
reenacting mapping face to face mapping
different emotions on video that was
previously recorded so if you can
imagine that means we can take emotions
that we've created the kind of emotion
creation we've been discussing and remap
it on previous video that's one way to

[26:17]
it on previous video that's one way to
see intelligence is taking raw human
data that we already have and mapping
new computer-generated
the the underlying fundamentals of human
but the surface appearance the

[26:31]
but the surface appearance the
representation of emotion visual or
auditory is generated by a computer it
could be in the embodied form

[27:13]
[Music]

[27:17]
very important to note for those
captivated by Sofia in the press or have
seen these videos
Sofia is an art exhibit she's not a
strong natural language processing

[27:31]
strong natural language processing
system this is not an AGI system but
it's a beautiful visualization of
embodying of Hollow
it's a beautiful visualization of how
easy it is to trick us human beings that
there's intelligence underlying

[27:47]
there's intelligence underlying
something that the emotional expression
the physical embodiment and the
emotional expression that has a that has
some degree of humor that has some
degree of wit and intelligence is enough

[28:01]
degree of wit and intelligence is enough
to captivate us so that's an argument
for not creating intelligence from
scratch but having machines at the very
surface the display of that emotion the
generation the mapping of the visual and

[28:15]
generation the mapping of the visual and
auditory elements worth underneath it is
really trivial technology that's
fundamentally relying on humans like in
the sophia's case and in the simplest
form we remove all elements of Hajus a

[28:32]
form we remove all elements of Hajus a
attractive appearance from from an agent
we really keep it to the simplest
muscles
characteristics of the face and see with
26 muscles controlled by a neural
network through time so recurrent neural

[28:45]
network through time so recurrent neural
network I was TM how can we explore the
generation of emotion can we get this
thing and this is an open question for
us too we just created the system we
don't know if we can can we get it to
make us feel something make us feel

[29:00]
make us feel something make us feel
something by watching it express its
feelings can it become human before our
eyes can I learn to by competing against
other agents a be testing on Turk a

[29:15]
other agents a be testing on Turk a
Mechanical Turk can the winners be very
convincing to make us feel entertained
pity love maybe some of you will fall in
love with angel here Nate dibinsky on

[29:34]
love with angel here Nate dibinsky on
Friday will talk about cognitive
modeling architectures so you will speak
about the cognitive modeling aspect can
we have a ma can we model cognition in

[29:45]
we have a ma can we model cognition in
some kind of systematic way to try to
build intuition of how complicated
cognition is Andre karpati famous for
being the state-of-the-art human on the
imagenet challenge the representative

[30:02]
imagenet challenge the representative
the 95% accuracy performance among other
things he's also famous for his now a
Tesla he will talk about the role the
limitations the possibilities of deep

[30:17]
limitations the possibilities of deep
learning we'll talk as I have spoken
about in the past few weeks and
throughout about our misunderstanding or
our flawed intuition about what are the

[30:32]
our flawed intuition about what are the
difficult and what are the easy problems
in deep learning and the power of
representational learning the ability of
neural networks to form deeper and
deeper representations of the underlying
raw data that ultimately forms

[30:49]
takes complex information that's hard to
make sense of and convert it into useful
actionable knowledge that is from a

[31:00]
actionable knowledge that is from a
certain lens in a certain a certain lens
in a certain problem space can be
clearly defined as understanding of the
complex information understanding is
ultimately taking complex information
and reducing it to its simple essential

[31:17]
and reducing it to its simple essential
elements representational learning is in
the trivial case here in drawing having
to draw a straight line to separate the
blue and the red curves that's
impossible to do in the in initial input

[31:32]
impossible to do in the in initial input
space on the Left what the act of
learning is for deep neural networks in
this formulation is to construct a
topology under which there exists a
straight line to accurately classify
blue versus red that's the problem and

[31:48]
blue versus red that's the problem and
for a simple blue and red line
it seems trivial here but this works in
the general case for arbitrary input
spaces for arbitrary nonlinear highly
dimensional input spaces and the ability

[32:00]
dimensional input spaces and the ability
to automatically learn features to learn
hierarchical representations of the raw
sensory data means that you could do a
lot more with data which means you can
expand further and further and further
to create intelligent systems that

[32:17]
to create intelligent systems that
operate successfully with real-world
data that's what representational
learning means that deep learning allows
because the arbitrary number of features
that can be automatically determined you
can learn a lot of things about a pretty

[32:31]
can learn a lot of things about a pretty
complex world
unfortunately there needs to be a lot of
supervised data there still needs to be
a lot of human input Andre and others
Josh will talk about the difference

[32:45]
Josh will talk about the difference
between our human brain our biological
neural network and the artificial neural
network the full human brain with 100
billion neurons 1000 trillion synapses
and the biggest neural networks out

[33:01]
and the biggest neural networks out
there the artificial neural network
having much smaller 60 million synapses
for ResNet 152 the biggest difference
the parameter is a human brain being
several orders of magnitude more

[33:16]
several orders of magnitude more
synapses the topology being much more
complex chaotic the asynchronous nature
of the human brain and the learning
algorithm of artificial neural networks
is trivial and constrained with

[33:30]
is trivial and constrained with
backpropagation is essentially an
optimization function over over a
clearly defined loss function from the
output to the to the input using back
propagation to teach to adjust the
weights on that network the learning

[33:45]
weights on that network the learning
algorithm for our human brain is mostly
unknown but it's certainly much more
complicated than back propagation the
power consumption the human brain is a
lot more efficient than artificial

[34:00]
lot more efficient than artificial
neural networks and there's a very kind
of artificial trivial supervised
learning process for training artificial
neural networks you have to have a
training stage and you have to have an
evaluation stage and once the network is

[34:17]
evaluation stage and once the network is
trained there's no clear way to continue
training it or there's a there's a lot
of ways but they're inefficient it's not
designed to do online learning naturally
to always be learning is designed to be

[34:30]
to always be learning is designed to be
to learn and then be applied obviously
our human brains are always learning but
the beautiful fascinating thing is that
they're both distributed computation
systems on a large scale so it's not a

[34:46]
systems on a large scale so it's not a
there's it doesn't ultimately boil down
to a single compute unit the computation
is distributed the back propagation
learning process is distributed can be
paralyzed in a GPU massively paralyzed
the underlying computational unit of a

[35:03]
the underlying computational unit of a
neuron is trivial but can be stacked
together to form forward neural networks
recurrent neural networks to represent
both spatial information with images and
temporal information we

[35:16]
temporal information we
the audio speech text sequences of
images and video and so on mapping from
one-to-one one-to-many many-to-one so
the mapping any kind of structure vector

[35:31]
the mapping any kind of structure vector
and time data as an input to any kind of
classification regression sequences
captioning video audio as output
learning in the general sense but in a

[35:45]
learning in the general sense but in a
domain that's precisely defined for the
supervised training process we can think
of the in deep learning case you can
think of the supervised methods where

[36:00]
think of the supervised methods where
humans have to annotate the data as
memorization of the data we can think of
the exciting new and growing field of
semi-supervised learning where most of
the data through or through generative
adversarial networks or through
significant data augmentation clever

[36:16]
significant data augmentation clever
data augmentation most of it is done
automatically the annotation process or
through simulation and then
reinforcement learning where most of the
most of the labels are extremely sparse
and come rarely and so the system has to

[36:30]
and come rarely and so the system has to
figure out how to operate in the world
with very little human input very little
human data we can think of that as
reasoning because you take very little
information from our teachers the humans
and transfer it across generalize it

[36:45]
and transfer it across generalize it
across to reason about the world and
finally unsupervised learning the
excitement of the community that promise
the hope you could think of that as
understanding because ultimately it's
taking data with very little or no human
input and forming representations that

[37:01]
input and forming representations that
that data is how we think of
understanding requiring making sense of
the world without strict input of how to
make sense of the world the kind of
process of discovering information maybe

[37:18]
process of discovering information maybe
discovering new ideas new ways to
simplify the world to represent the
world that you can do new things with it
the new is the key element there
understanding
and Andre and Ilya and others will talk

[37:32]
and Andre and Ilya and others will talk
about the certainly the past but the
future of deep learning where is it
going to go
is it overhyped underhyped what is the
future will the compute of cpu GPU si

[37:45]
future will the compute of cpu GPU si
Asics continue with the breakthroughs
the Moore's law in its various forms of
massive parallelization continue and the
large datasets with tens of millions of
images grow to billions and trillions
will the algorithms improve is there a

[38:03]
will the algorithms improve is there a
groundbreaking idea that's still coming
look with Jeff hiddens capsule networks
is there fundamental architectural
changes to neural networks that we can
come up with that will change everything

[38:15]
come up with that will change everything
that will ease the learning process
they'll make the learning process more
efficient or we'll be able to represent
higher and higher orders of information
such that you can transform knowledge
between domains and the software

[38:30]
between domains and the software
architectures that support intensive
florida pi torch i would say last year
and this year will be the year of deep
learning frameworks so those will
certainly keep coming in their various
forms and the financial backing is
growing and growing the open challenges

[38:49]
growing and growing the open challenges
for deep learning really a lot of this
course is kind of connected to deep
learning because that's where a lot of
the recent breakthroughs that inspire us

[39:00]
the recent breakthroughs that inspire us
to think about intelligence systems come
from but the challenges of many the need
the ability to transfer between
different domains as in reinforcement
learning and robotics the need for huge
data in an official learning that we

[39:16]
data in an official learning that we
still need supervised data an ability to
learn in an unsupervised way is a huge
problem and not fully automated learning
there's still a degree a significant
degree of hyper parameter necessary with

[39:31]
degree of hyper parameter necessary with
the reward functions the loss functions
are ultimately defined by humans and
therefore are deeply flawed when we
release those systems into the real
world
there is no ground truth for the testing
set and the goal isn't achieving a class

[39:47]
set and the goal isn't achieving a class
high classification on a trivial image
classification localization detection
problem but rather to have a autonomous
vehicle that doesn't kill pedestrians or

[40:00]
vehicle that doesn't kill pedestrians or
an industrial robot that operates in
jointly with other human beings and all
the edge cases that come up how does
deep learning methods how do machine
learning methods generalize over the
edge cases the weird stuff that happens
in the real world those are all the

[40:16]
in the real world those are all the
problems there Stephen Wolfram will be
here on Monday evening at 7 p.m. has
done a lot of amazing things I would say
is very interesting from his recent
interest in knowledge based programming

[40:31]
interest in knowledge based programming
Wolfram Alpha I think is the fuel for
most middle school and high school
students now for the first time taking
calculus I pray probably go to Wolfram
Alpha to answer their own questions but

[40:45]
Alpha to answer their own questions but
more seriously there is a a deep
connected graph of knowledge is being
built there with the Wolfram or Wolfram
Alpha and Wolfram language that steel
will explore in terms of language an
interesting thing he was part of the

[41:02]
interesting thing he was part of the
team on arrival that worked on the
language if for those of you are
familiar the arrival were a alien
species spoke with us us humans through

[41:15]
species spoke with us us humans through
a very interesting beautiful complicated
language and he was brought in as a
representative human to interpret that
language just like in the movie he was
represent that in real life and you used
the skills that him and his son

[41:30]
the skills that him and his son
Christopher used to analyze this
language very interesting that process
is extremely interesting I hope he talks
about it and his background with
Mathematica and new kind of science the
sort of another set of ideas that have

[41:49]
sort of another set of ideas that have
inspired people in terms of creating
intelligence systems is the idea that
from very simple things were very simple

[42:04]
from very simple things were very simple
rules extremely complex patterns can
emerge his work was cellular automata
did just that taking extremely simple
mathematical constructs here with

[42:17]
mathematical constructs here with
cellular automata these are these are
grids of computational units that switch
on and off in some kind of a predefined
way and only operate locally based on
their local neighborhood and somehow

[42:30]
their local neighborhood and somehow
based on different kinds of rules
different patterns emerge here's a three
dimensional cellular automata with a
simple rule starting with nothing with a
single cell they grow in really
interesting complex ways this emergent
complexity is inspiring it's the same

[42:46]
complexity is inspiring it's the same
kind of thing that inspires us about
neural networks that you can take a
simple computational unit and when
combined together in arbitrary ways can
form complex representations that's also
very interesting you can see knowledge

[43:00]
very interesting you can see knowledge
from a knowledge perspective you can see
knowledge formation in the same kind of
way simplicity at a mass distributed
scale resulting in complexity next
Tuesday
Richard Moyes from article 36 coming all

[43:17]
Richard Moyes from article 36 coming all
the way from UK for us we'll talk about
it works with autonomous weapons systems
works with also nuclear weapons but
primarily autonomous weapon systems and
concern legal policy and technological

[43:33]
concern legal policy and technological
aspects of banning these weapons there's
been a lot of agreement about the safety
hazards of autonomous systems that make
decisions to kill a human being
mark Robert CEO of Boston Dynamics

[43:49]
mark Robert CEO of Boston Dynamics
previously a long time ago faculty here
at MIT will talk about will bring robots
and talk to us about his work of robots
in the real world as doing a lot of

[44:02]
in the real world as doing a lot of
exciting stuff with humanoid robotics
and any kind of robots operating on legs
it's incredible
work extremely exciting and gets to
explore the idea of how difficult it is
to build these robot systems that

[44:15]
to build these robot systems that
operate in the real world from both the
control aspect and from the way the
final result is perceived by our society
it's very interesting to see when

[44:30]
it's very interesting to see when
intelligence in robotics is embodied and
then taking in by us and what that
inspires fear excitement hope concern
and all the above Ilya sutskever is

[44:46]
and all the above Ilya sutskever is
expert in many aspects of machine
learning
he is the co-founder of open AI I'll
talk about their different aspects of
game playing that they've recently been
exploring about using deeper enforcement

[45:02]
exploring about using deeper enforcement
learning to play our K games in D on the
deep mind side using deep reinforcement
learning to beat the best in the world
that the game of go in 2017 the big

[45:16]
that the game of go in 2017 the big
fascinating breakthrough achieved by
that team with alphago zero training an
agent that through self play playing
itself not on expert games so truly from
scratch learning to beat the best in the
world including the previous iteration

[45:30]
world including the previous iteration
of alphago
we will explore what aspects of the
stack of intelligent robotic systems
intelligent agents can be learned in
this way so deep learning the
memorization the supervised learning
memorization approach it looks at the

[45:47]
memorization approach it looks at the
sensor data feature extraction
representation learning aspect of this
taking the sensor data from camera light
our audio extracting the features
forming higher-order representations and

[46:00]
forming higher-order representations and
on those representations learning to
actually accomplish some kind of
classification regression task figuring
out based on the representation what is
going on in the raw sensory data and
then combining that data together to
reason about it and finally in the

[46:17]
reason about it and finally in the
robotic domains taking it all together
as with human
industrial robotics autonomous vehicles
taking all together and actually acting
in this world with the effectors and the

[46:30]
in this world with the effectors and the
open question is how much of this AI
stack can be learned that's something
for us to discuss to think about that a
Leo will touch on with deeper
enforcement learning we can certainly
learn representations and perform

[46:45]
learn representations and perform
classifications state-of-the-art better
than human and image classification
imagenet and segmentation tasks and the
excitement of deep learning is what's
highlighted there in the red box can be
done end to ends
raw sensory data out to the knowledge to

[47:00]
raw sensory data out to the knowledge to
the output to the classification can we
begin to reason is the open question
with the knowledge based programming
that Stephen Wolfram will talk about can
we begin to take these automatically
generated high order representations and

[47:15]
generated high order representations and
combine them together to form knowledge
bases to form aggregate graphs of ideas
that can then be used to reason and can
we then combine them together to act in

[47:30]
we then combine them together to act in
the world for whether in simulation with
arcade games or simulation of autonomous
vehicles or biotic systems or actually
in the physical world with robots moving
about can that end end from raw sensory
data to action be learned that's the

[47:47]
data to action be learned that's the
open question for for artificial general
intelligence for this class can this
entire process be end to end can we
build systems and how do we do it that

[48:01]
build systems and how do we do it that
achieve this process end to end in the
same way that humans do we're born in
this raw sensory environment taking in
very little information and learn to
operate successfully in arbitrary

[48:15]
operate successfully in arbitrary
constraints arbitrary goals and to do so
we have lectures we have three projects
and we have guest speakers from various
disciplines I hope that all these voices

[48:31]
disciplines I hope that all these voices
will be heard and will feed a
conversation
artificial intelligence and it's
positive and it's concerning effects in
society and how do we move forward from

[48:45]
society and how do we move forward from
an engineering approach the topics will
be deep learning deep reinforcement
learning cognitive modeling
computational cognitive science emotion
creation knowledge based programming AI
safety with autonomous weapon systems
and personal robotics with human

[49:01]
and personal robotics with human
centered artificial intelligence that's
for the first two weeks of this class
that's the the part where if you're
actually registered students that's
where you need to submit the project
that's when we all meet here every every
night with the incredible speakers but

[49:15]
night with the incredible speakers but
this will continue we already have
several speakers scheduled in the next
couple of months yet to be announced but
they're incredible and we have
conversations on video and we have new
projects
I hope this continues throughout 2018 on

[49:31]
I hope this continues throughout 2018 on
the topics of IAI ethics and bias
there's a lot of incredible work in we
now have a speaker there coming on the
topic of how do we create artificial
intelligence systems that I do not
discriminate do not form the kind of

[49:47]
discriminate do not form the kind of
biases that us humans do in this world
that are operating under social norms
but our reasoning beyond the flawed
aspects of those social norms with bias

[50:01]
aspects of those social norms with bias
creativity as with a project of dream
vision and beyond there is so much
exciting work in charin using machine
learning methods to create beautiful art
and music brain simulation neuroscience

[50:17]
and music brain simulation neuroscience
competition in neuroscience shockingly
in the first two weeks we don't have a
competition neuroscience speaker which
is a fascinating perspective brain
simulation or neuroscience in general

[50:30]
simulation or neuroscience in general
computational neuroscience is a
fascinating approach from the from the
muck of actual brain work to get the
perspective of how our brain works and
how we can create something that mimics
that resembles the fundamentals of what

[50:45]
that resembles the fundamentals of what
makes our brain intelligent and finally
the touring test the traditional
definition of intelligence defined by
Alan Turing was grounded in natural
language processing creating chat BOTS
that impress us that amaze us and trick
us into thinking they're human we will

[51:02]
us into thinking they're human we will
have a project and a speaker on natural
language processing in March with that
I'd like to thank you for coming today
and look forward to seeing your
submissions for the three projects thank

[51:15]
submissions for the three projects thank
you very much
[Applause]