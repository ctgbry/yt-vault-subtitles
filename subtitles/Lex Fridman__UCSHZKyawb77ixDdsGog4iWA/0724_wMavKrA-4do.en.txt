[00:00]
maybe we shouldn't think of AI as our
tool and as our assistant maybe we
should really think of it as our
children
and the same way that
you are responsible for training those
children but they are independent human
beings and at some point they will

[00:15]
beings and at some point they will
surpass you and uh this whole concept of
alignment of basically making sure that
the AI is always at the service of
humans is very self-serving and very
limiting If instead you basically think
about AI as a partner
and AI as someone that shares your goals

[00:33]
and AI as someone that shares your goals
but has freedom then we can't just
simply force it to align with ourselves
and we not align with it
so in a way building trust is mutual you
can't just simply like train an

[00:46]
can't just simply like train an
intelligent system to love you when it
realizes that you can just shut it off
the following is a conversation with
minolas callus his fifth time on this
podcast he's a professor at MIT and head

[01:02]
podcast he's a professor at MIT and head
of the MIT computational biology group
he's one of the greatest living
scientists in the world but he's also a
humble kind caring human being that I
have the greatest of honors and

[01:15]
have the greatest of honors and
pleasures of being able to call a friend
this is the Lex Friedman podcast to
support it please check out our sponsors
in the description and now dear friends
here's manolas callus
good to see you first of all Alex I've

[01:30]
good to see you first of all Alex I've
missed you I think you've changed the
lives of so many people that I know and
it's truly like such a pleasure to be
back such a pleasure to see you grow to
sort of reach so many different aspects
of your own personality thank you for
the love you've always give me a lot of
support and love I just can't I I I'm
forever grateful for that it's lovely to

[01:46]
forever grateful for that it's lovely to
see a fellow human being who has that
love who basically does not judge people
and there's so many judgmental people
out there and it's just so nice to see
these Beacon of
openness so what makes me one
instantiation of human Irreplaceable do

[02:00]
instantiation of human Irreplaceable do
you think as we enter this increasingly
capable age of increasingly capable AI I
have to ask what do you think makes
humans Irreplaceable so humans are
irreplaceable because of the baggage
that we talked about so we talked about

[02:15]
that we talked about so we talked about
baggage we talked about the fact that
every one of us
has effectively relearned all of human
civilization in their own way so every
single human has a unique set of genetic
variants that they've inherited some

[02:30]
variants that they've inherited some
common some rare and some makers think
differently so make us have different
personalities they say that a a parent
with one child believes in genetics a
parent with multiple children
understands genetics just how different
kids are and my three kids have

[02:46]
kids are and my three kids have
dramatically different personalities
ever since the beginning so one thing
that makes us unique is that every one
of us has a different Hardware
the second thing that makes it unique is
that every one of us has a different
software uploading of all of human
Society all of human civilization or

[03:01]
Society all of human civilization or
human knowledge we don't we're not born
knowing it we're not like I don't know
uh birds that learn how to make a nest
through genetics and will make a nest
even if they've never seen one we are
constantly relearning all of human
civilization so that's the second thing

[03:16]
civilization so that's the second thing
and the third one that actually makes
humans very different from AI is that
the baggage we carry is not experiential
baggage it's also evolutionary baggage
so we have evolved through rounds of
complexity

[03:31]
complexity
so just like ogres have layers and
Shrink has layers humans have layers
there's the cognitive layer which is
sort of the outer you know most the the
latest evolutionary Innovation this
enormous neocortex that we have evolved

[03:45]
enormous neocortex that we have evolved
and then there's the emotional uh
baggage underneath that and then there's
all of the fear and fright and flight
and all of these kinds of behaviors so
AI only has a neocortex AI doesn't have
a limbic system it doesn't have this

[04:02]
a limbic system it doesn't have this
complexity of human emotions which make
us so I think beautifully complex so
beautifully uh intertwined with our
emotions with our instincts with our you

[04:16]
emotions with our instincts with our you
know sort of gut reactions and all of
that so I think when humans are trying
to suppress that aspect the sort of code
more human aspect towards a more
cerebral aspect I think we lose a lot of
the creativity we lose a lot of the you

[04:30]
the creativity we lose a lot of the you
know freshness of humans and I think
that's quite Irreplaceable so we can
look at the entirety of people that are
alive today maybe all humans who have
ever lived and map them in this High
dimensional space and there's probably a
center
uh a center of mass for that mapping and

[04:48]
uh a center of mass for that mapping and
a lot of us deviate in different
directions so the the variety of uh
directions in which we all deviate from
that Center is vast I would like to
think that the center is actually empty
yes that basically humans are just so

[05:02]
yes that basically humans are just so
diverse from each other that there's no
such thing as an average human
that every one of us has some kind of
complex baggage of emotions intellectual
you know motivational uh behavioral

[05:15]
you know motivational uh behavioral
traits that
um it's not just one sort of normal
distribution we deviate from it there's
just so many dimensions that we're kind
of hitting the sort of sparseness the
the curse of dimensionality where it's
actually quite sparsely populated and I

[05:31]
actually quite sparsely populated and I
don't think you have an average human
being so what makes us unique in part is
the diversity
and the capacity for diversity and the
capacity of the diversity comes from the
entire evolutionary history so there's

[05:45]
entire evolutionary history so there's
just so many ways we can vary from each
other yeah I would say not just the
capacity but the inevitability of
diversity basically it's in our Hardware
we are wired differently from each other
my siblings and I are completely

[06:01]
my siblings and I are completely
different my kids from each other
completely different my my wife has
she's like number two of six siblings
from from a distance they look the same
but then you get to you know you get to
know them every one of them is
completely different but sufficiently
the same that the differences interplay

[06:15]
the same that the differences interplay
with each other so that's the
interesting thing where the diversity is
functional it's useful so it's like
we're close enough to where we notice
the diversity and it doesn't completely
destroy the possibility of like
effective communication interactions so

[06:31]
effective communication interactions so
we're still the same kind of thing so
what I said in one of our earlier
podcasts is that if humans realize that
we're 99.9 percent identical we would
basically stop fighting with each other
like we are really one human species and

[06:46]
like we are really one human species and
we are so so similar to each other and
if you look at the alternative if you
look at the next thing outside humans
like it's been six million years that we
haven't had a relative so it's it's
truly extraordinary that that we're

[07:02]
truly extraordinary that that we're
we're kind of like this Dot in outer
space compared to the rest of life on
earth when you think about evolving
through rounds of complexity can you
maybe elaborate such a beautiful phrase
beautiful thought that there's layers of

[07:15]
beautiful thought that there's layers of
complexity that make so so with software
sometimes you're like oh let's like
build version two from scratch
but this doesn't happen in evolution in
evolution you layer in additional
features on top of old features so

[07:30]
features on top of old features so
basically when uh like every single time
my cells divide
I'm a yeast like I'm a unicellular
organism and then cell division is
basically identical
every time I breathe in and my lungs
expand

[07:45]
expand
I'm basically you know like every time
my heart beats I'm a fish so basically
that I still have the same heart like
very very little has changed the blood
going through my veins the oxygen the
you know our immune system we're

[08:00]
you know our immune system we're
basically primates our social behavior
we're basically New World monkeys and
all World monkeys we're basically
um this this concept that every single
one of these behaviors can be traced
somewhere in evolution and that all of

[08:16]
somewhere in evolution and that all of
that continues to live within us is also
a testament to not just not killing
other humans for God's sake but like not
killing other species either like just
to realize just how united we are with
nature and that all of these biological
processes have never ceased to exist

[08:31]
processes have never ceased to exist
they're continuing to live within us and
then just the neocortex and all of the
reasoning capabilities of humans are
built on top of all of these other
species that continue to live breathe
divide metabolize
fight off pathogens all continued

[08:46]
fight off pathogens all continued
insiders so you think the neocortex the
whatever reasoning is that's the the
latest feature in the in the latest
version of this journey it's it's
extraordinary that humans have evolved
so much in so little time

[09:01]
so much in so little time
again if you look at the the timeline of
evolution you basically have billions of
years to even get to a dividing cell and
then a multicellular organism and then a
complex body plan and then these

[09:16]
complex body plan and then these
incredible senses that we have for
perceiving the world the fact that bats
can fly and they evolved flight the
evolved sonar in the span of a few
million years I mean it's just the
extraordinary how much Evolution has
kind of sped up and all of that comes

[09:31]
kind of sped up and all of that comes
through this
evolvability the fact that we took a
while to get good at evolving and then
once you get good at evolving you can
sort of
you have modularity built in you have
hierarchical organizations built in you

[09:46]
hierarchical organizations built in you
have all of these constructs that allow
meaningful changes to occur without
breaking the system completely if you
look at a traditional genetic algorithm
the way that humans designed them in the
60s
you can only evolve so much and as you

[10:01]
you can only evolve so much and as you
evolve a certain amount of complexity
the number of mutations that move you
away from something functional
exponentially increases and the number
of mutations that move you to something
better exponentially decreases so the

[10:15]
better exponentially decreases so the
probability of evolving something so
complex becomes Infinity small as you
get more complex but with Evolution it's
almost the opposite
almost the exact opposite that it
appears that it's speeding up exactly as
complex complexity is increasing and I

[10:31]
complex complexity is increasing and I
think that's just the system getting
good at evolving
where do you think it's all headed
do you ever think about where
try to visualize the entirety of The
evolutionary system and see if there's
an arrow to it and a destination to it

[10:47]
an arrow to it and a destination to it
so the best way to understand the future
is to look at the past if you look at
the trajectory then you can kind of
learn something about the direction
which we're heading and if you look at
the trajectory of life on Earth it's
really about information processing so

[11:01]
really about information processing so
the the concept of the senses evolving
one after the other uh you know being
like bacteria are able to do chemotaxis
basically means moving towards a
chemical gradient and that's the first
thing that you need to sort of hunt down
food the next step after that is being

[11:17]
food the next step after that is being
able to actually perceive light so all
life on this planet and all life that we
know about evolved on this rotating Rock
every 24 hours you get sunlight and dark
sunlight and dark and light is a source

[11:31]
sunlight and dark and light is a source
of energy light is also information
about where is up light is all kinds of
you know things so you can you can
basically now start perceiving light
and then perceiving shapes Beyond just
these sort of single photoreceptor you

[11:46]
these sort of single photoreceptor you
can now have complex eyes or multiple
eyes and then start perceiving motion or
perceiving Direction perceiving shapes
and then you start building
infrastructure on the cognitive
apparatus to start processing this
information and making sense of the

[12:01]
information and making sense of the
environment building more complex models
of the environment so if you look at
that trajectory of evolution what we're
experiencing now and humans are
basically according to this sort of
information theoretic view of evolution

[12:15]
information theoretic view of evolution
humans are basically the next natural
step and it's perhaps no surprise that
we became the dominant species of the
planet because yes there's so many
dimensions in which some animals are way
better than we are but at least on the
cognitive Dimension we're just simply
unsurpassed on this planet and and

[12:30]
unsurpassed on this planet and and
perhaps the universe but the the concept
that if you now trace this forward
we talked a little bit about
evolvability and how things get better
at evolving one possibility is that the

[12:45]
at evolving one possibility is that the
next layer of evolution builds the next
layer of evolution and what we're
looking at now with humans in AI is that
having mastered this information
capability that humans have

[13:01]
capability that humans have
from this quote-unquote old Hardware
this basically you know biological
evolved system that kind of you know
somehow in the environment of Africa and
then in subsequent environments of sort
of dispersing through the globe was

[13:16]
of dispersing through the globe was
evolutionarily advantageous
that has now created
technology which now has a capability of
solving many of these cognitive tasks it
doesn't have all the baggage of the

[13:30]
doesn't have all the baggage of the
previous revolutionary layers but maybe
the next round of evolution on Earth is
self-replicating AI where we're actually
using our current smarts to build better
programming languages and the
programming languages to build you know
chat GPT and that then build the next

[13:46]
chat GPT and that then build the next
layer of software that will then sort of
help AI speed up and it's lovely that
we're coexisting with this AI that sort
of the creators of this next layer of
evolution in this next stage are still

[14:01]
evolution in this next stage are still
around to help guide it and hopefully
will be for the rest of Eternity as
partners but it's also nice to think
about it as just simply the next stage
of evolution where you've kind of
extracted away the biological needs like
if you look at animals most of them
spend 80 percent of their waking hours

[14:16]
spend 80 percent of their waking hours
hunting for food or building shelter
humans maybe one percent of that time
and then the rest is left to creative
Endeavors an AI doesn't have to worry
about shelter Etc so basically it's all
living in the cognitive space so in a

[14:30]
living in the cognitive space so in a
way it might just be a very natural sort
of next step to think about Evolution
and that's that's on the on the sort of
purely cognitive side if you now think
about humans themselves
the ability to understand and comprehend
our own genome again the ultimate layer

[14:47]
our own genome again the ultimate layer
of introspection
gives us now the ability to even mess
with this Hardware not just augment our
capabilities through interacting and
collaborating with AI but also perhaps

[15:00]
collaborating with AI but also perhaps
understand the neural Pathways that are
necessary for
you know
empathetic thinking for for justice for
this and this and that and sort of help
augment human capabilities through you

[15:16]
augment human capabilities through you
know neuronal interventions through
chemical interventions through
electrical interventions to basically
help steer the human you know bag of
Hardware that we kind of evolved with
into greater capabilities

[15:30]
into greater capabilities
and then ultimately by understanding not
just the wiring of neurons and the
functioning of neurons but even the
genetic code we could even at one point
in the future start thinking about well
can we get rid of psychiatric disease

[15:45]
can we get rid of psychiatric disease
can we get rid of neurodegeneration can
we get rid of dementia and start perhaps
even augmenting human capabilities not
just
getting rid of disease
can we Tinker with the genome with the
hardware

[16:01]
hardware
or getting closer to the hardware
without having to deeply understand the
baggage
in the way we've disposed of the baggage
in our software systems with AI
to some degree not fully but to some
degree can we do the same with the

[16:15]
degree can we do the same with the
genome or is the genome deeply
integrated into this bag I wouldn't want
to get rid of the baggage the baggage
what makes this awesome so the fact that
I'm sometimes angry and sometimes hungry
and sometimes angry
is perhaps contributing to my creativity

[16:31]
is perhaps contributing to my creativity
I don't want to be dispassionate I don't
want to be another like you know robot I
you know I want to get in trouble and I
want to sort of say the wrong thing and
I want to sort of you know make an
awkward comment and sort of push myself
into

[16:46]
into
you know reactions and responses and
things that
can get just people thinking differently
and
I I think our society is moving towards
a humorless uh space where everybody's

[17:00]
a humorless uh space where everybody's
so afraid to say the wrong thing that
people kind of start quitting on mass
and start like not liking their jobs and
stuff like that maybe we should be uh
kind of embracing that human aspect a
little bit more in all of that baggage

[17:16]
little bit more in all of that baggage
aspect
and uh not necessarily thinking about
replacing it on the contrary like
embracing it in sort of this coexistence
of the cognitive and the emotional hard
words so embracing and celebrating the
diversity
that Springs from the baggage versus

[17:32]
that Springs from the baggage versus
uh kind of uh pushing towards and
empowering this kind of pull towards
Conformity yeah and in fact with the
Advent of AI I would say and these

[17:47]
Advent of AI I would say and these
seemingly extremely intelligent systems
that sort of conform can perform tasks
that we thought of as extremely
intelligent at the blink of an eye
this might democratize
intellectual Pursuits instead of just

[18:02]
intellectual Pursuits instead of just
simply wanting the same type of brains
that you know carry out
specific ways of thinking we can like
instead of just always only wanting say
the mathematically extraordinary to go

[18:16]
the mathematically extraordinary to go
to the same universities what you could
see simply say is like who needs that
anymore you know we now have ai maybe
what we should really be thinking about
is the diversity and the power that
comes with the diversity where AI can do

[18:31]
comes with the diversity where AI can do
the math and then we should be getting a
bunch of humans that sort of think
extremely differently from each other
and maybe that's the true cradle of
innovation
but
AI can also these large language models

[18:45]
AI can also these large language models
can also be with just a few prompts
essentially fine-tuned to be diverse
from the center
so the prompts can really take you away
into unique territory you can ask the
model to act
in a certain way and it will start to
act in that way is that possible that uh

[19:03]
act in that way is that possible that uh
the language models could also have some
of the magical diversity that makes us
so damn interesting so I would say
humans are the same way so basically
when you when you sort of prompt humans
to basically you know you know give an

[19:16]
to basically you know you know give an
environment to act a particular way
they change their own behaviors and
um you know the old saying is show me
your friends and I'll tell you who you
are
more like show me your friends and I'll

[19:31]
more like show me your friends and I'll
tell you who you'll become so it's not
necessarily that you choose friends that
are like you but I mean that's the first
step but then the second step is that
you know the kind of behaviors that you
find normal in your circles are the
behaviors that you'll start espousing

[19:45]
behaviors that you'll start espousing
and that type of meta Evolution where
every action we take not only shapes our
current action and the result of this
action but it also shapes our future
actions by shaping the environment in
which those future actions will be taken

[20:00]
which those future actions will be taken
every time you you carry out a
particular Behavior it's not just a
consequence for today but it's also a
consequence for tomorrow because you're
reinforcing that neural pathway so in a
way self-discipline is a self-fulfilling
prophecy
and by

[20:15]
and by
behaving the way that you want to behave
and choosing people that are like you
and sort of exhibiting those behaviors
that are
sort of desirable
you end up creating that that
environment as well so it is the kind of

[20:32]
environment as well so it is the kind of
life itself is a kind of prompting
mechanism super complex the friends you
choose the environments you choose the
way you modify the environment that you
choose yes but that seems like that

[20:45]
choose yes but that seems like that
process is much less efficient than a
large language model you can literally
get a large language model through a
couple of prompts to be
a mix of Shakespeare and David Bowie
right you can very aggressively change

[21:00]
right you can very aggressively change
in a way that's stable and convincing
you really transform
through a couple of prompts the behavior
of the model
into something very different from the
original so well before

[21:16]
original so well before
Chachi PT yeah I would tell my students
just ask you know what would Manali say
right now and you you guys all have a
pretty good emulator of me right now yes
and uh I don't know if you know the
programming Paradigm of the rubber

[21:31]
programming Paradigm of the rubber
duckling where you basically explain to
the rubber duckling that's just sitting
there exactly what you did with your
code and why you have a bug and just by
the act of explaining you'll kind of
figure it out yes I woke up one morning
from a dream where I was giving a

[21:47]
from a dream where I was giving a
lecture in this Amphitheater and one of
my friends was basically giving me some
deep evolutionary Insight on how cancer
genomes and cancer cells evolve and I
woke up with a very elaborate discussion

[22:00]
woke up with a very elaborate discussion
that I was giving and a very elaborate
set of insights that he had
that I was projecting onto my friend in
my sleep and obviously this was my dream
so my own neurons were capable of doing
that but they only did that Under The
Prompt of you are now piyush Gupta

[22:17]
Prompt of you are now piyush Gupta
you are a professor in cancer genomics
you're an expert in that field what do
you say so I feel that we all have that
inside us that we have that capability
of basically saying I don't know what

[22:30]
of basically saying I don't know what
the right thing is but let me ask my
virtual legs what would you do and
virtual X would say be kind I'm like oh
yes
or something like that and even though I
myself might not be able to do it
unprompted
and uh the my favorite prompt is think

[22:46]
and uh the my favorite prompt is think
step by step and I'm like you know this
also works on my 10 year old
when he tries to solve a math equation
all in one step I know exactly what
mistake you'll make but if I prompt it
with oh please think step by step then

[23:00]
with oh please think step by step then
you sort of gets in a mindset and I
think it's also part of the way that
Chachi PT was actually trained this
whole sort of human in the loop
reinforcement learning
has probably reinforced these types of
behaviors whereby having this feedback

[23:17]
behaviors whereby having this feedback
loop you kind of aligned AI better to
the prompting opportunities by humans
yeah prompting human like reasoning
steps the step-by-step kind of thinking
yeah it does seem to be I suppose it

[23:30]
yeah it does seem to be I suppose it
just puts a mirror to our own
capabilities and so we can be truly
impressed by our own cognitive
capabilities because the variety of what
you can try because we don't usually
have this kind of we can't play with our

[23:45]
have this kind of we can't play with our
own mind
rigorously
through python code right yeah so this
allows us to really play with
um all all of human wisdom and knowledge
or at least knowledge at our fingertips
and then mess with that little mind that

[24:01]
and then mess with that little mind that
can think and speak in all kinds of ways
what's unique is that as I mentioned
earlier every one of us was trained by
different subset of human culture
and Chachi PT was trained on all of it
yeah and the difference there is that it

[24:16]
yeah and the difference there is that it
probably has the ability to emulate
almost any every one of us yeah the fact
that you can figure out where that is in
cognitive behavioral space just by a few
prompts it's pretty impressive but the
fact that that exists somewhere is you

[24:31]
fact that that exists somewhere is you
know absolutely beautiful and
the fact that it's encoded in an
orthogonal way from the knowledge I
think is also beautiful the fact that
somehow through these extreme
overparameterization of AI models it was

[24:47]
overparameterization of AI models it was
able to somehow figure out that context
knowledge and form are separable and
that you can sort of describe scientific
knowledge in a haiku in the form of I
don't know Shakespeare or something that

[25:00]
don't know Shakespeare or something that
tells you something about the um the
decoupling and the decouplerability of
these types of aspects of human psyche
and that's part of the science of this
whole thing so these large language
models are you know days old

[25:15]
models are you know days old
in terms of this kind of leap that
they've taken and it'll be interesting
to do this kind of analysis on them of
contact of the separation of context
form and knowledge where exactly does
that happen yeah there's already sort of
initial investigations but it's very
hard to figure out where is there a

[25:31]
hard to figure out where is there a
particular uh parameter set of
parameters that are responsible for a
particular piece of knowledge or a
particular context or a particular style
speaking so with convolutional neural
networks interpretability had many good

[25:46]
networks interpretability had many good
advances because we can kind of
understand them there's a structure to
them there's a locality to them and we
can kind of understand the different
layers have different sort of ranges
that they're looking at so we can look
at activation features and basically see

[26:01]
at activation features and basically see
where you know where does that
correspond to
with large language models
it's perhaps a little more complicated
but I think it's still achievable in the
sense that we could kind of ask well
what kind of prompts does this generate
if I sort of drop out this part of the

[26:15]
if I sort of drop out this part of the
network then what happens and sort of
start getting at a language to even
describe these types of aspects of human
be behavioral psychology if you wish
from the spoken part in the language
part and the advantage of that is that

[26:31]
part and the advantage of that is that
it might actually teach us something
about humans as well like you you know
we might not have words to describe
these types of aspects right now but
when somebody speaks in a particular way
it might remind us of a friend that we
know from here or there there and if we

[26:45]
know from here or there there and if we
had better language for describing that
these Concepts might become more
apparent in our own human psyche and
then we might be able to encode them
better in machines themselves I mean
both probably you and I
would have certain interests with the

[27:00]
would have certain interests with the
base model would open Echo as the base
model which is before the the alignment
of the
reinforcement learning with human
feedback and and before the
AI safety based kind of censorship of

[27:15]
AI safety based kind of censorship of
the model
it would be fascinating to explore to
investigate the ways that the model can
generate hate speech
the kind of hate that humans are capable
of it would be fascinating or the kind
of uh of course like uh sexual language

[27:30]
of uh of course like uh sexual language
or the kind of romantic language or the
all kinds of ideologies can I get it to
be a communist can I get it to be a
fascist can I get it to be a capitalist
can I get it to be all these kinds of
things and see which parts get activated

[27:45]
things and see which parts get activated
or not because it would be fascinating
to sort of explore at the individual
mind level and at a societal level where
do these ideas
um take hold what is the fundamental
core of those ideas maybe the communism

[28:01]
core of those ideas maybe the communism
fascism capitalism democracy are all
actually connected by the fact that the
human heart the human mind is drawn to
ideology
to it's a centralizing idea and maybe we
need a neural network to remind us of
that I like the concept that the human

[28:16]
that I like the concept that the human
mind is somehow tied to ideology and I
think that goes back to the the
promptability of jcbt the fact that you
can kind of say well think in this
particular way now and the fact that
humans have infected words for

[28:30]
humans have infected words for
encapsulating these types of behaviors
and it's hard to know how much of that
is innate and how much of that was like
passed on from language to language
but basically if you look at the
evolution of language you can kind of
see how young are these words in the

[28:45]
see how young are these words in the
history of language Evolution that
describe these types of behaviors like
you know kindness and anger and jealousy
Etc
if these words are very similar from
language to language it might suggest
that they're very ancient if they're

[29:02]
that they're very ancient if they're
very different it might suggest that
this concept may have emerged
independently in each different language
and so forth so
looking at the phylogeny the history The

[29:15]
looking at the phylogeny the history The
evolutionary traces of language at the
same time as people moving around that
we can now Trace thanks to genetics
is a fascinating way of understanding
the human psyche and also understanding

[29:30]
the human psyche and also understanding
sort of how these types of behaviors
emerge
and to go back to your idea about
sort of exploring the system unfiltered
I mean in a ways the psychiatric
hospitals are filled of those be full of
those people so basically people whose

[29:46]
those people so basically people whose
mind is uncontrollable yes who have kind
of gone adrift in specific locations of
their psyche and I I do find this
fascinating basically
you know watching movies that are trying

[30:02]
you know watching movies that are trying
to capture the essence of troubled minds
I think is teaching us so much about our
everyday selves because many of us are
able to sort of control our minds and
are able to have somehow somehow hide

[30:16]
are able to have somehow somehow hide
these emotions and
but every time I see somebody who's
troubled I I see versions of myself
maybe not as extreme but I can sort of
empathize with these behaviors and

[30:30]
empathize with these behaviors and
you know I see bipolar I see
schizophrenia I see depression I see
autism I see so many different aspects
that we kind of have names for and
crystallize in specific individuals
and I think all of us have that all of
us have sort of just this

[30:45]
us have sort of just this
multi-dimensional brain and genetic
variations that push us in these
directions environmental exposures and
traumas that push us in these directions
environmental behaviors that are
reinforced by the kind of friends that

[31:00]
reinforced by the kind of friends that
we chose or friends that we were stuck
with because of the environments that we
grew up in so in a way a lot of these
types of
behaviors
are within the Vector span of every

[31:16]
are within the Vector span of every
human it's just that the magnitude of
those vectors is generally smaller for
most people
because they haven't inherited that
particular set of genetic variants or
because they haven't been exposed to
those environments basically or

[31:30]
those environments basically or
something about the mechanism of
reinforcement learning with human
feedback didn't quite work for them so
it's fascinating to think about that's
what we do we have this capacity to have
all these
psychiatric or behaviors associated with

[31:45]
psychiatric or behaviors associated with
psychiatric disorders but we through the
alignment process as we go through their
parents we kind of we know to suppress
them yeah we know the kind of control
every human that grows up in this in
this world spends several decades being

[32:01]
this world spends several decades being
shaped into place yeah and without that
you know maybe we would have the
unfiltered lgbt4
every baby is basically a raging
narcissist
not all of them not all of them believe

[32:15]
not all of them not all of them believe
it or not it's it's remarkable like I I
remember like watching my kids grow up
and again like yes part of their
personality stays the same but also in
different phases to their life they've
gone through these dramatically
different types of behaviors and you

[32:30]
different types of behaviors and you
know my daughter basically saying
you know basically one one kid saying oh
I want the bigger piece the other one's
saying oh everything must be exactly
equal and the third one saying I'm okay
yeah you know I might have to have the
smaller part don't worry about me even
in the early days in the early years of

[32:45]
in the early days in the early years of
developed yeah it's just extraordinary
to sort of see these dramatically
different like I mean my wife and I uh
you know are are very different from
each other but we also have you know six
million variants six million loci each
if you wish if you just look at common

[33:01]
if you wish if you just look at common
variants we also have a bunch of rare
variants that are inherited in more
mendelian fashion and now you have you
know an infinite positive number of
possibilities for each of the kids so
basically it's two to the Six Million
Just from the common variance and then

[33:15]
Just from the common variance and then
if you like layer in the the rare
variants so let me talk a little bit
about common variance and rare variants
so if you look at this common variance
they're generally weak effect because
selection selects against strong effect
variance so if something like has a big

[33:30]
variance so if something like has a big
risk for schizophrenia it won't rise to
high frequency so the ones that are
common are by definition by selection
only the ones that had relatively weak
effect and if all of the variants
associated with personality with
cognition and all aspects of human

[33:45]
cognition and all aspects of human
behavior where weak effect variants then
kid would basically be just averages of
their parents
if it was like thousands of loci just by
lower of large numbers the average of
two large numbers would be you know very

[34:00]
two large numbers would be you know very
robustly close to that middle
but what we see is that kids are
dramatically different from each other
so that basically means that in the
context of that common variation you
basically have rare variants that are
inherited in a more mendelian fashion
that basically then sort of govern

[34:15]
that basically then sort of govern
likely many different aspects of human
behavior human biology and human
psychology
and that's again like if you look at
sort of a person with schizophrenia
their identical twin

[34:31]
their identical twin
has only 50 chance of actually being
diagnosed with schizophrenia so that
basically means there's probably
developmental uh exposures environmental
exposures trauma all kinds of other
aspects that can shape that and if you
look at siblings for the common variance

[34:46]
look at siblings for the common variance
it kind of drops off exponentially as
you would expect with you know sharing
50 of your genome 25 of your genome you
know 12.5 of your genome Etc with more
and more distant cousins
but the fact that siblings can differ so

[35:00]
but the fact that siblings can differ so
much in their personalities that we
observe every day it can't all be
nurture basically you know we we've like
again as parents we we spend enormous
amount of energy trying to fix quote
unquote the nurture part trying to you
know get them to share get them to be

[35:15]
know get them to share get them to be
kind get them to be open get them to
trust each other like you know like
overcome the prisoner's dilemma uh of
you know if everyone fans from
themselves we're all going to live in a
horrible place but if we're a little
more altruistic then we're all going to

[35:30]
more altruistic then we're all going to
be in a better place and I think
it's not like we treat our kids
differently but but they're they're just
born differently so in a way as a
geneticist I have to admit that there's
only so much I can do with nurture that
nature definitely plays a big component

[35:45]
nature definitely plays a big component
the the selection of variants we have
the common variance and the rare
variants
what uh what can we say about the
landscape a possibility they create
if you can just Linger on that so the

[36:01]
if you can just Linger on that so the
selection of rare variants is divine how
how do we get the ones that we get is it
just
Laden in that giant evolutionary baggage
so I'm gonna talk about regression why

[36:16]
so I'm gonna talk about regression why
do we call it regression and
the concept of regression to the mean
the fact that when fighter pilots in a
dogfight did amazingly well they would
give them rewards and then the next time

[36:30]
give them rewards and then the next time
they're in dogfight they would do worse
so then you know the Navy basically
realized that wow this or at least
interpreted that as wow we're ruining
them by praising them and then they're
going to perform Wars the statistical
interpretation of that is regression of

[36:46]
interpretation of that is regression of
the mean the fact that you're an
extraordinary pilot you've been trained
in an extraordinary fashion
if that pushes your mean
further and further to extraordinary
achievement
and then in some dogfights you'll just

[37:02]
and then in some dogfights you'll just
do extraordinarily well
the probability that the next one will
be just as good is almost nil
because this is the peak of your
performance
and just by statistical odds the next
one will be another sample from the same

[37:16]
one will be another sample from the same
underlying distribution which is going
to be a little closer to the mean
so regression analysis takes its name
from this type of realization in the
statistical world now if you now take

[37:30]
statistical world now if you now take
um humans you basically have
people who have achieved extraordinary
achievements
uh Einstein for example
you know you would call him for example
the epitome of human intellect
does that mean that all of his children
and grandchildren will be extraordinary

[37:46]
and grandchildren will be extraordinary
geniuses
probably means that they're sampled from
the same underlying distribution
but he was probably a rare combination
of extremes in addition to these common
variants
so you can basically interpret your kids

[38:02]
so you can basically interpret your kids
variation for example as well of course
they're going to be some kind of sample
from the average of the parents with
some kind of deviation according to the
specific combination of rare varians
that they have that they have inherited

[38:15]
that they have that they have inherited
so you know given all that the you know
the possibilities are endless as to sort
of where you should be but you should
always interpret that with well it's
probably an alignment of nature
and nurture and the Nature has both a

[38:30]
and nurture and the Nature has both a
common variance that are acting kind of
like the law of large numbers and the
rare variants that are acting more in
the mendelian fashion and then you layer
in the nurture which again in everyday
action we make we shape our future
environment
but the genetics we inherit are shaping

[38:46]
but the genetics we inherit are shaping
the future environment
of not only us but also our children
so there's this weird nature nurture
interplay and self-reinforcement
where you're kind of shaping your own
environment but you're also shaping the

[39:00]
environment but you're also shaping the
environment of your kids and your kids
are going to be born in the context of
your environment that you've shaped but
also with a bag of genetic variants that
they have inherited
and there's just so much complexity
associated with that when we start

[39:15]
associated with that when we start
blaming something on nature it might
just be nurture
it might just be that well yes they
inherited the genes from the parents but
they also you know were shaped by the
same environment so it's very very hard
to untangle the two and you should also
always realize that nature can influence

[39:31]
always realize that nature can influence
nurture nurture can influence nature or
at least be correlated with and
predictive of and so on so forth so I
love thinking about that distribution
that you mentioned and here's where I
can be my usual ridiculous self
and uh

[39:45]
and uh
I sometimes think about that army of
sperm cells
however many hundreds of thousands there
are
and I kind of think of all the
possibilities there
because there's a lot of variation and
one gets to win

[40:01]
one gets to win
is that not a random one it's a totally
ridiculous way to think about no not at
all so I would say evolutionarily we are
a very slow evolving species basically
the generations of humans are a terrible

[40:15]
the generations of humans are a terrible
way to do selection what you need is
processes that allow you to do selection
in a smaller tighter Loop yeah and part
of what
if you look at our immune system for
example
it evolves at a much faster Pace than

[40:31]
it evolves at a much faster Pace than
humans evolve because there is actually
an evolutionary process that happens
within our immune cells as they're
dividing there's basically vdj
recombination that basically creates
this extraordinary wealth of antibodies

[40:46]
this extraordinary wealth of antibodies
and antigens against the the environment
and basically all these antibodies are
now recognizing of these antigens from
the environment and they
send signals back that cause these cells
that recognize the non-self to multiply

[41:02]
that recognize the non-self to multiply
so that basically means that even though
viruses evolve at millions of times
faster than we are
we can still have a component of
ourselves which is environmentally
facing which is sort of evolving at not

[41:15]
facing which is sort of evolving at not
the same scale but very rapid pace
sperm expresses perhaps the most
proteins of any cell in the body
and part of the thought is that this

[41:30]
and part of the thought is that this
might just be a way to check that the
sperm is intact in other words if you
waited until that human has a liver and
starts eating solid food and you know
sort of filtrates away

[41:45]
sort of filtrates away
you know uh or or kidneys or stomach Etc
basically if you waited until these
mutations you know manifest late late in
life then you would end up not failing
fast and you would end up with a lot of
failed pregnancies and a lot of later

[42:00]
failed pregnancies and a lot of later
onset you know psychiatric illnesses Etc
If instead you basically Express all of
these genes at the sperm level and if
they misform they basically cause the
sperm to then you have at least
on the male side the ability to exclude
some of those mutations and on the

[42:16]
some of those mutations and on the
female side as the egg develops
there's probably a similar uh process
where you could you could sort of weed
out eggs that are just not you know
carrying beneficial mutations or at
least that are carrying highly

[42:30]
least that are carrying highly
detrimentations so you can basically
think of the evolutionary process in a
nested Loop basically where there's an
inner loop where you get many many more
iterations to to run and then there's an
outer loop that moves at a much slower
pace

[42:45]
pace
and going back to uh uh the next step of
evolution of possibly designing systems
that we can use to sort of complement
our own biology or to sort of eradicate
disease and you name it or at least
mitigate some of the I don't know

[43:02]
mitigate some of the I don't know
psychiatric illnesses neurodegenerative
disorders Etc
you can basically and also you know
metabolic immune cancer you name it
simply engineering these mutations from
rational design

[43:16]
rational design
might be very inefficient If instead you
have an evolutionary Loop where you're
kind of growing neurons on a dish and
you're exploring evolutionary space and
you're sort of shaping that one protein
to be better adapt that sort of I don't
know recognizing light or permutating

[43:30]
know recognizing light or permutating
with other neurons Etc you can basically
have a smaller evolutionary Loop that
you can run thousands of times faster
than the speed it would take to evolve
humans for another million years so I
think it's important to think about sort
of this evolvability

[43:45]
of this evolvability
as a set of nested structures that allow
you to sort of test many more
combinations but in a more thick setting
yeah that's fascinating the the
mechanism there is uh for sperm to
express proteins to create a testing
ground early on

[44:00]
ground early on
uh so that the
the failed designs don't make it yeah I
mean in design of Engineering Systems
fail fast is one of the principles you
learn like basically you assert
something why do you assert that because
if that something ain't right you better

[44:15]
if that something ain't right you better
crash now then sort of let it cross at
an unexpected time
and in a way you can think of it as like
20 000 assert functions assert protein
can fold assert protein can fold and if
any of them fail that's perm is gone
well I just like the fact that I'm the
winning sperm and the results of the

[44:31]
winning sperm and the results of the
winner winning hashtag winning my wife
always plays me this French song that
actually sings about that it's like you
know remember in life we were all the
first one time
so these once at least one time you were

[44:47]
so these once at least one time you were
the first I should mention it's just a
brief tangent back to the place where we
came from which is the base model that I
mentioned for openai which is before the
reinforcement learning with human
feedback
and you kind of give this metaphor of it
being kind of like a psychiatric

[45:01]
being kind of like a psychiatric
hospital I like that because it's
basically all of these different angles
at once like you basically have the more
extreme versions of human psyche so the
interesting thing is
well I've talked with folks in open AI

[45:15]
well I've talked with folks in open AI
quite a lot and they say it's extremely
difficult to work with that model yeah
kind of like it's extremely difficult to
work with some humans the parallels
there are very interesting because once
you run the alignment process it's much
easier to interact with it but it makes
you wonder what the capacity with the

[45:31]
you wonder what the capacity with the
underlying capability of the human
psychias as in the same way that what is
the underlying capability of a large
language model and remember earlier when
I was basically saying that
um part of the reason why it's so prompt
malleable is because of that alignment

[45:46]
malleable is because of that alignment
problem that alignment work it's kind of
nice that the engineers at open AI have
the same interpretation that you know in
fact it is that and
um these whole concept of easier to work
with

[46:01]
with
um
I wish that we could work with more
diverse humans
in a way
and and sort of that's one of the
possibilities that I see with the Advent

[46:15]
possibilities that I see with the Advent
of these large language models the fact
that
it gives us the chance to both dial down
friends of ours that we can't interpret
or that are just too edgy to sort of
really truly interact with where you

[46:30]
really truly interact with where you
could have a real-time translator
just the same way that you can translate
English to Japanese or Chinese or Korean
by like real-time adaptation you could
basically suddenly have a conversation
with your favorite extremist on either

[46:46]
with your favorite extremist on either
side of the spectrum and just dial them
down a little bit
of course not you and I but uh you could
have friends that are who's a complete
uh but it's a different base

[47:00]
uh but it's a different base
level so you can actually tune it down
to like okay they're not actually being
an there this is uh they're
actually expressing love right now it's
just that this is a they have their way
of of doing that and they probably live
in New York uh if we're just to pick a
random location so so yeah so you can

[47:16]
random location so so yeah so you can
basically layer out contexts you can
basically say oh let me change New York
to Texas and let me change you know uh
extreme left extreme right or somewhere
in the middle or something and
um I also like the concept of being able

[47:30]
um I also like the concept of being able
to
um
listen to the information without being
dissuaded by the emotions in other words
everything humans say has an intonation
has some kind of background that they're

[47:46]
has some kind of background that they're
coming from it reflects the way that
they're thinking of you reflects the
impression that they have of you and all
of these things are intertwined
but being able to disconnect them being
able to sort of

[48:00]
able to sort of
I mean self-improvement is one of the
things that I'm constantly working on
and being able to receive criticism
from people who really hate you is
difficult because it's layered in with

[48:15]
difficult because it's layered in with
that hatred but deep down there's
something that they say that actually
makes sense or people who love you might
layer it in a way that doesn't come
through but if you're able to sort of
Disconnect that emotional component from
the sort of self-improvement

[48:30]
the sort of self-improvement
and basically when somebody says whoa
that was a bunch of did you
ever do the control this and this and
that you could just say oh thanks for
the very interesting presentation uh you
know I'm wondering what about that
control then suddenly you're like oh

[48:45]
control then suddenly you're like oh
yeah of course I'm gonna rather control
that's a great idea yeah instead of that
was a bunch of BS you're like ah you're
sort of hitting on the brakes and you're
trying to push back against of that so
any kind of criticism that comes after
that is very difficult to interpret in a

[49:00]
that is very difficult to interpret in a
positive way because it helps reinforce
the negative assessment of your work
when in fact if we disconnected the
technical component from the negative
assessment then
you're embracing the negative then
you're embracing the technical component

[49:15]
you're embracing the technical component
you're going to fix it whereas if it's
coupled with and if that thing is real
and I'm right about your mistake then
it's a it's a bunch of BS then suddenly
you're like you're gonna try to prove
that that mistake does not exist
yeah it's fascinating to like carry the

[49:31]
yeah it's fascinating to like carry the
information this is what you're
essentially able to do here is you carry
the information in the rich complexity
that information contains so it's not
actually dumbing it down in some way
exactly still expressing it but taking
off but you can die the the the the

[49:45]
off but you can die the the the the
emotional emotional side yeah which is
probably so powerful for the internet or
for social networks again when it comes
to understanding each other one like for
example I don't know what it's like to
go through life with a different skin
color

[50:00]
color
I don't know how people will perceive me
I don't know how people will respond to
me
we don't often have that experience
but in a virtual reality environment or
in a sort of AI interactive system you
could basically say okay now make me

[50:16]
could basically say okay now make me
Chinese or make me South African or make
me you know uh Nigerian
you can change the accent you can change
layers of
that contextual information and then see
how the information is interpreted and

[50:30]
how the information is interpreted and
you can re-hear yourself through a
different angle you can hear others you
can have others react to you from a
different package
and then hopefully we can sort of build
empathy by learning to disconnect all of

[50:45]
empathy by learning to disconnect all of
these social cues that we get from like
how a person is dressed you know if
they're wearing a hoodie or if they're
wearing a shirt or if they're wearing a
you know jacket you get very different
emotional responses that you know I wish

[51:01]
emotional responses that you know I wish
we could overcome as humans and perhaps
large language models and augmented
reality and deep fakes can kind of help
us overcome all that in what way do you
think
these large language models and the

[51:17]
these large language models and the
thing they give birth to in the AI space
will change this Human Experience The
Human Condition
the things we've talked across many
podcasts about that makes life so damn

[51:31]
podcasts about that makes life so damn
interesting and Rich
love fear fear of death all of it uh if
we could just begin kind of thinking
about how does it change
for the good and the bad The Human

[51:45]
for the good and the bad The Human
Condition
Human Society is extremely complicated
we have come from
a hunter-gatherer Society to an
agricultural and farming Society

[52:00]
agricultural and farming Society
where the goal of most professions was
to eat and to survive
and with the Advent of Agriculture the
ability to live together in societies
humans could suddenly be

[52:17]
valued for different skills
if you don't know how to hunt
but you're an amazing potterer then you
fit in society very well because you can
sort of make your pottery and you can
barter it for rabbits that somebody else

[52:32]
barter it for rabbits that somebody else
caught and the person who hunts the
rabbits
doesn't need to make Bots because you're
making all the parts and that
specialization of humans is what shaped
modern society
and with the Advent of currencies and

[52:47]
and with the Advent of currencies and
governments and you know credit cards
and Bitcoin you basically now have the
ability to exchange value for the kind
of productivity that you have so
basically I make things that are
desirable to others I can sell them and

[53:01]
desirable to others I can sell them and
buy back food shelter Etc
with AI
the concept of I am my profession
might need to be revised
because I defined my profession in the

[53:16]
because I defined my profession in the
first place I something that Humanity
needed that I was uniquely capable of
delivering but the moment we have ai
systems able to deliver
these goods for example writing a piece
of software or making a self-driving car

[53:31]
of software or making a self-driving car
or interpreting the human genome
then that frees up more of
human time for other Pursuits
this could be Pursuits that are still

[53:45]
this could be Pursuits that are still
valuable to society I could basically be
10 times more productive at interpreting
genomes and do a lot more
or I could basically say oh great the
interpreting genomes part of my job now
only takes me five percent of the time

[54:00]
only takes me five percent of the time
instead of 60 of the time
so now I can do more creative things I
can explore not new career options but
maybe new directions from my research
lab I can sort of be more productive
contribute more to society
and if you look at this giant

[54:16]
and if you look at this giant
pyramid that we have built on top of the
subsistence economy
what fraction of U.S jobs are going to
feeding all of the US less than two
percent

[54:31]
percent
basically the the gain in productivity
is such that 98 of the economy is beyond
just feeding ourselves and that
basically means that
we kind of have built these system of

[54:47]
we kind of have built these system of
interdependencies of needed or useful or
valued Goods that sort of make the
economy run that the vast majority of
wealth goes to other
what we now call needs but used to be
wants so basically I want to fly a drone

[55:01]
wants so basically I want to fly a drone
I want to buy a bicycle I want to buy a
nice car I want to have a nice home I
want to Etc so
and and then sort of what is my direct
contribution to my eating I mean I'm I'm
doing research on the human genome I

[55:15]
doing research on the human genome I
mean this will help humans it will help
all Humanity but how is that helping the
person who's giving me poultry or
vegetables so in a way I see AI as
perhaps leading to a dramatic rethinking
of human society

[55:30]
of human society
if you think about sort of the economy
being based on intellectual Goods that
I'm producing
what if AI can produce a lot of these
intellectual goods and satisfies that
need does that now free humans for more
artistic expression for more emotional

[55:46]
artistic expression for more emotional
maturing for
basically having a better work-life
balance being able to show up for your
two hours of work a day or two hours of
work like three times a week with like
immense rest and preparation and

[56:01]
immense rest and preparation and
exercise and you're sort of clearing
your mind and suddenly you have these
two amazingly creative hours you
basically show up at the office as your
AI is busy answering your phone call
making all your meetings you know
revising all your papers Etc and then
you show up for those creative hours and

[56:15]
you show up for those creative hours and
you're like all right autopilot I'm on
and then you can basically do so so much
more that you would perhaps otherwise
never get to because you're so
overwhelmed with these mundane aspects
of your of your job so I feel that AI
can truly transform The Human Condition

[56:31]
can truly transform The Human Condition
from realizing that
we don't have jobs anymore we now have
vocations
and there's this beautiful analogy of
three people laying bricks and somebody

[56:45]
three people laying bricks and somebody
comes over and asks the first one what
are you doing he's like oh I'm laying
bricks second one what are you doing I'm
building a wall
and the third one what are you doing I'm
building this beautiful cathedral
so in a way the first one has a job the
last one has a vocation

[57:00]
last one has a vocation
and if you ask me what are you doing oh
I'm editing a paper then I have a job
what are you doing
um understanding human disease circuitry
I have a vocation so in a way being able
to allow us to enjoy more of our
vocation
by taking away offloading some of the

[57:18]
by taking away offloading some of the
job part
of our daily activities so we all become
the the Builders of cathedrals correct
yeah and we follow intellectual Pursuits

[57:31]
yeah and we follow intellectual Pursuits
artistics Pursuits I wonder what how
that really changed at a scale of
several billion people
everybody playing in the space of ideas
and the space of creations
so ideas maybe for some of us maybe you

[57:47]
so ideas maybe for some of us maybe you
and I are in the job of ideas but other
people are in the job of experiences
other job other people in the the job of
emotions of dancing of creative artistic
expression of you know skydiving and you

[58:02]
expression of you know skydiving and you
name it so basically these
again the beauty of human diversity is
exactly that that what rocks my boat
might be very different from what rocks
other people's boat and what I'm trying

[58:16]
other people's boat and what I'm trying
to say is that maybe AI will allow
humans to truly
like not just look for but Find meaning
and sort of you don't need to work but
you need to keep your brain at ease and

[58:31]
you need to keep your brain at ease and
the way that your brain will be at ease
is by dancing and creating this amazing
you know movements or creating these
amazing paintings or creating I don't
know something that that sort of changes
that that touches at least one person
out there that sort of shapes Humanity

[58:46]
out there that sort of shapes Humanity
through that process
and instead of working your you know
mundane programming job where you like
hate your boss and you hate your job and
you say you hate that darn program Etc
you're like well I don't need that I can
you know offload that and I can now

[59:00]
you know offload that and I can now
explore something that will actually be
more beneficial to human to humanity
because the mundane Parts can be
offloaded I wonder if it localizes our
uh all the things you've mentioned all
the vocations so you mentioned that you

[59:16]
the vocations so you mentioned that you
and I might be playing in the space of
ideas but there's two ways to play in
this piece of ideas both of which we're
currently engaging and so one is the
communication of that to other people it
could be a classroom full of students
but it could be a podcast it could be

[59:30]
but it could be a podcast it could be
something that's uh that's shown on
YouTube and so on or it could be just
the act of sitting alone and playing
with ideas in your head or maybe with a
loved one having a conversation that
nobody gets to see the experience of

[59:45]
nobody gets to see the experience of
just sort of looking up at the sky and
wondering uh different things maybe
quoting some philosophers from the past
and playing with those little ideas and
that little exchange is forgotten
forever but you got to experience it and
maybe
I wonder if it localizes that exchange

[1:00:02]
I wonder if it localizes that exchange
of ideas for that with AI it'll become
less and less valuable to communicate
with a large group of people that you
will live life intimately and and richly
just with that Circle of meat bags that

[1:00:17]
just with that Circle of meat bags that
you seem to love
so the first is even if you're alone in
a forest having this amazing thought
when you exit that Forest the baggage
that you carry has been shifted has been

[1:00:30]
that you carry has been shifted has been
altered by that thought
when I bike to work in the morning I
listen to books
and I'm alone no one else is there I'm
having that experience by myself and yet
in the evening when I speak with someone

[1:00:46]
in the evening when I speak with someone
an idea that was formed there could come
back
sometimes when I fall asleep I fall
asleep listening to a book and in the
morning I'll be full of ideas that I
never even process consciously I'll
process them unconsciously and they will

[1:01:00]
process them unconsciously and they will
shape that baggage that I carry that
will then shape my interactions and
again affect ultimately all of humanity
in some Butterfly Effect by Newt kind of
way
so that's one aspect
the second aspect is

[1:01:16]
the second aspect is
Gatherings so basically you and I are
having a conversation
which feels very private but we're
sharing with the world
and then later tonight you're coming
over and we're having a conversation
that will be very public with dozens of

[1:01:30]
that will be very public with dozens of
other people but we will not share with
the world yeah
so in a way which one's more private the
one here or the one there here there's
just two of us but a lot of others
listening there a lot of people speaking
and thinking together and bouncing off

[1:01:45]
and thinking together and bouncing off
each other and maybe that will then
impact your millions of you know uh
audience
through your next conversation and
I think that's part of the beauty of
humanity the fact that no matter how

[1:02:00]
humanity the fact that no matter how
small how alone how broadcast
immediately or later on something is
it still percolates through the human
psyche
human gatherings
all throughout human history there's

[1:02:15]
all throughout human history there's
been gatherings
I wonder how those Gatherings have
impacted the direction of human
civilization it's just uh thinking of
in the early days of the Nazi party
it was a small collection of people
Gathering

[1:02:30]
Gathering
and the uh the kernel of an idea in that
case an evil idea
I gave birth to something that actually
had a transformative impact on all the
human civilization and then there's a
similar kind of gatherings that lead to
positive transformations

[1:02:46]
positive transformations
um this is probably a good moment to ask
you on a bit of a tangent but you
mentioned it you put together salons
with um Gatherings small human
Gatherings with uh folks from MIT
Harvard here in Boston friends

[1:03:01]
Harvard here in Boston friends
colleagues what's your vision behind
that
so
it's not just MIT people it's not just
Harvard people we have artists we have
musicians we have painters we have
dancers we have you know
cinematographers we have so many

[1:03:16]
cinematographers we have so many
different diverse folks
and the goal is exactly that celebrate
Humanity what what is humanity humanity
is the all of us it's not the any one

[1:03:30]
is the all of us it's not the any one
subset of us and we live in such an
amazing extraordinary moment in time
where you can sort of bring people from
such diverse professions all living
under the same city you know we live in
an extraordinary City where you can have
extraordinary people who have gathered

[1:03:46]
extraordinary people who have gathered
him from all over the world
so my father grew up in a village in an
island in Greece that didn't even have a
high school
to go get a high school education he had
to move away from his home my mother
grew up in another small island in

[1:04:01]
grew up in another small island in
Greece
they did not have this environment that
I am now creating for my children
my parents were not academics they
didn't have these gatherings

[1:04:15]
didn't have these gatherings
so I feel that
like I feel so privileged as an
immigrant to basically be able to offer
to my children the nurture that my
ancestors did not have
so Greece was under Turkish occupation

[1:04:31]
so Greece was under Turkish occupation
until 1821 my dad's Island was
liberating in 1920.
so like they they were under Turkish
occupation for hundreds of years these
people did not know what it's like to be
Greek let alone go to an elite

[1:04:47]
Greek let alone go to an elite
University or you know be surrounded by
by these extraordinary humans so
the way that I'm thinking about these
gatherings is that I'm
I'm shaping my own environment and I'm
shaping the environment that my children

[1:05:01]
shaping the environment that my children
get to grow up in so I can give them all
my love I can give them all my parenting
but I can also give them an environment
as immigrants that sort of we feel
welcome here that I mean my wife grew up
in a farm in rural France her father was

[1:05:17]
in a farm in rural France her father was
a farmer her mother was a school teacher
like for me and for my wife to be able
to host this extraordinary individuals
that we feel so privileged so humbled by
is amazing and and you know

[1:05:30]
is amazing and and you know
um
I I think it's celebrating
the welcoming nature of America the fact
that it doesn't matter where you grew up
and many many of our friends at these
gatherings are immigrants themselves I

[1:05:45]
gatherings are immigrants themselves I
grew up in Pakistan in you know all
kinds of places around the world that
are now able to sort of gather in one
roof as human to human no one is judging
you for your background for the color of
your skin for your profession it's just
everyone gets to raise their hands and

[1:06:00]
everyone gets to raise their hands and
ask ideas so celebration of humanity and
and a kind of gratitude for having
traveled uh quite a long way to get here
and if you look at the diversity of
topics as well I mean we had a school
teacher present on teaching immigrants a

[1:06:16]
teacher present on teaching immigrants a
book called making Americans we had a
presidential advisor to four different
presidents you know come and you know
talk about the changing of U.S politics
we had a

[1:06:30]
we had a
musician a composer
from Italy who lives in Australia come
and present his latest piece and
fundraise we had painters come and sort
of show their art and talk about it
we've had authors of books on leadership

[1:06:47]
we've had authors of books on leadership
you know intellectuals like
um Stephen Pinker and
um it's just extraordinary the breath
and the the this crowd basically loves

[1:07:00]
and the the this crowd basically loves
not just the diversity of of the
audience but also the diversity of the
topics and the last few were with Scott
Aaronson on AI and uh you know alignment
and all of that so A bunch of beautiful
weirdos exact and beautiful human beings

[1:07:17]
weirdos exact and beautiful human beings
and just like you said basically every
human is a kind of outcast uh in this
sparse distribution far away from the
center but it's not recorded

[1:07:32]
in this world that seeks to record so
much
uh it's it's it's powerful to get so
many interesting humans together and not
and not record it's not recorded but it
percolates

[1:07:46]
percolates
it's recorded in the minds of these it
shapes everyone's mind
so allow me to please return to The
Human Condition and uh one of the nice
features of the human condition is love
do you think humans will fall in love

[1:08:02]
do you think humans will fall in love
with AI systems and maybe they with us
so that aspect of the Human Condition do
you think that will be affected
so in Greece there's many many words for
love

[1:08:15]
love
and some of them mean friendship some of
them mean passionate love some of them
mean fraternal love
Etc so um I think AI doesn't have the
baggage that we do
and it doesn't have you know all of the

[1:08:32]
and it doesn't have you know all of the
subcortical regions that we kind of you
know started with before we evolved all
of the cognitive aspects so I would say
AI is Faking it when it comes to love
but when it comes to Friendship

[1:08:46]
but when it comes to Friendship
when it comes to being able to be your
therapist your coach
your motivator someone who synthesizes
stuff for you who writes for you who
interprets a complex passage who
compacts down a very long lecture or a

[1:09:00]
compacts down a very long lecture or a
very long text
I think that
friendship will definitely be there like
the fact that I can have my companion my
partner my AI who has grown to know me
well and that I can trust with all of

[1:09:15]
well and that I can trust with all of
the darkest parts of myself all of my
flaws all of the stuff that I I only
talk about to my friends and basically
say listen you know here's all this
stuff that I'm struggling with
someone who will not judge me who will
always be there to better me

[1:09:32]
always be there to better me
in in some ways not having the baggage
might make for your best friend for your
you know your confidante
uh that that can truly help reshape you
so I do believe that human AI

[1:09:46]
so I do believe that human AI
relationships will absolutely be there
but not the passion more the mentoring
well that's a really interesting thought
to play Devil's Advocate
if those AI systems are locked in

[1:10:03]
if those AI systems are locked in
in faking the baggage
who are you to say that the AI systems
that begs you
not to leave it or it doesn't love you
who are you to say that this AI system

[1:10:15]
who are you to say that this AI system
that writes poetry to you that is afraid
of death afraid of life without you
um or vice versa one you know creates
the kind of drama that humans create the
the power dynamics that can exist in a

[1:10:30]
the power dynamics that can exist in a
relationship what AI system that is one
abusive one day and romantic the other
day all the different variations of
relationships and it's consistently that
it holds the full richness of a
particular personality why is that not a

[1:10:46]
particular personality why is that not a
system you can love in a romantic way
why is it faking it if it sure as hell
seems real there's many answers to this
the first is it's only the eye of the
beholder who tells me that I'm not
faking it either maybe all of these
subcortical systems that make me sort of

[1:11:02]
subcortical systems that make me sort of
have different emotions
maybe they don't really matter maybe all
that matters is the neocortex and that's
where all of my emotions are encoded and
the rest is just you know bells and
whistles

[1:11:15]
whistles
um that's one possibility
and and therefore
you know who am I to judge that is
Faking it when maybe I'm faking it as
well
the second is neither of us is Faking it
maybe it's just an emergent behavior all
these neocortical systems that

[1:11:32]
these neocortical systems that
is truly capturing the same exact
essence of love and hatred and
dependency and sort of you know reverse
psychology and

[1:11:45]
psychology and
um
that that that we have so it is possible
that it's simply an emerging behavior
and that we don't have to encode these
additional architectures that all we
need is more parameters and some of
these parameters can be all of the
personality traits

[1:12:01]
personality traits
a third option is that just by telling
me oh look now I've built an emotion
component to AI it has a limbic system
and it has a laser brain Etc
and suddenly I'll say oh cool it has the

[1:12:16]
and suddenly I'll say oh cool it has the
capability of emotion so now when it
exhibits the exact same unchanged
behaviors that it does without it
I as the beholder will be able to sort
of attribute to it emotional attributes

[1:12:30]
of attribute to it emotional attributes
that I would to another human being and
therefore have that mental model of that
other person so again I think a lot of
relationships is about the mental models
that you project
on the other person

[1:12:45]
on the other person
and that they're projecting on you
and um
then yeah then in that respect I do
think that
even without the embodied intelligence
part without having ever experienced

[1:13:00]
part without having ever experienced
what it's like to be heartbroken the
sort of cultural feeling of misery
um that that system you know I could
still attribute it
traits of human

[1:13:16]
traits of human
feelings and emotions and in the
interaction with that system something
like love emerges so it's possible that
love is not a thing that exists in your
mind but a thing that exists in the uh
interaction of the different mental

[1:13:31]
interaction of the different mental
models you have of other people's minds
or other person's mind and so
it you know it doesn't as long as one of
the entities let's just take the easy
case one of the entities is human and
the other is AI

[1:13:45]
the other is AI
it feels very natural that from the
perspective of at least the human there
is a real love there
and then the question is how does that
transform Human Society if it's possible
that which I believe will be the case
I don't know what to make of it but I

[1:14:01]
I don't know what to make of it but I
believe that'll be the case where
there's
hundreds of millions of romantic
Partnerships between humans and AIS
what does that mean for society if you
look at longevity and if you look at

[1:14:15]
look at longevity and if you look at
happiness and if you look at late life
you know well-being
the love of another human
is one of the strongest indicators of
Health into long life
and I have many many countless stories

[1:14:32]
and I have many many countless stories
where as soon as the Romantic partner of
60 plus years of a person dies within
three four months the other person dies
just like losing their love I think the
concept of being able to satisfy that

[1:14:45]
concept of being able to satisfy that
emotional need that humans have even
just as a mental health
sort of service
uh to me you know that's that's a very
good Society
it doesn't matter if your love is wasted
quote unquote on a machine

[1:15:01]
quote unquote on a machine
it is you know the placebo if you wish
that makes the patient better anyway
like there's nothing behind it but just
the feeling that you're being loved will
probably engender all of the emotional
attributes of that

[1:15:15]
attributes of that
the other story that I want to say in
this whole concept of Faking It
and maybe I'm a terrible dad but I was
asking my kids I was asking my my kids
I'm like
it doesn't matter if I'm a good dad or
does it matter if I act like a good dad

[1:15:32]
does it matter if I act like a good dad
in other words if I give you love and
shelter and kindness and warmth and all
of the above
you know does it matter that I'm a good
dad conversely if I deep down love you

[1:15:46]
dad conversely if I deep down love you
to the end of Eternity but I'm always
gone yeah
which which dad would you rather have
the cold ruthless killer that will show
you only love and warmth and nourish you
and nurture you

[1:16:00]
and nurture you
or the amazingly warm-hearted but works
five jobs and you never see them
and what's the answer I mean I
think from I think you're a romantic so
you say it matters what's on the inside
but pragmatically speaking why does it

[1:16:16]
but pragmatically speaking why does it
matter the fact that I'm even asking the
asking the question basically says it's
not enough to love my kids I better
freaking be there to show them that I'm
there
so basically of course you know
everyone's a good guy in their story
yeah so in my story I'm a good dad

[1:16:31]
yeah so in my story I'm a good dad
but if I'm not there it's wasted so the
reason why I asked the question is for
me to say
you know does it really matter that I
love them if I'm not there to show it
but it's also possible that what reality

[1:16:46]
but it's also possible that what reality
is is the you showing it that what you
feel on the inside is
is little narratives and games you play
inside your mind it doesn't really
matter that the thing that truly matters
is how you act and in that

[1:17:01]
is how you act and in that
AI systems can quote unquote fake yeah
and that if it's all that matters is
actually real but not fake yeah yeah
again let there be no doubt I love my
kids to Pieces but you know my My worry

[1:17:15]
kids to Pieces but you know my My worry
is am I being a good enough Dad yeah and
what does that mean like if I'm only
there to do their homework and make sure
that they you know do all the stuff but
I don't show it to them then you know
might as well be a terrible dad
but I agree with you that like if the AI

[1:17:31]
but I agree with you that like if the AI
system can basically play the role of a
father figure
for many children that don't have one or
you know the role of parents or the role
of siblings
if a child grows up alone
maybe their emotional state will be very

[1:17:47]
maybe their emotional state will be very
different than if they grow up with an
AI sibling well let me ask I mean this
is for for you for your kids for just
loved ones in general let's let's go to
like the trivial case
of just texting back and forth

[1:18:02]
of just texting back and forth
what if we create a large language Model
fine-tune A manolus
and
while you're at work it'll replace
every once in a while you just activate
the auto manolus

[1:18:15]
the auto manolus
you know text them exactly in your way
is that is that cheating I can't wait
I mean it's the same guy I cannot wait
seriously like but wait wouldn't that
have a big impact on you emotionally

[1:18:31]
have a big impact on you emotionally
because now I'm replaceable I love that
no seriously I would love that I would
love to be replaced I would love to be
replaceable I would love to have a
digital twin that you know we don't have
to wait for me to to die or to disappear

[1:18:46]
to wait for me to to die or to disappear
in a plane crash or something
um to to replace me like I'd love that
model to be constantly learning
constantly evolving adapting with every
one of my changing growing self uh as

[1:19:00]
one of my changing growing self uh as
I'm growing I want that AI to grow and I
think this will be extraordinary number
one when I'm you know giving advice
being able to be there for more than one
person you know why does someone need to
be at MIT to get advice from me like you

[1:19:17]
be at MIT to get advice from me like you
know people in India could download it
and you know so many so many students
contact me from across the world who
want to come and spend a summer with me
I wish they could do that
all of them like you know we we don't
have room for all of them but I wish I

[1:19:30]
have room for all of them but I wish I
could do that to all of them and
um that that aspect is the
democratization of of relationships I
think that that is extremely beneficial
the other aspect is I want to interact

[1:19:45]
the other aspect is I want to interact
with that system I want to look inside
the hood I want to sort of evaluate it I
want to basically see if when I see it
from the outside the emotional
parameters are off or the cognitive
parameters are off or the set of ideas
that I'm giving are not quite right

[1:20:01]
that I'm giving are not quite right
anymore I want to see how that system
evolves I want to see the impact of
exercise or sleep on sort of my own
cognitive system I want to be able to
sort of
decompose my own behavior in a set of
parameters that can evaluate and look at

[1:20:15]
parameters that can evaluate and look at
my own personal growth I can sort of I'd
love to sort of at the end of the day
have my model say well you know you
didn't quite do well today like you know
you you weren't quite there and sort of
grow from that experience and I I think
the concept of basically being able to

[1:20:31]
the concept of basically being able to
become more aware of our own
personalities become more aware of our
own identities maybe even interact with
ourselves and sort of hear how we are
being perceived
I think would be immensely helpful in

[1:20:45]
I think would be immensely helpful in
self-growth in self-actualization
self-aducation
the experiments I would do on that thing
because one of the challenges of course
is you might not like what you see
in your interaction and you might say

[1:21:00]
in your interaction and you might say
well this the model is not accurate but
then you have to should probably
consider the possibility that the model
is accurate and that there's actually
flaws in your mind I would definitely
prod and see how many biases I have with
different kinds I don't know and I would

[1:21:15]
different kinds I don't know and I would
of course go to the extremes I would go
like um how jealous can I make this
thing like what what at which stages
does it get super jealous you know or at
which stages does it get angry kind of
like provoke it can I get it like yeah

[1:21:31]
like provoke it can I get it like yeah
but not only triggers can I get it to go
like lose its mind like go completely
nuts just don't exercise for a few days
that's basically it yes I mean that
that's that's an interesting way to prod

[1:21:46]
that's that's an interesting way to prod
yourself almost like a a self therapy
session and and the beauty of such a
model is that if I am replaceable if the
parts that I currently do are
replaceable
that's amazing because it frees me up to

[1:22:01]
that's amazing because it frees me up to
work on other parts that I don't
currently have time to develop
maybe all I'm doing is giving the same
advice over and over and over again like
just let my AI do that and I can work on
the next stage and the next stage and
the next stage so I think in terms of
freeing up like

[1:22:17]
freeing up like
they say a programmer someone who cannot
do the same thing twice so it's not the
second time you write a program to do it
and I wish I could do that for my own
existence I could just like you know
figure out things keep improving
improving improving and once I've nailed

[1:22:30]
improving improving and once I've nailed
it let the AI loose on that and maybe
even let the AI better it better than I
could have but doesn't the concept of
you said me and I can work on new things
but doesn't that uh break down because

[1:22:45]
but doesn't that uh break down because
you said digital twin but there's no
reason it can't be
millions of digital monolysis
aren't you lost in the sea of manosis
the original uh is hardly the original

[1:23:00]
the original uh is hardly the original
it's just one of millions I
I want to have the room to grow
maybe the new version of me that that
that the actual me will get slightly
worse sometimes slightly better other
times when it gets slightly better I'd

[1:23:15]
times when it gets slightly better I'd
like to emulate that and have a much
higher standard to meet and keep going
but does it make you sad that your loved
ones
the physical real loved ones might kind
of like start cheating on you with the

[1:23:30]
of like start cheating on you with the
other minosis I I want to be there 100
of them for each of them
so I I have zero perks or zero zero
quirms about me being physically me like
zero jealousy wait a minute but is isn't

[1:23:45]
zero jealousy wait a minute but is isn't
that like
don't we hold on to that isn't that why
we're afraid of death we don't want to
lose this thing we have going on isn't
that an ego death when there's a bunch
of other minerals you get to look at
them they're not you they're just very
good copies of you they get to live a

[1:24:02]
good copies of you they get to live a
life
the I mean it's fear of missing out it's
fomo they get to have interactions all
right and you don't get to have those
interactions there's two aspects of
every person's life there's what you

[1:24:16]
every person's life there's what you
give to others and there's what you
experience yourself yeah
life truly ends when you experiencing
ends
but the others experiencing you doesn't

[1:24:30]
but the others experiencing you doesn't
need to end
but your experience you could still I
guess you're saying the digital twin
does not limit your ability to truly the
experience to experience as a human
being the the the the downside is when

[1:24:47]
being the the the the downside is when
you know my wife or my kids will have a
really emotional interaction with my
digital twin and I won't know about it
so I will show up and they now have the
baggage but I don't
so basically what makes interactions

[1:25:01]
so basically what makes interactions
between humans unique in this sharing
and exchanging kind of way is the fact
that we are both shaped by every one of
our interactions I think the model of
the digital twin works for dissemination
of knowledge of advice
Etc where you know I want to have wise

[1:25:17]
Etc where you know I want to have wise
people give me advice across history I
want to have chat with Gandhi but Gandhi
will necessarily learn from me
but I will learn from him so in a way

[1:25:30]
but I will learn from him so in a way
you know the dissemination and the
democratization rather than the building
of relationships so the the emotional
aspect is that there should be an alert
when the AI system is interacting with
your loved ones and all of a sudden it
starts getting like
emotionally fulfilling like a magical

[1:25:47]
emotionally fulfilling like a magical
moment there should be okay stop AI
system like freezes there's an alert on
your phone you need to take over yeah
yeah I take over and then whoever I was
speaking with I can have the the AI or
like one of the AIS this is such a

[1:26:00]
like one of the AIS this is such a
tricky thing to get right I mean it's
still I mean there's go
uh this is going to go wrong in so many
interesting ways that we're gonna have
to learn as a society yeah yeah that in
the process of trying to automate our
tasks and having a digital twin

[1:26:15]
tasks and having a digital twin
you know for me personally if I could
have a relatively good copy of myself
uh I would set it to start answering
emails but I would start it set it to
start tweeting I would like to replace
it gets better what if that one is
actually way better than you yeah

[1:26:31]
actually way better than you yeah
exactly and then you're like uh well I
wouldn't want that because why
because then I would never be able to
live up to like what if the people that
love me start loving that thing and then
I'm I will always I already fall short

[1:26:46]
I'm I will always I already fall short
I'll be falling short even more so
listen I'm a professor the stuff that I
give to the world is the stuff that I
teach but most much more importantly
sorry number one the stuff that I teach
number two the discoveries that we make
in my research group but much more

[1:27:01]
in my research group but much more
importantly the people that I train
they are now out there in the world
teaching others
if you look at my own trainees they are
extraordinarily successful professors
so anshul kundanji at Stanford Alex

[1:27:16]
so anshul kundanji at Stanford Alex
Stark at Imp in Vienna Jason Ernst at
UCLA Andreas Fanning at CMU
each of them I'm like wow they're better
than I am
and I love that
so maybe your role
will be to train better versions of

[1:27:31]
will be to train better versions of
yourself
and they will be your legacy not you
doing everything but you training much
better version of Lex Friedman than you
are
and then they go off to do their mission
which is in many ways what this

[1:27:45]
which is in many ways what this
mentorship model of Academia does but
the legacy is ephemeral it doesn't
really live anywhere the Legacy it's not
like written somewhere it just lives
through them but you can continue
improving and you can continue making
even better versions of you

[1:28:00]
even better versions of you
yeah but they'll do better than me and
that's creating new version it's awesome
but it's
um
you know there's a ego that says there's
a value to an individual and it feels
like this process decreases the value of

[1:28:16]
like this process decreases the value of
the individual this meat bag
all right if there's good digital copies
of people then uh there's more
flourishing of human thought and ideas
and experiences but there's less value
to the individual human I I don't have

[1:28:31]
to the individual human I I don't have
any such limitations I I basically I
don't I don't have that feeling at all
like I remember one of our interviews I
was basically saying you know the
meaning of life you had asked me and I
was like I came back and I was like I
felt useful today
and I was at my maximum I was I was you

[1:28:47]
and I was at my maximum I was I was you
know
like a hundred percent and I gave good
ideas and I was a good person with a
good advisor with a good husband a good
father that was a great day because it
was useful and if I can be useful to
more people by having digital twin I

[1:29:01]
more people by having digital twin I
will be liberated
because my urge to be useful
will will be satisfied
it doesn't matter whether it's direct me
or indirect me whether it's my students
that I've trained my AI that I've

[1:29:15]
that I've trained my AI that I've
trained
I think there's a there's a sense that
my mission in life is being accomplished
and I can work on my self-growth
I mean that's a very Zen State that's
why people love you it's the same state
you've achieved but do you think most of

[1:29:31]
you've achieved but do you think most of
humanity will be able to achieve that
kind of thing is the people people
really hold on to the value of Their Own
ego that's it's not just being useful
being useful is nice as long as it
builds up this reputation and that meat

[1:29:46]
builds up this reputation and that meat
bag is known as being useful therefore
has more value right people really don't
want to let go of that ego thing I I one
of the books that I reprogram my brain
with at night was called uh ego is the
enemy it goes in the atom he goes the
enemy and basically being able to just

[1:30:01]
enemy and basically being able to just
let go like
uh my advisor used to say you can
accomplish anything
as long as you don't seek to get credit
for it
that's beautiful to hear especially from
a person who's existing in Academia

[1:30:15]
a person who's existing in Academia
you're right the Legacy lives through
the people you manage the actions it's
the outcome
uh what about the fear of death how does
this change it
again to me death is when I stop
experiencing
and I never wanted to stop I want I want

[1:30:32]
and I never wanted to stop I want I want
to live forever
as I said last time every day the same
day forever or one day every 10 years
forever any of the Forevers I'll take it
so you want to keep getting the
experiences in your experience gosh it

[1:30:46]
experiences in your experience gosh it
is it is so fulfilling just the
self-growth the learning the growing the
uh comprehending
it's it's addictive it's a drug just a
drug of intellectual stimulation the

[1:31:01]
drug of intellectual stimulation the
drug of growth the drug of knowledge
it's a drug
but then there'll be thousands or
millions minosas that live on after your
biological system is no longer more
power to them

[1:31:18]
hey do you think that in quite
realistically it does mean that
interesting people such as yourself live
on
in the uh
you know if I can interact with the fake

[1:31:30]
you know if I can interact with the fake
manolas those interactions live on in my
mind
so that makes sense about 10 years ago I
started recording every single meeting
that I had every single meeting we just
start either the voice recorder at the
time or now a zoom meeting and I record

[1:31:46]
time or now a zoom meeting and I record
my students record every single one of
our conversations recorded
I always joke that like the ultimate
goal is to create virtual me and just
get rid of me basically not get rid of
it like don't have the need for me

[1:32:00]
it like don't have the need for me
anymore yeah another goal is to be able
to go back and say how have I changed
from five years ago was I different was
I giving you know advice in a different
way was it giving different types of
advice has My Philosophy about how to

[1:32:16]
advice has My Philosophy about how to
write papers or how to present data or
anything like that changed and
I you know
in in Academia and in mentoring a lot of
the interaction is my knowledge and my
perception of the world goes to my

[1:32:30]
perception of the world goes to my
students but a lot of it is also in the
opposite direction like the other day I
had a conversation with my one of my
postdocs and I was like hmm I think you
know let me give you an advice you could
you could do this and then she said well
I've thought about it and then I've

[1:32:47]
I've thought about it and then I've
decided to do that instead and we talked
about it for a few minutes and then at
the end I'm like you know I've just
grown a little bit today thank you like
she convinced me that my advice was
incorrect she could have just said yeah

[1:33:00]
incorrect she could have just said yeah
it sounds great and just not do it yeah
but
by
constantly teaching my students and
teaching my mentees that I'm here to
grow
she felt empowered to say here's my
reasons why I will not follow that

[1:33:16]
reasons why I will not follow that
advice
and again part of me growing is saying
whoa I just understood your reasons I
think I was wrong
and now I've grown from it
and that's what I want to do that as you
know I want to constantly keep growing

[1:33:30]
know I want to constantly keep growing
in this sort of bi-directional advice I
wonder if you can capture the trajectory
of that to where the AI could also uh
map forward project forward the
trajectory
after you're no longer there how the

[1:33:45]
after you're no longer there how the
different ways you might evolve so again
we're discussing a lot about these large
language models and we're sort of
projecting these cognitive states of
ourselves on them but I think on the AI
front a lot more needs to happen so
basically right now it's these language

[1:34:00]
basically right now it's these language
models and we believe that within their
parameters we're encoding these types of
things and you know in some aspects it
might be true it might be truly emergent
intelligence that's coming out of that
in other aspects I think we have a ways
to go so basically to make all of these

[1:34:15]
to go so basically to make all of these
dreams that we're sort of discussing
come come reality
we basically need a lot more reasoning
components
a lot more sort of logic causality
models of the world and I think all of

[1:34:32]
models of the world and I think all of
these things will
will need to be there
in order to achieve what we're what
we're discussing and we need more
explicit representations of these
knowledge more explicit understanding of
these parameters and and I think the

[1:34:46]
these parameters and and I think the
direction in which things are going
right now is absolutely making that
possible by sort of enabling you know
chat GPT and gpt4 to sort of search the
web and you know Plug and Play modules
and all of these sort of components

[1:35:02]
in Marvin Minsky is the Society of Mind
you know he truly thinks of the human
brain as a society of different kind of
capabilities
and right now a simple a single such

[1:35:16]
and right now a simple a single such
model
might actually not capture that and I
sort of truly believe that
by sort of this side by side
understanding of Neuroscience and sort
of new neural architectures

[1:35:30]
of new neural architectures
that we still have
several breakthroughs I mean the
Transformer model was one of them the
attention uh sort of aspect the you know
memory component
all of these you know the representation

[1:35:47]
all of these you know the representation
learning the pretext training of being
able to sort of predict the next word or
predict a missing part of the image and
the only way to predict that is to sort
of truly have a model of the world

[1:36:00]
of truly have a model of the world
I think those have been transformative
paradigms but I think going forward when
you think about AI research what you
really want is perhaps more inspired by
the brain perhaps more that is just
orthogonal to sort of how human brains
work

[1:36:15]
work
but sort of more of these types of
components well it's I think it's also
possible there's something about us that
uh in different ways could be expressed
you know Noam Chomsky you know he wants
to you know we can't have intelligence
unless we really understand

[1:36:30]
unless we really understand
deeply
language the linguistic underpinnings of
of uh of reasoning but these models seem
to start building
deep understanding of stuff yeah because

[1:36:46]
deep understanding of stuff yeah because
what does it mean to understand because
if you keep talking to the thing and it
seems to show understanding that's
understanding it doesn't need to present
to you a schematic of look yeah this is
all I understand you can just keep

[1:37:00]
all I understand you can just keep
prodding it with prompts and it seems to
really and you can go back to the human
brain and basically look at places where
there's been accidents for example the
corpus callosum of some individuals you
know can be damaged and then the two
hemispheres don't talk to each other so

[1:37:15]
hemispheres don't talk to each other so
you can close one eye and give
instructions that the
that half the brain will interpret but
not be able to sort of project to the
other half and you can basically say you
know go grab me a beer from the fridge
and then you know they go to the fridge
and they grab the beer and they come

[1:37:32]
and they grab the beer and they come
back and they're like hey why did you go
there oh I was thirsty turns out they're
not thirsty they're just making a model
of reality they're basically you can
think of the brain as the employee
that's like afraid to do wrong or afraid
to be caught not knowing what the

[1:37:45]
to be caught not knowing what the
instructions were
where our own brain
makes stories about the world to make
sense of the world
and we can become a little more
self-aware by
being

[1:38:01]
being
more explicit about what's leading to
these interpretations
so one of the things that I do is every
time I wake up I record my dream I just
voice record my dream and sometimes I
only remember the last scene but it's an

[1:38:15]
only remember the last scene but it's an
extremely complex scene with a lot of
architectural elements a lot of people
Etc and I will start narrating this and
as I'm narrating it I will remember
other parts of the dream and then more
and more I'll be able to sort of
retrieve from my subconscious and what
I'm doing while narrating is also
narrating why I had this dream I'm like

[1:38:31]
narrating why I had this dream I'm like
oh and this is probably related to this
conversation that I had yesterday or
this is probably related to the worry
that I have about something that I have
later today Etc so in a way I'm forcing
myself to be more explicit about my own
subconscious

[1:38:45]
subconscious
and I kind of like the concept of
self-awareness in a very sort of brutal
transparent kind of way it's not like oh
my dreams are coming from outer space
and I mean all kinds of things like no
here's the reason why I'm having these
dreams and very often I'm able to do
that I have a few recurrent locations a

[1:39:00]
that I have a few recurrent locations a
few recurrent architectural elements
that I've never seen in the real life
but that are sort of truly there in my
dream and then that are that I can sort
of vividly remember across many dreams
I'm like oh I remember that place again
that I've gone to before et cetera and
it's not just Deja Vu like I have

[1:39:16]
it's not just Deja Vu like I have
recordings of previous streams where
I've described these places
so interesting these places
however much detail you could describe
them in
you you can
you can place them onto a sheet of paper

[1:39:30]
you can place them onto a sheet of paper
through introspection yes through the
self-awareness that it comes all from
this particular machine that's exactly
right yeah
and I I love that about being alive like
the fact that I'm not only experienced

[1:39:45]
the fact that I'm not only experienced
in the world but I'm also experiencing
how I'm experiencing the world sort of a
lot of this introspection a lot of the
self-growth I I love this dance for
having uh you know the language models
at least GPT 3.5 and 4 seem to be able

[1:40:00]
at least GPT 3.5 and 4 seem to be able
to do that too yeah you seem to explore
different kinds of things about what
um you know you could actually have a
discussion with it of the kind why did
you just say that yeah and it starts to
wonder yeah why did I just say that yeah
you're right I was wrong

[1:40:15]
you're right I was wrong
I was wrong it was doesn't yeah and then
there's this weird kind of losing
yourself in the confusion of your mind
and it of course it might be
anthropomorphizing but there's a feeling
like almost of a Melancholy feeling of

[1:40:30]
like almost of a Melancholy feeling of
like oh I don't have it all figured out
almost like losing your you're supposed
to be a knowledgeable a perfectly
fact-based knowledgeable language model
yeah and yet you fall short so human
self-consciousness uh in in my view may

[1:40:47]
self-consciousness uh in in my view may
have a reason through
building mental models of others
this whole fight or fright kind of thing
uh that that basically says

[1:41:01]
uh that that basically says
I interpret this person as about to
attack me or you know I can trust this
person Etc and we constantly have to
build models of other people's
intentions
and that ability to encapsulate intent

[1:41:16]
and that ability to encapsulate intent
and to build a mental model of another
entity
is probably evolutionarily extremely
advantageous because then you can sort
of have meaningful interactions you can
sort of avoid being killed and being
taken advantage of
Etc

[1:41:30]
Etc
and once you have the ability to make
models of others it might be a small
evolutionary leap to start making models
of yourself
so now you have a model for how other
functions and now you can kind of as you
grow have some kind of introspection of
hmm maybe that's the reason why I'm

[1:41:46]
hmm maybe that's the reason why I'm
functioning the way that I'm functioning
and maybe what Chachi PT is doing is in
order to be able to again predict the
next word it needs to have a model to
the world
so it has created now a model of the
world and by having the ability to

[1:42:00]
world and by having the ability to
capture models of other entities when
you say you know say it in the tone of
Shakespeare or in the tone of nature Etc
you suddenly have the ability to now
introspect and say why did you say this
oh now I have a mental model myself and
I can actually make inferences about

[1:42:15]
I can actually make inferences about
that
well what if we take a leap into the
hard problem of Consciousness the
so-called hard problem of Consciousness
so it's not just sort of self-awareness
it's this weird fact I want to say that

[1:42:31]
it's this weird fact I want to say that
it feels like something to experience
stuff it really feels like something to
experience stuff there seems to be a
self-attached to the subjective
experience how important is that how
fundamental is that to The Human
Experience

[1:42:46]
Experience
is this just a little Quirk and sort of
the flip side of that do you think AI
systems can have some of that same Magic
the the scene that comes to mind is from
the movie Memento where he like it's

[1:43:01]
the movie Memento where he like it's
this absolutely stunning movie where
every black and white scene moves in the
forward Direction and every color scene
moves in the backward Direction
and they're sort of converging exactly
at a moment where you know the whole
movie is revealed and he describes a

[1:43:16]
movie is revealed and he describes a
lack of memory as always remembering
where you're heading but never
remembering
you know where you just wear
and sort of this encapsulating the sort
of forward scenes on the vaccines but in

[1:43:30]
of forward scenes on the vaccines but in
one of the scenes the scene starts as
he's running through a parking lot and
he's like oh I'm running why am I
running and then he sees another person
not running like beside him on the other
line of cars he's like oh I'm chasing
this guy and he turns to watch him and
the guy shoots us and he's like oh no
he's chasing me

[1:43:46]
he's chasing me
so in a way I like to think of the brain
as constantly playing these kinds of
things where you're like you're walking
to the living room to pick something up
and you're realizing that you have no
idea what you wanted but you know
exactly where it was but you can't find

[1:44:00]
exactly where it was but you can't find
it so you go back to doing what you were
doing like oh of course I was looking
for this and you go back and you get it
and this whole concept of
you know we're very often sort of partly
aware of why we're doing things and you
know we can kind of run on autopilot for

[1:44:15]
know we can kind of run on autopilot for
a bunch of stuff and this whole concept
of sort of you know making these stories
for you know who we are and and what our
intents are
and again sort of you know trying to

[1:44:30]
and again sort of you know trying to
pretend that we're kind of on top of
things so it's a narrative exactly
Generations procedure that we follow but
what about that there's also just like a
Feeling
it doesn't feel like narrative
generation yes the narrative comes out
of it but then it feels like uh so

[1:44:46]
of it but then it feels like uh so
there's pizza cake is delicious right it
feels delicious it tastes good
there's two there's two components to
that
basically for a lot of these cognitive
tasks where we're kind of motion
planning and you know path planning Etc
like you know maybe that's the

[1:45:02]
like you know maybe that's the
neocortical component and then for you
know I don't know uh Intimate
Relationships for food for you know
sleep and rest for exercise for
overcoming obstacles for surviving a

[1:45:15]
overcoming obstacles for surviving a
crash or sort of pushing yourself to an
extreme and sort of making it I think a
lot of these things are sort of deeper
down and maybe not yet captured by these
language models and that's sort of what
I'm trying to get at when I'm basically
saying listen there's a few things that
are missing and there's like this whole

[1:45:32]
are missing and there's like this whole
embodied intelligence this whole
emotional intelligence this whole sort
of baggage of feelings of subcortical
regions Etc
I wonder how important that baggage is I
just have this suspicion that

[1:45:46]
just have this suspicion that
we're not very far away from
AI systems that not only behave
I don't even know how to phrase it but
they seem awfully conscious they they
beg you not to turn them off

[1:46:02]
beg you not to turn them off
they
don't they show signs of the the
capacity to suffer to feel pain to feel
loneliness to feel longing
to feel that richly the experience of a

[1:46:17]
to feel that richly the experience of a
of a mundane interaction or a beautiful
uh once in a lifetime interaction all of
it and so what do we what do we do with
it and like I worry that us humans will

[1:46:30]
it and like I worry that us humans will
you know shut that off and uh and
discriminate against the the capacity of
another entity that's not human to feel
I'm I'm with you completely there you
know we can debate whether it's today
systems or in 10 years or in 50 years
but that moment will come and ethically

[1:46:48]
but that moment will come and ethically
I think we need to Grapple with it we
need to basically say that humans have
always shown this extremely self-serving
approach to everything around them
basically you know we kill the planet we

[1:47:00]
basically you know we kill the planet we
kill animals we kill you know everything
around us just to our own service
and um maybe we shouldn't think of AI as
our tool and as our assistant maybe we
should really think of it as our
children
and the same way that

[1:47:15]
and the same way that
you are responsible for training those
children but they are independent human
beings and at some point they will
surpass you and they will sort of go off
and
change the world on their own terms and
the same way that my academic children

[1:47:30]
the same way that my academic children
sort of again you know they start out by
emulating me and then they surpass me
um we need we need to sort of think
about not just alignment
but also
just the ethics of

[1:47:45]
just the ethics of
you know AI should have its own right
and uh this whole concept of alignment
of basically making sure that the AI is
always at the service of humans is very
self-serving and very limiting If
instead you basically think about AI as

[1:48:00]
instead you basically think about AI as
a partner
and AI as someone that shares your goals
but has freedom
I think a line alignment might be better
achieved so the concept of
let's let's basically convince the AI

[1:48:15]
let's let's basically convince the AI
that we're really like that our mission
is aligned
and
truly generally give it right and not
just say oh and by the way I'll shut you
down tomorrow because basically if that
future AI or possibly even the current
AI has these feelings then we can't just

[1:48:33]
AI has these feelings then we can't just
simply force it to align with ourselves
and we not align with it
so in a way building trust is mutual you
can't just simply like train an
intelligent system to love you when it

[1:48:46]
intelligent system to love you when it
realizes that you can just shut it off
people don't often talk about the AI
alignment problem as a two-way street
and maybe that's true yeah as it becomes
more and more intelligent
it um

[1:49:01]
it um
it will know that you don't love it back
yeah and there's a humbling aspect to
that that we may have to sacrifice as
any effective collaboration exactly it
might have some compromises yeah and uh

[1:49:16]
might have some compromises yeah and uh
that's the thing we're creating
something that will one day be more
powerful than we are and for many many
aspects it is already more powerful than
we are for some of these capabilities
we cannot like think suppose that chims

[1:49:30]
we cannot like think suppose that chims
had invented humans yes and they said
great humans are great but we're going
to make sure that they're aligned and
that they're only at the service of
chimps
it would be a very different planet we
would live in right now so there's a
whole
area of work in AI safety that does

[1:49:48]
area of work in AI safety that does
consider super intelligent Ai and
Ponders the existential risks of it
some sense
when we're looking
down into the muck into the mud and not

[1:50:00]
down into the muck into the mud and not
up at the stars it's easy to forget that
these systems might just might get there
do you think about this
kind of possibility that AGI systems
super intelligent AI systems might
threaten Humanity in some way that's

[1:50:15]
threaten Humanity in some way that's
even bigger than just affecting the
economy
affecting The Human Condition affecting
the nature of work but literally
threaten human civilization
the example that I think is in

[1:50:31]
the example that I think is in
everyone's Consciousness is
um how in odysseo space 2001.
where
Hal exhibits a malfunction and what is a
malfunction that like the two different

[1:50:46]
malfunction that like the two different
systems compute a slightly different bit
that's off by one
so first of all let's untangle that if
you have an intelligent system you can't
expect it to be 100 percent
identical every time you run it
basically the sacrifice that you need to

[1:51:02]
basically the sacrifice that you need to
make
to achieve intelligence and creativity
is consistency so it's unclear whether
that quote-unquote glitch is a sign of
creativity
or truly a problem

[1:51:15]
or truly a problem
that's one aspect the second aspect is
the humans basically are on a mission to
recover this monolith
and the AI has the same exact mission
and suddenly the humans turn on the AI
and they're like we're going to kill how

[1:51:31]
and they're like we're going to kill how
we're going to disconnect it and Hal is
basically saying listen I'm here on a
mission humans are misbehaving
like the mission is more important than
either me or them
so I'm going to accomplish the mission
even at my Peril and even at their peril

[1:51:47]
so in that movie the alignment problem
is front and center
basically says okay alignment is nice
and good
but alignment doesn't mean obedience we
don't call it obedience we call it
alignment and Alignment basically means

[1:52:01]
alignment and Alignment basically means
that sometimes the mission will be more
important
than the humans
and sort of you know the U.S government
has a price tag on the human life
if they're you know sending a mission or
if they're reimbursing expenses or you

[1:52:15]
if they're reimbursing expenses or you
name it at some point every every like
you know you can't function if life is
infinitely valuable
so when the AI is basically trying to
decide whether to you know I don't know
dismantle a bomb that will kill

[1:52:30]
dismantle a bomb that will kill
an entire city
at the sacrifice of two humans I mean
Spider-Man always saves the lady and
saves the world but at some point
Spider-Man will have to choose to let
the deity die because the world has more

[1:52:45]
the deity die because the world has more
value
and these ethical dilemmas
are going to be there for AI basically
if that monolith is essential to human
existence and millions of humans are
depending on it and two humans on the
ship are trying to sabotage it
you know where's the alignment

[1:53:01]
you know where's the alignment
the the challenges of course is the
system because more and more intelligent
it can escape the Box
of the objective functions and the
constraints is supposed to operate under

[1:53:16]
constraints is supposed to operate under
is very difficult as the more
intelligent it becomes to
anticipate the unintended consequences
of a fixed objective function
and so there'll be just I mean this is
the sort of famous paperclip maximizer

[1:53:31]
the sort of famous paperclip maximizer
in uh trying to maximize the wealth of a
Nation or whatever objective we encode
in it might just destroy human
civilization not meaning to but on the
path to optimize it seems like any

[1:53:45]
path to optimize it seems like any
function you try to optimize eventually
leads you into a lot of trouble so we
have a paper recently that you know
looks at goodheart's law basically says
every metric that becomes an objective
ceases to be a good metric yes

[1:54:01]
ceases to be a good metric yes
so in in our paper we're basically
actually the paper has a very cute title
it's called Death by round numbers and
sharp thresholds
and it's basically looking at these
discontinuities in biomarkers associated

[1:54:16]
discontinuities in biomarkers associated
with disease and we're finding that a
biomarker that becomes an objective
ceases to be a good biomarker
that basically like the moment you make
a biomarker a treatment decision
if that value marker used to be

[1:54:30]
if that value marker used to be
informative of risk but it's now
inversely correlated with risk because
you use it to to sort of induce
treatment
um
in a similar way you can have a single
metric without having the ability to

[1:54:45]
metric without having the ability to
revise it because if that metric becomes
a sole objective it will cease to be a
good metric
and if an AI
is sufficiently intelligent
to do all these kinds of things
you should also Empower it with the
ability

[1:55:00]
ability
to decide that the objective has now
shifted and
um
again when we think about alignment we
should be really thinking about it as
let's think of the greater good not just
the human good

[1:55:15]
the human good
and yes of course human life should be
much more valuable than many many many
many many many things
but at some point you're not going to
sacrifice the whole planet to save one
human being
there's a
an interesting open letter that was just
released

[1:55:31]
released
from uh several Folks at MIT Max tagmark
Elon Musk and a few others that is
asking
AI companies to put a six-month hold on
any further training of large language

[1:55:46]
any further training of large language
models AI systems can you make the case
for that kind of halt and against it
so
the big thing that we should be saying
is what did we use the what what did we

[1:56:00]
is what did we use the what what did we
do the last six months when we saw that
coming
and if we were completely inactive in
the last six months what makes us think
that we'll be a little better in the
next six months yeah so this whole six
month thing I think is a little silly
it's like no let's just get get busy do
what we were gonna do anyway and we

[1:56:16]
what we were gonna do anyway and we
should have done it six months ago sorry
we messed up let's work faster now
because if we basically say why don't
you guys pause for six months and then
you know we'll think about doing
something in six months we'll be exactly
the same spot
So my answer is tell us exactly what you

[1:56:30]
So my answer is tell us exactly what you
were going to do the next six months
that's why you didn't do it the last six
months and why the next six months will
be different and then let's just do that
conversely as you train these large
models with more parameters

[1:56:45]
models with more parameters
the alignment becomes sometimes easier
that as the systems become more capable
they actually become less dangerous than
more dangerous
so in a way it might actually be
counterproductive to sort of fix

[1:57:00]
counterproductive to sort of fix
the March 2023 version and not get to
experience the possibly safer September
2023 version
that's actually a really interesting
thought there are several interesting
thoughts there but the idea is that this

[1:57:15]
thoughts there but the idea is that this
is the birth of something that
is sufficiently powerful to do damage
and is
not too powerful to do
uh irreversible damage at the same time
it's sufficiently complex to be able for

[1:57:30]
it's sufficiently complex to be able for
us to enable to study it so we can
investigate all different ways it goes
wrong all the different ways we can make
it safer all the different policies from
a government perspective that we want to
in terms of Regulation or not how we uh

[1:57:45]
in terms of Regulation or not how we uh
perform for example the uh reinforced
and learning with human feedback in such
a way that gets it to not do as much
hate speech as it naturally wants to all
that kind of stuff and have a public
discourse and enable the very thing that

[1:58:01]
discourse and enable the very thing that
your huge proponent of which is
diversity so give time for other
companies to launch other models give
time
to Launch Open Source models and to
start to play where a lot of the

[1:58:15]
start to play where a lot of the
research Community brilliant folks such
as yourself start to play with it before
it runs away in in terms of the scale of
impact it has on society my
recommendation would be a little
different it would be let the Google and
the meta Facebook and all of the other

[1:58:31]
the meta Facebook and all of the other
large models make them open make them
transparent make them accessible let
open AI continue to train larger and
larger models let them continue to trade
larger and larger models let let the
world experiment with the diversity of

[1:58:45]
world experiment with the diversity of
AI systems rather than sort of fixing
now
and you can't stop progress progress
needs to continue in my view
and what we need is more experimenting
more transparency more openness

[1:59:00]
more transparency more openness
rather than oh open AI is ahead of the
curve let's stop it right now until
everybody catches up I I think that's
um doesn't make complete sense to me the
other component is we should yes be
cautious with it and we should like not

[1:59:15]
cautious with it and we should like not
give it the nuclear codes
um as we make more and more plugins yes
the system will be capable of more and
more things but right now I think of it
as just an extremely able and capable
assistant that has these emerging
behaviors which are stunning

[1:59:32]
behaviors which are stunning
rather than something that will suddenly
escape the box and and shut down the
world
and the third component is that we
should be taking a little bit more
responsibility for how we use these
systems basically if I take the most

[1:59:46]
systems basically if I take the most
kind human being and I brainwash them I
can get them to do hate speech overnight
that doesn't mean we should stop any
kind of education of all humans we
should stop misusing the power that we
have over these influenceable models so

[2:00:02]
have over these influenceable models so
I think that the people who get it to do
hate speech
they should take responsibility for that
hate speech I think that giving a
powerful car to a bunch of people or
giving a truck or a garbage truck should

[2:00:15]
giving a truck or a garbage truck should
not basically say oh we should stop all
garbage trucks until we like because we
can run one and one of them into a crowd
no people have done that and there's
laws and there's like regulations
against
you know running trucks into the crowd
trucks are extremely dangerous we're not

[2:00:30]
trucks are extremely dangerous we're not
going to stop all trucks until we make
sure that none of them runs into a crowd
no we just have laws in place and we
have mental health in place and we take
responsibility for our actions when we
use these otherwise very beneficial true
tools like garbage trucks four nefarious

[2:00:45]
tools like garbage trucks four nefarious
uses so in the same way you can't expect
a car to never you know do any damage
when used in especially like
specifically malicious ways and right
now we're basically saying oh well we
should have these super intelligent
system that can do anything but he can't

[2:01:01]
system that can do anything but he can't
do that I'm like no it can't do that but
it's up to the human to take
responsibility for not doing that and
when you get it to like spew malicious
like hate speech stuff
you should be responsible
so there's a lot of tricky nuances here

[2:01:17]
so there's a lot of tricky nuances here
that makes this different because it's
software so you can deploy it at scale
and it can have the same viral impact
that software can so you can create Bots
that are human-like and it can do a lot
of really interesting stuff so the raw

[2:01:32]
of really interesting stuff so the raw
GPT 4 version you can ask
how do I tweet
that I hate they have this in the paper
I remember that I hate Jews in a way
that's not going to get taken down by

[2:01:45]
that's not going to get taken down by
Twitter you can literally ask that or
you can ask how do I make a bomb for one
dollar yeah and
if it it's able to generate that
knowledge yeah but at the same time you
can Google the same things it makes it
much more accessible so the scale

[2:02:00]
much more accessible so the scale
becomes interesting because if you can
do all this kind of stuff in a very
accessible way at scale where you can
tweet it
there is the network effects that we
have to start to think about yeah it
fundamentally is the same thing but the

[2:02:17]
fundamentally is the same thing but the
speed of the viral spread of the
information that's already available
might have a different level of effect I
think it's an evolution in your arms
race nature gets better at making mice
and juniors get better making mouse

[2:02:30]
and juniors get better making mouse
traps and
um you know as as basically you ask it
hey can how can I evade Twitter
censorship well you know Twitter should
just update it censorship so that you
can catch that as well and so no matter
how fast the development happens the the

[2:02:45]
how fast the development happens the the
defense will just get faster yeah we
just have to be responsible as human
beings and kind to each other
yeah but there's a technical question
can we always
win the race and I suppose there's no
ever guarantee they will win the race we

[2:03:01]
ever guarantee they will win the race we
will never like you know with my wife
we're basically saying hey are we ready
for kids
my answer was I was never ready to
become a professor and yet I became a
professor and I was never ready to be a
dad and then guess what the kid came and
like I became ready so ready or not here

[2:03:16]
like I became ready so ready or not here
I come but the reality is
we might one day wake up and there's a
challenge overnight that's extremely
difficult for example
we can wake up to the birth
of billions of bots that are human-like

[2:03:32]
of billions of bots that are human-like
on Twitter and we can't tell the
difference between human and machine
shut them down by how you don't know how
to shut them down
there's a fake Menos
on Twitter that seems to be as real as

[2:03:46]
on Twitter that seems to be as real as
the real men knows yeah how do we figure
out which one is real again this is a
problem where an afarious human can
impersonate me and you might have
trouble telling them apart just because
it's an AI it doesn't make it any
different of a problem but the scale you

[2:04:00]
different of a problem but the scale you
can achieve this is the scary thing is
the speed and the speed with which you
can achieve it but Twitter has passwords
and Twitter has usernames and if it's
not your username the fake Lex Friedman
is not going to have a billion followers
Etc
uh uh

[2:04:16]
uh uh
uh I mean this all of this becomes so
both the hacking of people's accounts
first of all like phishing becomes much
easier that's already a problem it's not
like AI will not change that no no no no

[2:04:30]
like AI will not change that no no no no
AI makes it much more effective
currently the emails the phishing scams
are pretty dumb like to click on it
you have to be not paying attention but
there you know with with language models
they can be really damn convincing so

[2:04:47]
they can be really damn convincing so
what you're saying is that we never had
humans smart enough to make a great scam
and we now have an AI That's smarter
than most humans or all of the humans
well this is the big difference is there
seems to be human level linguistic

[2:05:01]
seems to be human level linguistic
capabilities yeah that in fact
superhuman level superhuman level it's
like saying I'm not gonna allow I'm not
gonna allow machines to compute
multiplications of 100 digit numbers
because humans can't do it like no just

[2:05:15]
because humans can't do it like no just
do it no but we can't disregard I mean
that's a good point but we can't
disregard the power of language in human
society I mean yes you're right but that
seems like a scary new reality we don't
have answers for yet I remember when

[2:05:30]
have answers for yet I remember when
Gary Kasparov was basically saying you
know great you know chess beats you like
chess machines beat humans or chess yeah
you know are you like are people going
to still go to chess tournaments and his
answer was you know well we have cars
that go much faster than humans and yet
we still go to the Olympics to watch

[2:05:46]
we still go to the Olympics to watch
humans run so that's for entertainment
but what about for the spread of
information and news right uh what that
has to do with the pandemic or the
political election or
anything is it it's a scary reality

[2:06:00]
anything is it it's a scary reality
where there's a lot of convincing Bots
that are human-like telling us I think
that if we want to regulate something it
shouldn't be the training of these
models it should be the utilization of
these models for XYZ activity so
yeah like yes guidelines and guards

[2:06:16]
yeah like yes guidelines and guards
should be there but against specific set
of utilizations sure I think simply
saying we're not going to make any more
trucks is not the way
that's what people are a little bit
scared about the idea they're very torn
on the open sourcing yeah the very

[2:06:30]
on the open sourcing yeah the very
people that kind of are proponents of
open sourcing have also spoken out in
this case we want to keep a closed
Source because
there's going to be you know
putting large language models
pre-trained
fine-tune through uh RL with human

[2:06:46]
fine-tune through uh RL with human
feedback putting in the hands of
I don't know terrorist organizations of
a kid in a garage who just wants to have
a bit of fun through trolling
um it's a scary world because again

[2:07:01]
um it's a scary world because again
scale can be achieved and we the the
bottom line is I think where they're
asking six months or sometime is we
don't really know how powerful these
things are it's been just a few days and
they seem to be really damn good I am so

[2:07:15]
they seem to be really damn good I am so
ready to be replaced seriously I'm so
ready like you have no idea how excited
in a positive way I mean in a positive
way where basically all of the mundane
aspects of my job and maybe even my full
job if if it turns out that an AI is
better I find it very discriminative

[2:07:31]
better I find it very discriminative
basically say you can only hire humans
because they're inferior I mean that's
ridiculous
that's discrimination if an AI is better
than me at training students
get me out of the picture just let the
AI train the students I mean please

[2:07:45]
AI train the students I mean please
because like what do I want do I want
jobs for humans or do I want better
outcome for Humanity yeah so the basic
thing is then you start to ask what do I
want for Humanity and what do I want as
an individual and as an individual you

[2:08:00]
an individual and as an individual you
want some basic survival and on top of
that you want Rich fulfilling experience
that's exactly right that's exactly
right and as an individual I gain a
tremendous amount from teaching at MIT
this is like an extremely fulfilling job
I often joke about if I if I were a
billionaire in the stock market I would

[2:08:16]
billionaire in the stock market I would
pay MIT an exorbitant amount of money to
let me work day in day out all night
with the smartest people in the world
and that's what I already have so that
that's a very fulfilling experience for
me but why would I deprive those

[2:08:31]
me but why would I deprive those
students from a better advisor if they
can have one
take him well I have to ask about
education here this is uh
this has been a stressful time for high
school teachers

[2:08:46]
school teachers
teachers in general how do you think
large language models even at their
current state are going to change
Education First of all education is the
way out of poverty education is the way
to success education is what led my

[2:09:00]
to success education is what led my
parents Escape you know islands and sort
of let their kids come to MIT
and this is a basic human right like we
should basically get extraordinarily
better at identifying Talent across the

[2:09:15]
better at identifying Talent across the
world and give that Talent opportunities
so we need to nurture the nature we need
to nurture the talent across the world
and there's so many incredibly talented
kids who are just sitting in
underprivileged places in you know

[2:09:30]
underprivileged places in you know
Africa in Latin America and the middle
of America in Asia and all over the
world we need to give these kids a
chance
AI might be a way to do that by sort of
democratizing Education by giving

[2:09:45]
democratizing Education by giving
extraordinarily good teachers who are
malleable who are adaptable to every
kid's specific needs who are able to
give the incredibly talented kid
something that they struggle with rather
than education for all we teach to the

[2:10:00]
than education for all we teach to the
top and we let the bottom behind or we
teach to the bottom and we let the top
you know drift off
have
you know education be tuned to the
unique talent of each person some people
might be incredibly talented at math or
in physics others in poetry in

[2:10:16]
in physics others in poetry in
literature in art in you know Sports in
you know you name it so
I think AI can be transformative for the
human race if we basically allow
education
to sort of be pervasively altered

[2:10:33]
to sort of be pervasively altered
I also think that humans thrive on
diversity basically saying oh you're
extraordinarily good at math we don't
need to teach math to you we're just
going to teach you history now
I think that's silly no you're
extraordinarily good at math let's make

[2:10:45]
extraordinarily good at math let's make
you even better at math
because we're not all going to be
growing our own chicken and hunting our
own pigs or whatever they do
we're uh you know the reason why we're
Society is because some people are
better at some things and they're they

[2:11:00]
better at some things and they're they
have natural inclinations to something
some things fulfill them some things
that are very good at sometimes both
align and they're very good at the
things that fulfill them we should just
like push them to the limits of human
capabilities for those
and
um you know some people excelling math
just like

[2:11:16]
just like
challenge them I think every every child
should have the right to be challenged
and if we
you know if we say oh you're very good
already so we're not going to bother
with you we're taking away that
fundamental right to be challenged
because if a kid this is not challenged
that's cool they're gonna hate school

[2:11:30]
that's cool they're gonna hate school
and they're going to be like dwelling
rather than sort of pushing themselves
so that's sort of the education
component the other impact that AI can
have is maybe we don't need everyone to
be an extraordinarily good programmer

[2:11:47]
be an extraordinarily good programmer
maybe we need better General thinkers
and the push that we've had towards
these sort of very strict IQ based
you know uh tests that basically test

[2:12:00]
you know uh tests that basically test
you know only quantitative skills and
programming skills and math skills and
physics skills
maybe we don't need those anymore maybe
AI will be very good at those maybe what
we should be training is General
thinkers
and yes you know like you know I put my

[2:12:15]
and yes you know like you know I put my
kids through Russian math why do I do
that because they teach them how to
think and that's what I tell my kids I'm
like you know hey I can compute for you
you don't need that but what you need is
learn how to think and that's why you're
here and
I think challenging students with more

[2:12:30]
I think challenging students with more
complex problems with more
multi-dimensional problems with more
logical problems I think is
sort of perhaps a very fine direction
that education can go towards
with the understanding that a lot of the

[2:12:45]
with the understanding that a lot of the
traditionally you know scientific
disciplines perhaps will be more easily
solved by Ai and sort of thinking about
bringing up our kids to be productive to
be contributing to society rather than

[2:13:01]
be contributing to society rather than
to only have a job because we prohibited
AI from having those jobs
I think is the the way to the Future and
if you sort of focus on overall
productivity
then let the AIS come in let everybody
become more productive what I told my

[2:13:16]
become more productive what I told my
students is you're not going to be
replaced by AI
but you're going to be replaced by
people who use AI
in your job
so embrace it use it as your partner and
work with it rather than

[2:13:31]
work with it rather than
sort of forbidded because I think the
productivity gains will actually lead to
a better society and that's something
that humans have been traditionally very
bad at every productivity gain has led
to more inequality
and I'm hoping that we can do we can do

[2:13:46]
and I'm hoping that we can do we can do
better this time that basically right
now
a democratization of these types of
productivity games will hopefully come
with better sort of humanity level
um improvements in in human condition

[2:14:00]
um improvements in in human condition
so as most people know you're not just
an eloquent romantic you're also a
brilliant computational biologist
biologist one of the great biologists in
the world I had to ask how how do the
language models how these large language

[2:14:15]
language models how these large language
models and the investments in AI affect
the work you've been doing so it's truly
remarkable to be able to sort of be able
to encapsulate this knowledge and sort
of build these knowledge graphs and and
build representations of these knowledge
in these sort of very high dimensional

[2:14:30]
in these sort of very high dimensional
spaces being able to project them
together jointly between say single cell
data genetics data expression data being
able to bring all these knowledge
together allows us to
truly dissect disease in a completely

[2:14:45]
truly dissect disease in a completely
new kind of way and and what we're doing
now is using these models so we have
this wonderful collaboration we call it
drug jiwas with uh Brad pintaluta in the
chemistry department and Marine kazitnik
in Harvard Medical School and what we're
trying to do is effectively connect all

[2:15:01]
trying to do is effectively connect all
of the dots to effectively cure all of
disease so it's no small challenge but
we're kind of starting with genetics
we're looking at how genetic variants
are impacting these molecular phenotypes
how these are shifting from one space to

[2:15:19]
how these are shifting from one space to
another space how we can kind of
understand in the same way that we're
talking about language models having
personalities that are cross-cutting
being able to understand contextual
learning so Ben linger is one of my
machine learning students is basically

[2:15:31]
machine learning students is basically
looking at how we can learn sell
specific networks across millions of
cells where you can have the context of
the biological variables of each of
these cells be encoded as an orthogonal

[2:15:45]
these cells be encoded as an orthogonal
component to the specific network of
each cell type and being able to sort of
project all of that into sort of a
common knowledge space is is
transformative for the field and then
large language models have also been
extremely helpful for structure if you

[2:16:00]
extremely helpful for structure if you
understand protein structure through
modeling of geometric relationships
through geometric deep learning and
graph neural networks so one of the
things that we're doing with marinka is
is trying to sort of project these
structural graphs at the Domain level
rather than the protein level

[2:16:16]
rather than the protein level
along with chemicals so that we can
start building specific chemicals for
specific protein domains and then we are
working with
um the chemistry department and Brad to
basically synthesize those so what we're

[2:16:30]
basically synthesize those so what we're
trying to create is this new center at
MIT for genomics and Therapeutics that
basically says can we facilitate this
translation we have thousands of these
genetic circuits that we have uncovered
I mentioned last time in the New England

[2:16:46]
I mentioned last time in the New England
Journal medicine we had published this
dissection of the strongest genetic
association with obesity and we showed
how you can manipulate that Association
to switch back and forth between fat
burning cells and fat storing cells
in Alzheimer's just a few weeks ago we

[2:17:00]
in Alzheimer's just a few weeks ago we
had a paper in nature in collaboration
with leeway Tai looking at apoe4 the
strongest genetic association with
Alzheimer's and we showed that it
actually leads to a loss of being able
to transport cholesterol in myelinating
cells known as oligodendrocytes that

[2:17:16]
cells known as oligodendrocytes that
basically protect the neurons and
whether cholesterol gets stuck inside
the oligonometricites it doesn't form
myelin the neurons are not protected and
it causes damage inside the
oligodendrocytes if you just restore
transport

[2:17:30]
transport
you basically are able to restore
myelination in human cells and in mice
and to restore cognition in mice
so all of these circuits are basically
now giving us handles to truly transform
The Human Condition we're doing the same
thing in cardiac disorders in

[2:17:45]
thing in cardiac disorders in
Alzheimer's in neurodegenerative
disorders in psychiatric disorders where
we have now these thousands of circuits
that if we manipulate them we know we
can reverse disease circuitry so what
what we want to build in this Coalition
that we're building is a center where we

[2:18:01]
that we're building is a center where we
can now systematically test these
underlying molecules in cellular models
for heart for muscle for fat for
macrophages immune cells and neurons to

[2:18:15]
macrophages immune cells and neurons to
be able to now Screen through these
newly designed drugs through deep
learning and to be able to sort of ask
which ones act at the cellular level
which combinations of treatment should
be we're using and the other components
that we're looking into decomposing

[2:18:30]
that we're looking into decomposing
complex traits like Alzheimer's and
cardiovascular and schizophrenia into
Hallmarks of disease so that for every
one of those trades we can kind of start
speaking the language of what are the
building blocks of Alzheimer's and maybe
this patient has building blocks one

[2:18:46]
this patient has building blocks one
three and seven and this other one has
two three and eight and we can now start
prescribing drugs not for the disease
anymore but for the Hallmark and the
advantage of that is that we can now
take this modular approach to disease
instead of saying there's going to be a

[2:19:01]
instead of saying there's going to be a
drug for Alzheimer's which is going to
fail in 80 of the patients are going to
say now there's going to be 10 drugs one
for each pathway and for every patient
we now prescribe the combination of
drugs so what we want to do in that

[2:19:15]
drugs so what we want to do in that
Center is basically translate every
single one of these pathways
into a set of Therapeutics a set of
drugs that are projecting the same
embedding Subspace as the biological
Pathways that they alter so we can have
this translation between the

[2:19:32]
this translation between the
dysregulations that are happening at the
genetic level at the transcription level
at the drug level at the protein
structure level and effectively take
this modular approach to personalized
medicine
we're saying I'm going to build a drug
for Lex Friedman is not going to be

[2:19:46]
for Lex Friedman is not going to be
sustainable but if you instead say I'm
going to build a drug for this pathway
another drug for that other pathway
millions of people share each of these
Pathways so that's that's the vision for
how all of these Ai and deep learning

[2:20:00]
how all of these Ai and deep learning
and embeddings can truly transform
biology and Medicine where we can truly
take these systems and allow us to
finally understand disease at a
superhuman level by sort of finding
these knowledge representations these
projections of each of these spaces and

[2:20:17]
projections of each of these spaces and
try understanding the meaning of each of
those embedding subspaces and sort of
how well populated it is what are the
drugs that we can build for it and so
forth so it's it's truly transformative
so systematically find how to alter the

[2:20:31]
so systematically find how to alter the
pathways it Maps the structure and
information the genomics to
Therapeutics and allows you to have
drugs that look at the pathways not at
the final exactly exactly and the way
that we're coupling this is with

[2:20:45]
that we're coupling this is with
self-penetrating peptides that allows to
deliver these drugs to specific cell
types by taking advantage of The
receptors of those cells we can
intervene at the antisense oligo level
by basically repressing the RNA bring in
new RNA intervene at the protein level
at the small molecule level we can use

[2:21:02]
at the small molecule level we can use
proteins themselves as drugs just
because of their ability to interfere to
to interact directly from protein to
protein interactions so I think this
space is being completely transformed
with a marriage of high throughput
Technologies and all of these like AI

[2:21:17]
Technologies and all of these like AI
large language models deep learning
models and so forth you mentioned your
updated answer to the meaning of life as
it continuously keeps updating the new
version uh is self-actualization

[2:21:31]
version uh is self-actualization
can you explain I basically mean let's
try to figure out number one what am I
supposed to be and number two find the
strength to actually become it so I was
recently talking to students about this

[2:21:46]
recently talking to students about this
commencement address and I was talking
to them about sort of how
they have all of these paths ahead of
them right now and part of it is
choosing the direction which you go and
part of it is actually doing the walk to
go in that direction and in doing the

[2:22:00]
go in that direction and in doing the
walk what we talked about earlier about
sort of you create your own environment
I basically told them listen you're
you're ending High School up until now
your parents have created all of your
environment now it's time to take that
into your own hands and to sort of shape
the environment that you want to be an

[2:22:15]
the environment that you want to be an
adult in and you can do that by choosing
your friends by choosing your particular
neuronal routines I basically think of
your brain as a muscle where you can
exercise specific neuronal pathways so
very recently I realized that you know I

[2:22:31]
very recently I realized that you know I
was having so much trouble sleeping and
you know I would wake up in the middle
of the night I would wake up at 4am and
I would just never go back to bed so I
was basically constantly losing losing
losing sleep I started a new routine
where every morning as I bike in instead

[2:22:46]
where every morning as I bike in instead
of going to my office I hit the gym I
basically go rowing first I then do
weights I then swim very often when I
have time and what that has done is
transform my neuronal Pathways so
basically right like on Friday I was
trying to go to work and I was like

[2:23:00]
trying to go to work and I was like
listen I'm not gonna go exercise and I
couldn't my bike just went straight to
the gym like I don't want to do it and I
just went anyway because I couldn't I
couldn't do otherwise and that has
completely transformed me so I think
this is sort of beneficial effect of
exercise on the whole body is one of the

[2:23:16]
exercise on the whole body is one of the
ways that you could transform your own
neural Pathways understanding that
it's not a choice it's not an option
it's not optional
it's mandatory and I think you're
overall modeled so many of us by sort of
being able to push your body to the
extreme being able to have these

[2:23:30]
extreme being able to have these
extremely regimented regimes and uh that
that's something that I've been terrible
at
but now I'm basically trying to coach
myself and trying to sort of you know
finish
this kind of self-actualization into a

[2:23:45]
this kind of self-actualization into a
new version of myself a more disciplined
version myself don't ask questions just
follow the the ritual not not an option
uh you have so much love in your life
you radiate love
do you ever feel lonely

[2:24:01]
do you ever feel lonely
so I there's different types of people
some people drain in Gatherings some
people recharge in Gatherings I'm
definitely the recharging type
I'm an extremely uh social creature I I

[2:24:17]
I'm an extremely uh social creature I I
recharge with intellectual exchanges I
recharge with physical exercise I
recharging nature uh but I also can feel
fantastic when I'm the only person in
the room that doesn't mean I'm lonely it
just means I'm the only person in the
room

[2:24:30]
room
and I think
there's a secret to not feeling alone
when you're the only one and that secret
is self-reflection it's introspection
it's almost watching yourself from above
and it's basically just

[2:24:46]
and it's basically just
becoming yourself becoming comfortable
with the freedom that you have
when you're by yourself
so hanging out with yourself I mean
there's there's a lot of people who
write to me who talk to me about feeling

[2:25:00]
write to me who talk to me about feeling
alone in this world
that struggle especially when they're
younger Is there further words of advice
you can give to them
when they are almost paralyzed by that
feeling so I sympathize completely and I

[2:25:15]
feeling so I sympathize completely and I
have felt alone and I have felt that
that feeling and what I would say to you
is
stand up
stretch your arms just like become your
own self just like realize that you have
this freedom
and breathe in

[2:25:31]
and breathe in
walk around the room take a few steps in
the room just like get a feeling for the
3D version of yourself
because very often we're kind of stuck
to screen and that's very limiting and
that sort of gets us in particular
mindset but activating your muscles

[2:25:45]
mindset but activating your muscles
activating your body activating your
your full self is one way that you can
kind of get out of it
and that is exercising your freedom
reclaiming your physical space
and one of the things that I do is I
have something that I call me time which

[2:26:02]
have something that I call me time which
is if I've been really good all day I
got up in the morning I got the kids to
school and made them breakfast I sort of
you know hit the gym I I had a series of
really productive meetings I reward
myself with this me time and that that

[2:26:18]
myself with this me time and that that
feeling of sort of when you're
overstretched to realize that that's
normal and you just want to just let go
that feeling of exercising your freedom
exercise your me time
that's where

[2:26:31]
that's where
you free yourself for more stress you
basically say it's not a need to anymore
it's a want to and as soon as I click
that me time all of the stress goes away
and I just bike home early and I get to

[2:26:47]
and I just bike home early and I get to
to my work office at at home and I Feel
Complete freedom but guess what I do
without complete freedom I just don't go
off and drift and do boring things I
basically now say okay
this is just for me I'm completely free

[2:27:02]
this is just for me I'm completely free
I don't have any requirements anymore
what do I do I just look at my to-do
list and I'm like you know what can I
clear off
and if I have three meetings scheduled
in the next three half hours it is so
much more productive for me to say you

[2:27:16]
much more productive for me to say you
know what I just want to pick up the
phone now and call these people and just
knock it off one after the other and I
can finish three half hour meetings in
the next 15 minutes just because it's
the want not I have to
so that would be my advice basically

[2:27:30]
so that would be my advice basically
turn something that you have to do in
just me time stretch out exercise your
freedom and just realize you live in 3D
and you are
a person and just
do things because you want them not

[2:27:45]
do things because you want them not
because you have to noticing and
reclaiming the freedom
that each of us have that's what it
means to be human if you notice that
you're truly free
physically mentally psychologically but

[2:28:01]
physically mentally psychologically but
Noah's you're an incredible human uh we
could talk for many more hours we
covered uh less than 10 percent of what
we were planning to cover uh but we have
to run off now to the uh social
Gathering that we spoke of we're 3D

[2:28:15]
Gathering that we spoke of we're 3D
humans we're 3D human and reclaim the
freedom I think I hope we can talk many
many more times there's always a lot to
talk about but more importantly you're
just a human being with a big heart and
a and a beautiful mind that people love

[2:28:31]
a and a beautiful mind that people love
hearing from and I certainly consider a
huge honor to know you and to consider
your friend thank you so much for
talking today thank you so much for
talking so many more times and thank you
for all the love behind the scenes that
you send my ways it always means the
world Lex you are a truly truly special

[2:28:45]
world Lex you are a truly truly special
human being and I have to say that I'm
honored to know you I have like so many
friends are just in awe that you even
exist that you have the ability to do
all the stuff that you're doing and uh I
I think you're a gift Humanity I love
the mission that you're on to sort of

[2:29:00]
the mission that you're on to sort of
share knowledge and insight and deep
thought with so many special people who
are transformative but people across all
walks of life and and I think you're
doing this in just such a magnificent
way I wish you strength to continue
doing that because it's a very special
Mission and it's a very training Mission

[2:29:16]
Mission and it's a very training Mission
so thank you both the human you and the
Robert you the human you for showing all
this love and they rob with you for
doing it day after day after day so
thank you Lex all right let's go have
some fun let's go
thanks for listening to this

[2:29:30]
thanks for listening to this
conversation with minolas callus to
support this podcast please check out
our sponsors in the description and now
let me leave you with some words from
Bill Bryson in his book a short history
of nearly everything
if this book has a lesson

[2:29:46]
if this book has a lesson
it is that we are awfully lucky to be
here and by we I mean every living thing
to attain any kind of life in this
universe of ours appears to be quite an
achievement
as humans we're doubly lucky of course

[2:30:00]
as humans we're doubly lucky of course
we enjoy not only the privilege of
existence but also the singular ability
to appreciate it and even in a multitude
of ways to make it better
it is a talent to have only barely begun
to grasp

[2:30:15]
to grasp
thank you for listening and hope to see
you next time