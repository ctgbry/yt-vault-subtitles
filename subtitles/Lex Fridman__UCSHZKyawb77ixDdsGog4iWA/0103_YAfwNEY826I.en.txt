[00:03]
[Music]
do you think neural networks can be made
to reason yes there's no question about
that again we have a good example right
the question is is how so the question
is how much prior structure you have to
put in the neural net so that something
like human reasoning will emerge from it
you know from running another question
is all of our kind of model of what
reasoning is that are based on logic are
discrete and and are therefore
incompatible with gradient based
learning and I was very strong believer
in this idea granion baserunning I don't
believe that other types of learning
that don't use kind of gradient
information if you want so you don't
like discrete mathematics you don't like
anything discrete
well that's it's not that I don't like
it it's just that it's it's incompatible
with learning and I'm a big fan of
running right so in fact that's perhaps
one reason why deep learning has been

[01:01]
one reason why deep learning has been
kind of looked at with suspicion by a
lot of computer scientists because the
math is very different the math that you
use for deep running you know we kind of
as more to do with you know cybernetics
the kind of math you do in electrical
engineering than the kind of math you
doing computer science and and you know
nothing in in machine learning is exact
right computer science is all about sort
of you know obviously compulsive
attention to details of like you know
every index has to be right and you can
prove that an algorithm is correct right
machine learning is the science of
sloppiness really that's beautiful so
okay maybe let's feel around in the dark
of what is a neural network that reasons
or a system that is works with
continuous functions that's able to do
build knowledge however we think about
reasoning builds on previous knowledge

[02:00]
reasoning builds on previous knowledge
build on extra knowledge create new
knowledge generalize outside of any
training set ever built what does that
look like if yeah they may be do you
have Inklings of thoughts of what that
look like well yeah I mean yes or no if
I had precise ideas about this I think
you know we'd be building it right now
but and there are people working on this
or whose main research interest is
actually exactly that right so what you
need to have is a working memory so you
need to have some device if you want
some subsystem they can store a
relatively large number of factual
episodic information for you know a
reasonable amount of time so you you
know in the in the brain for example it
kind of three main types of memory one
is the sort of memory of the the state
of your cortex and that sort of
disappears within 20 seconds you can't

[03:00]
disappears within 20 seconds you can't
remember things for more than about 20
seconds or a minute if you don't have
any other form of memory the second type
of memory which is longer-term is a
short-term is the hippocampus so you can
you know you came into this building you
remember whether where the the exit is
where the elevators are you have some
map of that building that's stored in
your hippocampus you might remember
something about what I said you know a
few minutes ago and forgot all right if
it starts being raised but you know but
that there's a marker in your
hippocampus and then the the longer term
memory is in the synapse the synapses
right so what you need if you want for a
system that's capable of reasoning is
that you want the hippocampus like thing
right and that's what people have tried
to do with memory networks and you know
in altering machines and stuff like that
right and and now with transformers
which have sort of a memory in they're
kind of self attention system you can
you can think of it this way so so

[04:00]
you can think of it this way so so
that's one element you need another
thing you need is some sort of network
that can access this memory
get an information back and then kind of
crunch on it and then do this
iteratively multiple times because a
chain of reasoning is a process by which
you you you can you update your
knowledge about the state of the world
about you know it's gonna happen etc and
that there has to be this sort of
recurrent operation basically and you
think that kind of if we think about a
transformer so that seems to be too
small to contain the knowledge that's
that's to represent the knowledge as
containing Wikipedia for example well
transformer doesn't have this idea of
recurrence it's got a fixed number of
layers and that's the number of steps
that you know limits basically it's a
representation but recurrence would
build on the knowledge somehow I mean
yeah it would evolve the knowledge and
expand the amount of information perhaps

[05:02]
expand the amount of information perhaps
or useful information within that
knowledge yeah but is is this something
that just can emerge with size because
it seems like everything we have now is
just no it's not it's not it's not clear
how you access and write into an
associative memory in efficient way I
mean sort of the original memory network
maybe had something like the right
architecture but if you try to scale up
a memory network so that the memory
contains all Wikipedia it doesn't quite
work right so so this is a need for new
ideas there okay but it's not the only
form of reasoning so there's another
form of reasoning which is true which is
very classical so in some types of AI
and it's based on let's call it energy
minimization okay so you have some sort
of objective some energy function that
represents the the the quality or the
negative quality okay energy goes up
when things get bad and they get low

[06:00]
when things get bad and they get low
when things get good so let's say you
you want to figure out you know what
gestures do I need to to do to grab an
object or walk out the door if you have
a good model of your own body a good
model of the environment using this kind
of energy minimization you can make a
you can make you can do planning and
it's
in optimum control is called it's called
market model predictive control you have
a model of what's gonna happen in the
world as consequence of your actions and
that allows you to buy energy
minimization figure out a sequence of
action that optimizes a particular
objective function which measures you
know minimize the number of times you're
gonna hit something and the energy gonna
spend doing the gesture and etc so so
that's performer reasoning planning is a
form of reasoning and perhaps what led
to the ability of humans to reason is
the fact that or you know species you
know that appear before us had to do
some sort of planning to be able to hunt

[07:00]
some sort of planning to be able to hunt
and survive and survive the winter in
particular and so you know it's the same
capacity that you need to have so in
your intuition is if you look at expert
systems in encoding knowledge as logic
systems as graphs in this kind of way is
not a useful way to think about
knowledge graphs are your brittle or
logic representation so basically you
know variables that have values and
constraint between them that are
represented by rules is real too rigid
and too brittle right so one of the you
know some of the early efforts in that
respect were were to put probabilities
on them so a rule you know you know if
you have this in that symptom you know
you have this disease with that
probability and you should prescribe
that antibiotic with that probability
right this mice in system from the 70s
and that that's what that branch of AI

[08:01]
and that that's what that branch of AI
led to you know Bayesian networks in
graphical models and causal inference
and viral you know yeah method so so
there there is I mean certainly a lot of
interesting work going on in this area
the main issue with this is is knowledge
acquisition how do you reduce a bunch of
data to a graph of this type near relies
on the expert on a human being to encode
at add knowledge and that's especially
in practical question the second
question is do you
to represent knowledge symbols and you
want to manipulate them with logic and
again that's incomparable we're learning
so one suggestion with geoff hinton has
been advocating for many decades is
replace symbols by vectors think of it
as pattern of activities in a bunch of
neurons or units or whatever you wanna
call them and replace logic by

[09:01]
call them and replace logic by
continuous functions okay
and that becomes now compatible there's
a very good set of ideas by written in a
paper about 10 years ago by Leon go-to
on who is here at Facebook the title of
the paper is for machine learning to
machine reasoning and his idea is that
learning learning systems should be able
to manipulate objects that are in the
sense fit in a space and then put the
result back in the same space so is this
idea of working memory basically and
it's a very enlightening and in the
sense that might learn something like
the simple expert systems
I mean it's with you can learn basic
logic operations there yeah quite
possibly yeah this is a big debate on
sort of how much prior structure you
have to put in for this kind of stuff to
emerge that's the debate I have with
Gary Marcus and people like that

[10:03]
you