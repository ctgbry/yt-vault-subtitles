[00:01]
so we're now talking about humans but if
we think about building artificial
intelligence systems robots do you think
all the features and bugs that you have
highlighted in human beings are useful
for constructing AI systems so both
systems are useful for perhaps while
instilling in robots what is happening
these days is that actually what is
happening in deep learning is is more
like a system one product than like a
system to product I mean deep learning
matches patterns and anticipate what's
going to happen so it's highly
predictive what's right what deep
learning doesn't have and you know many
people think that this is a critical it
it doesn't have the ability to reason so
it it does and there is no system to
bear but I think very importantly it

[01:02]
bear but I think very importantly it
doesn't have any causality or any way to
represent meaning and to represent real
interaction so until that is solved the
you know what can be accomplished is
marvelous and very exciting but limited
that's actually really nice to think of
current advances in machine learning is
essentially system one advances so how
far can we get with just system one if
we think I'm learning in artificial
systems and I mean you know it's very
clear that deep mind is already gone
we're way beyond what people thought was
possible I think I think the thing that
has impressed me most about the
developments in AI is the speed it's
that things at least in the context of
deep learning and maybe this is about to
slow down but things moved a lot faster
than anticipated the transition from

[02:00]
than anticipated the transition from
solving solving chess to solving go
was I mean that's the world rain how
quickly it went the move from alphago to
alpha 0 is sort of bewildering the speed
at which they accomplished that
now clearly they're they're eight so
there are many problems that you can
solve that way but there are some
problems for which you needs something
else something like reasoning where
reasoning and also you know that one of
the real mysteries psychologists there
Gary Marcus who is also a critic of AI I
mean he what he points out and I think
he has the point is that humans learn
quickly children don't need million
examples they need two or three examples
so clearly there is a fundamental

[03:01]
so clearly there is a fundamental
difference and what enables would enable
the machine to to learn quickly what you
have to build into the machine because
it's dear that you have to build some
expectations or something in the machine
to make it ready to learn quickly
that's that at the moment seems to be
unsolved I'm pretty sure that the mind
is working on it but yeah they're if
they have solved it I haven't heard yet
they're trying to actually them an open
air trying to start to get to use neural
networks to reason so assemble knowledge
of course causality is temporal
causality is out of reach
to most everybody you mentioned the
benefits of system one is essentially
that it's fast allows us to function in
the world ask them skilled you know it's
skill and it has a model of the world
you know in a sense I mean there was the

[04:02]
you know in a sense I mean there was the
earlier phase of a I attempted to model
reasoning and they were moderately
successful but you know reasoning by
itself doesn't get you
much deep learning has been much more
successful in terms of you know what
they can do but now that's an
interesting question whether it's
approaching its limits what do you think
I think absolutely so I just talked to
John Lagoon he mentioned you know I know
him so he thinks that the limits were
not going to hit the limits with you all
networks that ultimately this kind of
system want pattern matching will start
to start to look like system two with
without significant transformation of
the architecture so I'm more with the
with the majority of the people who
think that yes you know networks will
hit a limit in their capability he on

[05:01]
hit a limit in their capability he on
the one hand I have heard him tell they
missus obvious essentially that you know
what they have accomplished it's not a
big deal that they have just touched
that basically you know they can't do
unsupervised learning in in an effective
way and but you're telling me that he
thinks that the current within the
current architecture you can do
causality and reasoning so he's very
much a pragmatist in a sense that saying
that were very far away
that they're still yeah I think there's
this idea that he says is uh we can only
see one or two mountain peaks ahead and
there might be either a few more after
or thousands more after yes so that kind
of idea right but nevertheless it
doesn't see a the final answer not
fundamentally looking like one that we
currently have
so neural networks being a huge part

[06:01]
so neural networks being a huge part
that you know I mean that's very likely
because because pattern matching is so
much of what's going on behind you can
think of neural networks as processing
information sequentially yeah I mean you
know there is there is an important
aspect to for example you get systems
that translate and they do a very good
job but they really don't know what
they're talking
about and and and for that I'm really
quite surprised for that you would need
you would need an AI that has sensation
an AI that is in touch with the world
and soreness and maybe even something
resembles consciousness kind of ideas li
awareness of you know awareness of
what's going on so that the the words
have meaning who can get in touch with
some perception or some action yeah so

[07:00]
some perception or some action yeah so
that's a big thing for Yan and as well
here first is grounding to the physical
space so so that's what we're talking
about the same yeah so but so how how
you ground I mean the grounding without
grounding then you get you get a machine
that doesn't know what it's talking
about because it is talking about the
world ultimately the question open
question is what it means to ground I
mean we're very human centric in our
thinking but what does it mean for a
machine to understand what it means to
be in this world does it need to have a
body does he need to have a finiteness
like we humans have all of these
elements it's very nice to know I'm you
know I'm not sure about having a body
but having a perceptual system having a
body would be very helpful to me if if
you think about human mimicking human
ooh but having a perception that seems
to be essential so that you can build

[08:03]
to be essential so that you can build
you can accumulate knowledge about the
world so if you can you can imagine a
human completely paralyzed and there's a
lot that the human brain could learn you
know with a paralyzed body so if we got
a machine that could do that it would be
a big deal and then the flip side of
that something you see in children and
something in machine learning world is
called active learning maybe it is
awesome is being able to play with the
world how important for developing
system waters or system to
you think it is to play with the world
be able to interact with me a lot a lot
of what you learn as you learn to
anticipate the outcomes of your actions
I mean you can see that how babies learn
it you know with their hands are they
how they learn you know to connect you

[09:01]
how they learn you know to connect you
know the movements of their hands was
something that clearly is something that
happens in the brain and and and the
ability of the brain to learn new
patterns so you know it's the kind of
thing that you get with artificial limbs
that you connect it and then people
learn to operate the artificial limb you
know really impressively quickly at
least from from what I hear so and we
have a system that is ready to learn the
world through action at the risk of
going into way too mysterious of land
what do you think it takes to build a
system like that obviously we're very
far from understanding how the brain
works but how difficult is it to build
this mind of ours you know I mean I
think that yonder Coons answer that we
don't know how many mountains there are
I think that's a very good answer I

[10:00]
I think that's a very good answer I
think that you know if you if you look
at what cool very cool coil is saying
that strikes me is of the war but but I
think people are much more realistic
than that were actually they missus
Abhi's is and Yanis and so the people
are actually doing the work fairly
realistic I think - maybe phrase it
another way from a perspective not of
building it but from understanding it
how complicated are human beings in in
the following sense you know I work with
autonomous vehicles and pedestrians so
we tried to model pedestrians how
difficult is it to model a human being
their perception of the world the two
systems they operate under sufficiently
to be able to predict whether the
pedestrians gonna cross the road or not
and I'm fairly optimistic about that
actually because what we're talking

[11:00]
actually because what we're talking
about is a huge amount of information
that every vehicle has and that feeds
into one system into one gigantic system
and so anything that any vehicle learns
becomes part of what the whole system
knows and with a system multiplier like
that there is a lot that you can do so
human beings are very complicated but
and and you know system is going to make
mistakes but human makes mistakes I
think that they'll be able to I think
they are able to anticipate pedestrians
otherwise a lot would happen they're
able to you know they're able to get
into a roundabout and into the end to
traffic so they must know both to expect
though to anticipate how people will
react when they're sneaking in and
there's a lot of learning that's

[12:01]
there's a lot of learning that's
involved in that currently the
pedestrians are treated as things that
cannot be hid and not treated as agents
with whom you interact in a game
theoretic way so I mean it's not it's a
totally open problem and every time
somebody tries to solve it it seems to
be harder than we think and nobody's
really tried to seriously solve the
problem of that dance because I'm not
sure if you've thought about the problem
of pedestrians but you're really putting
your life in the hands of the driver you
know there is a dance as part of the
dance that would be quite complicated
but for example when I cross the street
and there is vehicle approaching I look
the driver in the eye and I think many
people do that
and you know that's a signal that that
I'm sending and I would be sending that
machine to an autonomous vehicle and it

[13:01]
machine to an autonomous vehicle and it
had better understand it because it
means I'm crossing so and there's
another thing you do
that actually so I'll tell you what you
do because we watched I've watched
hundreds of hours of video on this is
when you step in the street you do that
before you step in the street and when
you step in the street you actually look
awake away yeah yeah now what what is it
what the saying is mean you're trusting
that the car who hasn't Sloane down yet
will slow down yeah and you're telling
him yeah
I'm committed yeah I mean this is like
in a game of chicken so I'm committed
and if I'm committed I'm looking away so
there is you you just have to stop so
the question is whether a machine that
observes that needs to understand
mortality here I'm not sure that it's
got to understand so much it's got to
anticipate so and here but you know

[14:03]
anticipate so and here but you know
you're surprising me because here I
would think that maybe you can
anticipate without understanding because
I think this is clearly what's happening
in playing go or in playing trace
there's a lot of anticipation and there
is zero understanding so I thought that
you didn't need a model of the human yes
and the model of the human mind to avoid
hitting pedestrians but you are
suggesting that I do yeah you do as and
then it's then it's a lot harder so this
is all
you