[00:00]
in this video I proposed to ask the
question that was asked by Alan Turing
almost seventy years ago in his paper
Computing Machinery and intelligence can
machines think this is the first paper
in a paper reading club that we started

[00:16]
in a paper reading club that we started
focused on artificial intelligence but
also including mathematics physics
computer science you know science all
the scientific and engineering
disciplines on the surface this is a
philosophical paper but really it's one
of the most impactful and important

[00:30]
of the most impactful and important
first steps towards actually engineering
intelligent systems but providing a test
benchmark that we call today the Turing
test of how we can actually know
quantifiably that a system has become
intelligent so I'd like to talk about an

[00:47]
intelligent so I'd like to talk about an
overview of ideas in the paper provide
some of the objections inside the paper
and external to the paper consider some
alternatives to the test proposed within
the paper and then finished with some

[01:01]
the paper and then finished with some
takeaways like I said the title of the
paper was Computing Machinery and
intelligence published almost 70 years
ago in 1950 author Alan Turing and to me
now we can argue about this on the slide

[01:15]
now we can argue about this on the slide
I say it's one of the most impactful
papers to me it probably is the most
impactful paper in the history of
artificial intelligence while only being
a philosophy paper I think the number of
researchers from inside computer science

[01:30]
researchers from inside computer science
and from outside that has inspired as
may dream at a collective intelligence
level of our species inspire that this
is possible I think is immeasurable for
all the major engineering breakthroughs
and computer science breakthroughs and

[01:46]
and computer science breakthroughs and
papers stretching all the way back to
the 30s and 40s with even the work by
Alan Turing with the Turing machine some
some of the mathematical foundations of
computer science to today with deep

[02:00]
computer science to today with deep
learning a sequence of papers from the
very practical
Alex Ned paper to the backpropagation
paper so all of these papers that
underlie the actual successes of the
field I think the seed was plan
did the dream was born with this paper

[02:18]
did the dream was born with this paper
and it happens to have some of my
favorite opening laws of any paper I've
ever read it goes I propose to consider
the question can machines think this

[02:31]
the question can machines think this
should begin with the definitions of the
meaning of the terms machine and think
the definition might be framed so as to
reflect so far as possible normally use
of the words but this attitude is
dangerous if the meaning of the words

[02:45]
dangerous if the meaning of the words
machine and think are to be found in
examining how they're commonly used it
is difficult to escape the conclusion
that the meaning and the answer to the
question can machines think is to be
sought in a statistical survey such as a
Gallup poll but this is absurd instead

[03:02]
Gallup poll but this is absurd instead
of attempting such a definition I shall
replace the question by another which is
closely related to it and is expressed
in relatively unambiguous terms and he
goes on to define the imitation game the
construction that we today call the

[03:16]
construction that we today call the
Turing test which goes like this there's
a human interrogator on one side of the
wall and there's two entities one a
machine one a human on the other side
and the human interrogator communicates

[03:31]
and the human interrogator communicates
with the two entities on the other side
of the wall by written word by passing
notes back and forth and after some time
of this conversation the human
interrogator is tasked with making a
decision which of the other two entities

[03:45]
decision which of the other two entities
is a human and which is a machine I
think this is a powerful leap of
engineering which is take an ambiguous
but a profound question like can
machines think and convert it into a
concrete test that can serve as a
benchmark for intelligence but there's

[04:03]
benchmark for intelligence but there's
echoes in this question to some of the
other profound questions that we often
ask so not only can machines think but
can machines be conscious Commission's
fall in love can machines create art
music poetry can machines enjoy a

[04:18]
music poetry can machines enjoy a
delicious meal
piece of chocolate cake I think these
are really really important questions
but very difficult to ask when we're
trying to create a non-human system that
tries to achieve human-level

[04:31]
tries to achieve human-level
capabilities so that's where touring
formulates this imitation game and his
prediction was that by the year 2000 or
in 50 years since the paper that a
machine with 100 megabytes of storage

[04:46]
machine with 100 megabytes of storage
will fool 30% of humans in a five-minute
test of conversation another broader
societal prediction he made which i
think is also interesting is that people
will no longer consider a phrase like

[05:00]
will no longer consider a phrase like
thinking machine contradictory
so basically artificial intelligence at
a human level become so commonplace that
we would just take it for granted and
the other part that he goes at lengthen
towards the end of the paper to describe

[05:16]
towards the end of the paper to describe
which he believes that learning machines
or machine learning will be a critical
component of this success I think it's
also useful to break apart to imply
claims within the paper open claims open

[05:30]
claims within the paper open claims open
questions one is that the imitation game
as throwing proposes is a good test of
intelligence and the second is that
machines can actually pass this test so
when you say can machines think you're

[05:46]
when you say can machines think you're
both proposing an engineering benchmark
for the word think and raising the
questions can machines pass this
benchmark one of the perhaps tragic but
also exciting aspects of this whole area

[06:02]
also exciting aspects of this whole area
of work is that we still have a lot of
work to do
so throughout this presentation I will
not only describe some of the ideas in
the paper and outside of it in the year
since but also some of the open
questions that remain both at the

[06:16]
questions that remain both at the
philosophical the psychological and the
technical levels so here the open
question stands is even impossible to
create a test of intelligence for
artificial systems that will be
convincing to us or will we always raise

[06:30]
convincing to us or will we always raise
the bar a Korell
that question is looking at the
prediction that were made that people
will no longer find the phrase Thinking
Machines contradictory why do we still
find that phrase contradictory why do we

[06:46]
find that phrase contradictory why do we
still think that computers are not at
all intelligent for many people the game
of chess
was seen as the highest level of
intelligence in these early days in fact
we assign a lot of intelligence to Garry

[07:00]
we assign a lot of intelligence to Garry
Kasparov for being one of the greatest
if not the greatest chess players of all
time as a human why do we not assign at
least an inkling of that to IBM D blue
when I beat Garry Kasparov now of course

[07:15]
when I beat Garry Kasparov now of course
you might start saying there's a
brute-force algorithm or in the case of
alphago now for zero
you know how the learning mechanisms
behind those algorithms work when they
mastered the game of go in the game of
chess
and we'll get to some of those
objections but there's something deeply

[07:31]
objections but there's something deeply
psychological within those objections
that almost fear an artificial
intelligence that passes the test so the
drawing test is very interesting as a
thought experiment as a philosophical
construct but it's also interesting as a

[07:46]
construct but it's also interesting as a
real engineering test and one of the
implementations of it has been called
the lobner prize which has been running
since 1991 to today and the awards
behind it the war structure is 25,000

[08:01]
behind it the war structure is 25,000
dollars for a system that using text
alone passes the test and $100,000 that
uses other modalities like visual and
auditory input the rules of the
competition have changed through the
years but there currently are as follows

[08:16]
years but there currently are as follows
it's a 25-minute conversation and in
order to win to pass the test you have
to fool 50 percent of the judges with
which the system communicates mitsugu
and rose from Steve Warwick and Bruce

[08:31]
and rose from Steve Warwick and Bruce
Wilcox have been dominating the past ten
years winning all but one of the years
some details
Masuka rows are both mostly scripted
rule-based chatbots so they're not and
to end learning systems I believe there

[08:48]
to end learning systems I believe there
is a little bit of machine learning but
as as I understand at the core there
mostly scripted and on the next slide
we'll go through a transcript of a
conversation with mitsuko to give you a
sense of what those conversations are

[09:00]
sense of what those conversations are
like but I'd like to mention sort of a
tragic note really that as far as I
understand the prize is no longer funded
but money aside it shows that there's
not a broad interest in this
construction both inside and outside the

[09:16]
construction both inside and outside the
research community it's really
surprising to me that google deepmind
facebook AI major groups major
individual researchers in the field of
AI have not taken on this challenge I
hope to actually be a small part of

[09:31]
hope to actually be a small part of
changing that a little bit because I
think there is a lot of value in
considering the Turing test I don't
think as a distraction and I'll return
to that point later on in this
datian so you can pause and maybe read
parts of this transcript I'll highlight

[09:45]
parts of this transcript I'll highlight
on the right at the top of the right
column the human says you're a robot
Mitsuko answers how can a person be a
robot human many people live lives akin
to robots Mitsuko how many more than a

[10:00]
to robots Mitsuko how many more than a
million human yes Mitsuko that seems
like rather a lot human do you think
Southampton will be Swansea with suku I
think so human why it's so good no
reason it's just what I think human he

[10:17]
reason it's just what I think human he
must have a reason Masuka nope
no real reason human which team do you
support
Mitsuko I support Leeds United human
leads exclamation point how's the season

[10:30]
leads exclamation point how's the season
going Masuku yes it is a city in the
north of England about half a million
people live there it is the same as ever
so you see in this transcript it's just
some little gap of in humanity that

[10:46]
some little gap of in humanity that
becomes apparent there's a lingering and
a repeatability of points there's
certain gaps in understanding and
ability to follow tangents all those
kinds of things but it's still not clear

[11:01]
kinds of things but it's still not clear
to me as an open question how to make
explicit where exactly the point of the
failure of the test is I believe that
hasn't actually been really researched

[11:15]
hasn't actually been really researched
that well in these constructions as
opposed to decision making at the very
end of a conversation is this human or
not rather marking parts of a
conversation is more or less human like
suspicious parts that make you wonder
this is not human I think they'll be

[11:31]
this is not human I think they'll be
really interesting to see if it's
possible to make explicit what aspects
of the conversation are the failure
points one of the times that the claim
that the Turing test was passed I think
most famously was in 2014 at an
exhibition event that marked the 60th

[11:46]
exhibition event that marked the 60th
anniversary of drawings death eugene
goostman fooled 33% of the event judges
and the method he used was to portray a
13 year old Ukrainian boy that had a
bunch of different personality quirks
and obviously the language barrier and

[12:01]
and obviously the language barrier and
had some humor and a constant sort of
drive towards misdirecting the
conversation back to the places where it
was comfortable doing so there's some
criticism the committee of this event
due to some sort of smoke and mirrors

[12:16]
due to some sort of smoke and mirrors
kind of the PR marketing side of things
that that I think is always there with
these kind of exhibition events but
setting that aside I think the
interesting lessons here is that the

[12:30]
interesting lessons here is that the
parameters the rules of the actual
engineering of the Turing test can
determine whether it contains sort of
the spirit of the Turing test which is
the test that captures the ability of of

[12:45]
the test that captures the ability of of
an agent to have a deep meaningful
conversation so in this case you can
argue that a few tricks were used to
circumvent the need to have a deep
meaningful conversation and 30% of

[13:00]
meaningful conversation and 30% of
judges were fooled without rigorous
thorough transparent open domain testing
on the left is a transcript with Scott
Harrison the famed computer scientist
quantum computing researcher talked to
him on the podcast brilliant guy he

[13:16]
him on the podcast brilliant guy he
posted some of the conversation that he
had with Eugene he was one of the judges
on his blog that I think is really
interesting so it shows that the judge
the interrogator when they're an expert
they can drive they can truly put the

[13:30]
they can drive they can truly put the
the bot to the test Scott did he really
didn't allow the kind of misdirection
the Eugene non-stop tried to to do and
you could see that in the transcript
Scott refuses to take the misdirection
so as I mentioned despite the waning I

[13:47]
so as I mentioned despite the waning I
guess popularity of the lobner prize and
the Turing test idea in general Google
has published the paper and proposed a
system called Mena
that's a chatbot that's an end-to-end

[14:00]
that's a chatbot that's an end-to-end
deep learning system
presentation of goal in the 2.6 billion
parameters is to capture the
conversational context well to be able
to generate the text that fits the
conversation context well now one
interesting aspect of this besides being

[14:15]
interesting aspect of this besides being
a serious attempt at creating a
learning-based system for open domain
conversational agents is that a new
metric is proposed and it's a two-part
metric of sensibleness and specificity
now sensibleness is that a boss

[14:31]
now sensibleness is that a boss
responses have to make sense in context
they have to fit the context just give
you a sense for humans who have 97
percent sensibleness so ability to match
what we're saying to the to the context
now the reason you need another side of

[14:48]
now the reason you need another side of
that metric is because you can be
sensible you can fit the context by
being boring by being generic by making
statements like I don't know or that's a
good point so if these generic
statements that fit a lot of different

[15:01]
statements that fit a lot of different
kinds of contexts so the other side of
the metric is specificity basically the
goal being there is don't be boring is
to say something very specific to this
context so not only does it match the
context but it captures something very

[15:16]
context but it captures something very
unique to this particular set of lines
of conversation that form the context I
think it's fair to say that the the
beauty the music the the humor the wit

[15:30]
beauty the music the the humor the wit
of conversation comes from that ability
to play with the specifics the
specificity metric so both are really
important
humans achieve 86% sensibleness and
specificity mean achieved seventy-nine

[15:45]
specificity mean achieved seventy-nine
percent compared to mitsugu who achieves
56% now take this all with a grain of
salt I want to be very careful here
because there is also not to throw shade
but it's close source currently and

[16:00]
but it's close source currently and
there's a little bit of a feeling of a
PR marketing situation here naturally
perhaps the paper is made in such a way
the methodology and the results are made
in such a way that benefit the way the
learning framework was constructed

[16:16]
learning framework was constructed
now that's I don't want to over
criticize that because I think there's
still a lot of interesting ideas in this
paper but in terms of looking at the
actual percentages of 86 percent human
performance and 79 percent meaning a
performance I think we're quite away

[16:31]
performance I think we're quite away
from being able to make conclusive
statements about a system achieving
human level conversational capabilities
so those plots should be taken with a
grain of salt but the actual content of
the idea is I think is really
interesting I think quite obviously the

[16:46]
interesting I think quite obviously the
future long term but hopefully short
term is in learning end to end
learning based approaches to open domain
conversation so just like drawing
described funny enough 70 years ago on

[17:00]
described funny enough 70 years ago on
this paper that machine learning it
would be essential to success I I
believe the same it's a lot less
interesting and revolutionary to think
so today but I believe that machine
learning will also need to be a very
central part of achieving human level

[17:16]
central part of achieving human level
conversational capabilities so let's
talk through some objections nine of
them are highlighted by Turing himself
in his paper here provides some informal
highly informal summaries the first

[17:31]
highly informal summaries the first
objection is religious which connects
thinking to quote unquote the soul and
God presumably is the giver of the soul
to humans now Tory's response to that is

[17:46]
to humans now Tory's response to that is
God is all-powerful there is no reason
why he can't assign souls to anything
biological or artificial so it doesn't
seem that whatever mechanism by which

[18:01]
seem that whatever mechanism by which
the soul arrives in the human cannot
also be repeated for artificial
creatures the second objection is the
quote unquote head in the sand it's a
bit of a ridiculous one but I think it's
an important one because it keeps coming

[18:15]
an important one because it keeps coming
up often even in today's context
highlighted by folks like you know I
musk Stuart Russell and so on the head
in the sand objection is that AGI is
scary so human level and super human
level intelligence

[18:30]
level intelligence
scary today we talk about is existential
threats it seems like the world would be
totally transformed if we have something
like that then it could be transform in
a highly negative way so let's not think
about it because it kind of seems far
away so it probably won't happen so

[18:46]
away so it probably won't happen so
let's just not think about it that's
kind of the objection of the Turing test
it's so far away it's not worthwhile to
even think about a test for this
intelligence or what human level
intelligence means or what superhuman
level intelligent means the response

[19:01]
level intelligent means the response
quite naturally is that it doesn't
matter how you feel about something on
whether it's going to happen or not so
we kind of have to set our feelings
aside and not allow fear or emotion to
model our thinking or detract us from

[19:17]
model our thinking or detract us from
thinking about it at all the third
objection is from Gaydos incompleteness
theorem saying there's limits to
computation this is the Roger Penrose
line of thinking that basically if a
machine is a computation system there is

[19:31]
machine is a computation system there is
limited capabilities in that it can
never be a perfectly rational system
Tony's response to this is that humans
are not rational either they're flawed
nowhere does it say that intelligence
equals infallibility in fact it could

[19:46]
equals infallibility in fact it could
probably be argued that phal ability is
at the core of intelligence the fourth
objection is that consciousness may be
required for intelligence Touring's
response to this is to separate whether
something is conscious and whether

[20:01]
something is conscious and whether
something appears to be cautious so the
focus of the Turing test is how
something appears and so in some sense
humans to us as far as we know only
appear to be cautious we can't prove
that they're actually conscious humans

[20:15]
that they're actually conscious humans
outside of ourselves and so since humans
only appear to be cautious there's no
reason to think that machines can't also
appear to be cautious and that's at the
core of the Turing test
so the Turing test kind of skirts around
the question of whether something is or

[20:31]
the question of whether something is or
isn't intelligence whether is or isn't
conscious the fundamental question is
does it appear to be intelligent does it
appear to be cautious so he actually
doesn't respond to the idea that
consciousness is or isn't required
for intelligence he just says that if it

[20:46]
for intelligence he just says that if it
is there's no reason why you can't fake
it and that will be sufficient to
achieve the display of intelligence the
fifth objection is the negative Nancy
objection of machines will never be able

[21:02]
objection of machines will never be able
to do X whatever X is you can make it
love joke humor understand to generate
humor
eat enjoy food create art music poetry

[21:15]
eat enjoy food create art music poetry
and so on so there's a lot of things we
could put in that X the machines could
never do and basically highlighting our
human intuition about the limitations of
machines just like well the second
objection
naturally the response here is that the

[21:31]
naturally the response here is that the
objection that machines will never do X
doesn't have any actual reasoning behind
it is just a vapid opinion based on the
world today refusing to believe that the

[21:45]
world today refusing to believe that the
world of tomorrow will be different the
sixth objection probably the most
important one the most interesting comes
by way of Ada Lovelace lady Lovelace the
mother of computer science it was a
basic idea that machines can only do

[22:01]
basic idea that machines can only do
what we program them to do now this is
an objection that appears in many forms
throughout before touring and after
touring and I think it's a really
important objection to think about so in
this particular case I think Turia's

[22:15]
this particular case I think Turia's
response is quite shallow but it is
nevertheless pretty interesting and
we'll talk about it again later on his
responses well if machines can only do
what we programmed them to do we can
rephrase that statement as saying

[22:30]
rephrase that statement as saying
machines can't surprise us and when you
rephrase it that way it becomes clear
that machines actually surprised us all
the time a system that is sufficiently
complex will no longer be one of which
we have a solid intuition of how it

[22:46]
we have a solid intuition of how it
behaves even if we built all the
individual pieces of code for those of
you have programmed things so I've
written a lot of programs
in the initial design stage of an
intuition about how it should behave
there's a design there's a plan

[23:00]
there's a design there's a plan
you know what the individual functions
do but as the piece of code grows your
ability to intuit exactly the mapping
from input to output fades with the size
of the code base even if you understand

[23:15]
of the code base even if you understand
everything about the code and even if
you said logical and syntactic bugs
aside the
objection looks to the brain and looks
to the continuous analog nature of that
particular neural network system so

[23:30]
particular neural network system so
Touring's response to that is sure the
brain might be analog and then computer
digital computers are discrete but if
you have a big enough digital computer
it can sufficiently approximate the
analog system meaning to a sufficient

[23:46]
analog system meaning to a sufficient
degree that it would appear intelligent
the eighth objection is the freewill
objection right is that when you have
deterministic rules laws algorithms
they're going to result in predictable

[24:03]
they're going to result in predictable
behavior and this kind of exactly
deterministic predictable behavior
doesn't quite feel like the mind that we
know us humans as possessing this kind

[24:17]
know us humans as possessing this kind
of feeling that underlies what's
required for intelligence for a mind I
think is behind the Chinese room thought
experiment that we'll talk about next
so Touring's response here is that

[24:32]
so Touring's response here is that
humans very well could be a complex
collection of rules there's no
indication that we're not just because
we don't understand or don't even have
the tools to explore the kind of rules

[24:45]
the tools to explore the kind of rules
that underlie our brain doesn't mean
it's not just a collection of
deterministic perfectly predictable sets
of rules objection number nine is kind
of fun
quite possibly Turing is throwing us but

[25:02]
quite possibly Turing is throwing us but
more likely the ideas of mind-reading
extrasensory perception telepathy were a
little bit more popular in his time so
the objection here is what if
mind-reading was used to cheat the test

[25:15]
mind-reading was used to cheat the test
so basically if human to human
communication through telepathy could be
used then a machine can't achieve that
same kind of telepathic communication
and so that can be used to uh to
circumvent the effectiveness of the test

[25:32]
circumvent the effectiveness of the test
now
join us response to this is well you
just have to design our room that not
only protects you from being able to see
whether it's a robot or a human but also
design a telepathy proof room that

[25:47]
design a telepathy proof room that
prevents telepathic communication again
could be touring trolling us but I think
more importantly I think it's a nice
illustration at the time and even still
today that there's a lot of mystery

[26:00]
today that there's a lot of mystery
about how our mind works
if you chuckle and completely laugh off
the possibility of telepathic
communication I think you're assuming
too much about your own knowledge about
how our mind works I think we know very
little about how our mind works it is

[26:16]
little about how our mind works it is
true we have very little scientific
evidence of telepathic communication but
that shouldn't you shouldn't take the
next leap and have a feeling like you
understand that telepathic communication
is impossible you should nevertheless

[26:30]
is impossible you should nevertheless
maintain an open mind but as an
objection it doesn't seem to be a very
effective one I wanted to dedicate just
one slide and probably the most famous
objection to the Turing test proposed by
John Searle in 1980 in his paper minds
brains and programs commonly known as

[26:47]
brains and programs commonly known as
the Chinese room thought experiment and
it's kind of a combination of number
four number six and number eight
objections in the previous slide which
is the consciousness is required for
intelligence the ada lovelace objection

[27:02]
intelligence the ada lovelace objection
that programs can only do what we
program them to do and the deterministic
free will objection that deterministic
rules will lead to predictable behavior
and that doesn't seem to be like what

[27:15]
and that doesn't seem to be like what
the mind does so there's echoes of all
those objections that toring anticipated
all put together into the Chinese room
as a small aside it is now 6 a.m. I did
not sleep last night so this video is

[27:31]
not sleep last night so this video is
brought to you by this magic potion
called nitro cold brew a an excessively
expensive canned beverage from Starbucks
that fuels
me this wonderful Saturday morning

[27:48]
me this wonderful Saturday morning
here's to you dear friends okay the
Chinese room involves following
instructions of an algorithm so there's
a human sitting inside a room that
doesn't know how to speak Chinese but

[28:02]
doesn't know how to speak Chinese but
there's notes being passed to them
inside the room from outside in Chinese
and all they do is follow a set of rules
in order to respond to that language so
the idea is if the brain inside the

[28:19]
the idea is if the brain inside the
system that passes the Turing test is
simply following a set of rules that
it's not truly understanding it is not
conscious it does not have a mind the

[28:30]
conscious it does not have a mind the
objection is philosophical so there's
not for my computer science engineering
self there's not enough meat in it to
even make it that interesting it's very
human centric but allow us to explore it
further
so the key argument is that programs

[28:48]
so the key argument is that programs
computational systems are formal and so
they can capture syntactic structure
minds our brains have mental content so

[29:00]
minds our brains have mental content so
they can capture semantics and so the
claim that I think is the most important
the clearest in the paper is that syntax
by itself is neither constitutive of nor
sufficient for semantics so just because
you can replicate the syntax of the

[29:16]
you can replicate the syntax of the
language doesn't mean you can truly
understand it and this is the same kind
of criticism we hear of language models
of today with transformers that opening
is gp2 really doesn't understand the
language
it's just mimicking the statistics of it

[29:31]
it's just mimicking the statistics of it
so well that it can generate
syntactically correct and even like have
echoes of semantic structure that
indicates some kind of understanding but
it doesn't to me that argument is not
very interesting from an engineering

[29:46]
very interesting from an engineering
perspective because it just sounds like
saying humans can understand things
humans are special
therefore machines cannot understand
things
it's a very human centric argument
that's not allowing us to rigorously

[30:01]
that's not allowing us to rigorously
explore what exactly this understanding
mean from a computational perspective or
put in other words if understanding
intelligence consciousness either one of
those is not achievable through

[30:16]
those is not achievable through
computation then where is the point that
computation hits the wall the most
interesting open questions to me here
are on the point of faking things or
mimicking or the appearance of things
does the mimicking of thinking equal

[30:31]
does the mimicking of thinking equal
thinking does the mimicking of
consciousness equal consciousness does
the mimicking of love equal love this is
something that I think a lot about and
depending on the day go back and forth
but I tend to believe from an
engineering perspective I tend to agree

[30:46]
engineering perspective I tend to agree
with the spirit and the work of Alan
Turing in that at this time as engineers
we can only focus on building the
appearance of thinking the appearance of
consciousness the appearance of love I
think as we work towards creating that

[31:01]
think as we work towards creating that
appearance will actually begin to
understand the fundamentals of what it
means to be conscious what it means to
love what it means to think you may have
even heard me say sometimes that the

[31:15]
even heard me say sometimes that the
appearance of consciousness is
consciousness I think that's me being a
little bit poetic but I think from our
perspective from our exceptionally
limited understanding both problems are
in the same direction so it's not like

[31:32]
in the same direction so it's not like
if we focus on creating the appearance
of consciousness that's going to lead us
astray in my personal view is going to
lead us very far down the road of
actually understanding and maybe one day
engineering consciousness and now I'd
like to talk about some alternatives and

[31:46]
like to talk about some alternatives and
variations the Turing test that I find
quite interesting so there's a lot of
kind of natural variations and
extensions to the Turing test first the
total Turing test proposed in 1989 it

[32:00]
total Turing test proposed in 1989 it
extends the Turing test in the natural
language conversation domain to
perception computer vision and obviously
manipulation of robotics so it takes it
into the
world the interesting question here to
me is whether adding extra modalities

[32:17]
me is whether adding extra modalities
like audio visual manipulation makes the
test harder or easier to me is very
possible that a test with a narrow
bandwidth of communication such as the

[32:32]
bandwidth of communication such as the
natural language communication the
Turing test is actually harder to pass
than the one that includes other
modalities but anyway one of the
powerful things about the original
Turing test is that is so simple the

[32:45]
Turing test is that is so simple the
Lovelace test proposed in 2001 builds on
the Ada Lovelace objection to form the
test that says the machine has to do
something surprising that the creator or
the person who's aware how the program

[33:02]
the person who's aware how the program
was created cannot explain so it should
be truly surprised there is also in 2014
was proposed Lovelace 2.0 test which
emphasizes a more constrained definition

[33:15]
emphasizes a more constrained definition
of what surprising is because it's very
difficult to pin down to formalize the
idea of surprise and explain right in in
the original formulation of the Lovelace
test but with Lovelace 2.0 it emphasizes
sort of creativity art so on so it's

[33:33]
sort of creativity art so on so it's
more concrete than surprise especially
if you define constraints to which
creative medium we're operating in you
basically have to create an impressive
piece of artistic work I think that's an

[33:48]
piece of artistic work I think that's an
interesting conception but it takes us
in the land that's much more not less
subjective than the original Turing test
but this brings us to the open and the

[34:01]
but this brings us to the open and the
very interesting question of surprise
which i think is really at the core of
our conception of intelligence I think
it is true that our idea of what makes
an intelligent machine is one that

[34:15]
an intelligent machine is one that
really surprised us so when we one day
finally create a system of human level
or superhuman level intelligence
we will surely be surprised so we have
to think what kind of behavior is one
that will surprise this to the core to

[34:30]
that will surprise this to the core to
me I have many examples in mind that
I'll cover in future videos but one
certainly one of the hardest ones is
humor and finally the truly total Turing
test proposed in 1998 proposes an

[34:46]
test proposed in 1998 proposes an
interesting philosophical idea that we
should not judge the performance of an
individual agent in an isolated context
but instead look at the body of work
produced by a collection of intelligent

[35:00]
produced by a collection of intelligent
agents throughout their evolution with
some constraints on the consistency
underlying you know the evolutionary
process it's interesting to suggest that
the way we conceive of intelligence

[35:15]
the way we conceive of intelligence
amongst us humans is grounded in the
long arc of history of the body of work
we've created together I don't find that
argument convincing but I do find the
interesting question and the open
question the idea that we should measure

[35:33]
question the idea that we should measure
systems not in the moment or a
particular five-minute period or 20
minute period but over a period of
months and years perhaps condensed in a
simulated context so really increase the

[35:47]
simulated context so really increase the
scale at which we judge interactions by
several orders of magnitude that to me
is a really interesting idea you know to
judge alpha zero performance not on a

[36:02]
judge alpha zero performance not on a
single game of chess but looking at
millions of games and not looking at a
million games for a static set of
parameters but looking at the millions
of games played as the system was

[36:15]
of games played as the system was
strained from scratch and became better
and better and better there's something
about that full journey that may capture
intelligence so intelligence very well
could be the journey not the destination

[36:30]
could be the journey not the destination
I think there's something there it's
very imprecise in this construction but
it struck me as a as a very novel idea
for benchmark not to measure
instantaneous performance but
performance over time in the improvement

[36:45]
performance over time in the improvement
of performance over time it appears that
there's something to that but I can't
quite make it concrete and I'm not sure
as possible to formalize in the way that
the original Turing test is formalized
another kind of test is the Winograd
schema challenge which i think is really

[37:01]
schema challenge which i think is really
compelling and in many ways so first to
explain it with an example there's a
sentence really two sentences let's say
the trophy doesn't fit into the brown
suitcase because it's too small and the
trophy doesn't fit into the brown

[37:15]
trophy doesn't fit into the brown
suitcase because it is too large and the
question is what is too small what is
too large the answer for the small what
is too small is the suitcase is too
small the trophy doesn't fit into the
brown suitcase because it is too small

[37:30]
brown suitcase because it is too small
and then the second question is what is
too large the answer there is the trophy
that trophy doesn't fit into the brown
suitcase because it is too large the
basic idea behind this challenge is the
ambiguity and the sentence can only be

[37:46]
ambiguity and the sentence can only be
resolved with common-sense reasoning
about ideas in this world and so the
strength of this test is it's quite
clear quite simple and yet requires the
least in theory this this deep thing

[38:02]
least in theory this this deep thing
that we think makes us human which is
the ability to reason at the very basic
level of common sense reasoning the
other nice thing is it can be a
benchmark like we're used to in the

[38:16]
benchmark like we're used to in the
machine learning world that doesn't
require subjective human judges there's
literally a right answer the weakness
here that's holds for other similar
challenges in the space is that it's

[38:30]
challenges in the space is that it's
very difficult to come up with a large
amount of questions I mean each one is
handcrafted and so that means you can't
build a benchmark of millions or
billions of questions it has to be on a
small scale variations of the Winograd

[38:48]
small scale variations of the Winograd
scheme are included
and some natural language benchmarks of
today that people use in the machine
learning context the Amazon elect
surprise
I think captures nicely the spirit of

[39:03]
I think captures nicely the spirit of
the Turing test I think it's actually
quite an amazing challenge and
competition that uses voice conversation
in the wild so with real people and they
can use a I think it's called a social
bot skill on there Alexa devices and I

[39:17]
bot skill on there Alexa devices and I
don't want to wake up my own Alexa
devices but basically say her name and
say let's chat and that brings up one of
the bots involved in the challenge and
then you can have a conversation and
then the bar that's to be reached is for

[39:32]
then the bar that's to be reached is for
you to have a twenty minute or longer
conversation with the bot and for
two-thirds or more of the interactions
to be that long so the basic metric of
successful interaction is the duration

[39:45]
successful interaction is the duration
of the interaction and as of today we're
still really really far away from that
so why is this a good metric and I do
think it's a really powerful metric as
opposed to us judging the quality of
conversation in retrospect we speak with
our actions so a deep meaningful

[40:02]
our actions so a deep meaningful
conversation is one we don't want to
leave when we have other things
contending for our time when we make the
choice to stay in that conversation
that's as powerful a signal as any to

[40:15]
that's as powerful a signal as any to
show that that conversation has content
has meaning is enjoyable I think that
it's what passing the Turing test in its
original spirit actually is and I should
mention that as of today no team has

[40:31]
mention that as of today no team has
even come close to passing the Turing
test as it is constructed by the Alexa
prize there are several things that are
really surprising about this challenge
one is that it's not a lot more popular
and two that Amazon chose to limit it to

[40:46]
and two that Amazon chose to limit it to
students only I mean almost making it an
educational exercise as opposed to a
moonshot challenge for our entire
generation of researchers I mentioned
before but I'll say it again here that

[41:00]
before but I'll say it again here that
it's surprising to me that the biggest
research lab
industry and academia have not focused
on this problem have not found the magic
within the Turing test problem and the
elect surprise as it formulates I
believe the spirit of the Turing tests

[41:18]
believe the spirit of the Turing tests
quite well a very different kind of test
is the hotter price that I buy markers
hotter which I think is really
fascinating on both a philosophical
mathematical angle underlying it is the

[41:31]
mathematical angle underlying it is the
idea that compression is strongly
correlated with intelligence put another
way the ability to compress knowledge
well requires intelligence and the
better you compress that knowledge the

[41:46]
better you compress that knowledge the
more intelligent you are I think this is
a really compelling notion because then
we can make explicit we can quantify how
intelligent you are by how well you're
able to compress knowledge as the prize

[42:01]
able to compress knowledge as the prize
webpage puts it being able to compress
well is closely related to acting
intelligently thus reducing the slippery
concept of intelligence to hard file
size numbers so the task is to take one

[42:15]
size numbers so the task is to take one
gigabyte of Wikipedia data and compress
it down as much as possible the current
best is a eight point five eight
compression factor so down from one
gigabyte to one hundred seventeen
megabytes and the awards for each one

[42:31]
megabytes and the awards for each one
percent improvement you win five
thousand euros I find this competition
just amazing and fascinating on many
levels I think it's a really good
formulation of an intelligence challenge

[42:45]
formulation of an intelligence challenge
but it's not a test that's one of his
kind of limitations at least in the
poetic sense that it doesn't set a bar
beyond which we're really damn impressed
meaning it's harder to set a bar like
the one formulated by the Turing test

[43:00]
the one formulated by the Turing test
beyond which we feel it would be human
level intelligence now the bar that's
set by the Turing Alan Turing and others
the lobna prize alexa prize are also
arbitrary but it feels like we're able
to intuit a good bar in that context
better

[43:16]
better
being able to intuit the kind of bar we
need to set for the compression
challenge another fascinating challenge
is the abstraction and reasoning
challenge put forth by francois charlet
just a few months ago so this is very
exciting it's actually ongoing is a

[43:30]
exciting it's actually ongoing is a
competition on Kegel I think with the
deadline in May it's a really really
interesting idea I haven't internalized
it fully yet and perhaps we'll do a
separate video on just this paper alone
and I'll talk to Francois I'm sure on

[43:45]
and I'll talk to Francois I'm sure on
the podcast and other contacts in the
future about it
I think there's a lot of brilliant ideas
here that I still have to kind of digest
a little bit but let me describe the
high level ideas behind this benchmark
so first of all the name is abstraction

[44:02]
so first of all the name is abstraction
reason in corpus or challenge arc the
domain is in a grid world of patterns
not limited in size but the grid world
is filled with cells that can be of
different colors and the spirit of the

[44:17]
different colors and the spirit of the
set of tests that Francois proposes is
to stay close to IQ test so psychometric
intelligent tests that we use to measure
the intelligence of human beings
now the Turing test is kind of at a

[44:31]
now the Turing test is kind of at a
higher level of natural language in this
construction of Arc it goes as close as
possible to the very basic elements of
reasoning just like an attic you test of

[44:46]
reasoning just like an attic you test of
patterns it gets to the very core such
that we can then make explicit the
priors the concepts that we bring to the
table of those tests and if we can make
them explicit it reduces the test as

[45:02]
them explicit it reduces the test as
close as possible to the measure of the
system's ability to reason now the
concepts that are brought to this grid
world here's just a couple of example of
priors that Francois shows in his paper

[45:15]
priors that Francois shows in his paper
I recommend highly it called on the
measure of intelligence here prior
concept is not referring to a previous
concept is referring to a prior set of
knowledge that you bring to the table so
this first row of illustrations of the
two

[45:30]
two
world's illustrates the idea of object
persistence with noise so we're able to
understand that large objects when there
is some visual noise occluding our

[45:45]
is some visual noise occluding our
ability to see them that they still
exist in the world and if that noise
changes the object is still unchanged so
that that idea of object persistence in
the world is as a prior that we bring to

[46:00]
the world is as a prior that we bring to
the table of understanding this grid
world another prior is on the left at
the bottom is objects are defined by
spatial contiguity so so objects in this
grid world when the cells are the same

[46:17]
grid world when the cells are the same
color and they're touching each other
they're probably part of the same object
and if there's black cells that separate
the those groupings of cells that means
there's multiple objects so this kind of
spatial contiguity of colored cells

[46:33]
spatial contiguity of colored cells
defined the entity of the object and on
the right at the bottom is the color
based contiguity which means that even
if the cells of different colors are

[46:45]
if the cells of different colors are
touching if their colors are different
that means it likely belongs to a
different object that's the basic prior
and there's a few others by the way just
beautiful pictures in that paper that
make you really think about the core

[47:01]
make you really think about the core
elements of intelligence I love that
paper worth worth looking at there's a
lot of interesting insights in there
just to give you some examples of what
the actual task for the machine in this
test looks like it's similar to the kind

[47:16]
test looks like it's similar to the kind
of task we've seen in an IQ test so here
there's three pairings and the task is
for the fourth pairing of images to
generate the grid world that fits the

[47:30]
generate the grid world that fits the
other three that fits the generating
pattern of the other three so in this
case figure four from the paper a task
where the implicit goal is to complete a
symmetrical pattern the nature of the
task is specified
by the three input-output examples the

[47:45]
by the three input-output examples the
test-taker must generate the output grid
corresponding to the input grid of the
test input bottom right so here will
your task with understanding in the
first three pairings is that the input
has a perfect global symmetry to it and

[48:05]
has a perfect global symmetry to it and
also that there's parts of the image
that are missing that can be filled in
order to complete that perfect symmetry
now that's relying on another prior

[48:16]
now that's relying on another prior
another basic concept of symmetry which
I think underlies a lot of our
understanding of visual patterns again
so the intelligent system has to have a
good representation of symmetry in

[48:30]
good representation of symmetry in
various contexts this is fascinating and
beautiful beautiful images okay another
example figure 10 from the paper a task
where the implicit goal is to count
unique objects and select the objects
that appears the most times the actual

[48:46]
that appears the most times the actual
task has more demonstration pairs in
these three so figure 10 here from the
paper a task where the implicit goal is
to count unique objects and select the
objects that appear the most times so
again there's three pairings you see in

[49:01]
again there's three pairings you see in
the first one there's three blue objects
and the second one is four yellow
objects and the third one there's three
red objects so you have to figure that
out and then the output is the grid
cells capturing that object that appears

[49:15]
cells capturing that object that appears
the most times and so apply that kind of
reasoning to complete the output of the
fourth pairing one of the challenges for
this kind of test is it's difficult to
generate but just like I said I think
there's a lot of really interesting

[49:30]
there's a lot of really interesting
technical and philosophical ideas here
that are worth exploring so let's
quickly talk through a few takeaways so
zooming
is the Turing test a good measure of
intelligence and can it serve as an

[49:45]
intelligence and can it serve as an
answer to the big ambiguous but profound
philosophical questions of chem machines
think so first some notes on the
underlying challenges of the Turing test
let's talk about intelligence so if we

[50:01]
let's talk about intelligence so if we
compare human behavior and intelligent
behavior it's clear that the Turing test
hopes to capture the intelligent parts
of human behavior but if we're trying to
really capture human level intelligence

[50:17]
really capture human level intelligence
it's also possible that we want to
capture the unintelligent irrational
parts human behavior so it's an open
question or the natural conversation is
a test of intelligence or humaneness

[50:33]
a test of intelligence or humaneness
because if it's a test of intelligence
it's focusing only on kind of rational
systematic thinking if it's a test of
humaneness then you have to capture the
full range of emotion the mess the

[50:46]
full range of emotion the mess the
irrationality the laziness the boredom
all the things that make us human and
all the things that then project
themselves into the way we carry out
through conversation as I mentioned in
the previous objectives the Turing test

[51:00]
the previous objectives the Turing test
really focuses on the external
appearances not the internal processes
so like I said from an engineering
perspective I think it's very difficult
to create a test for internal processes
for some of these concepts that we have

[51:15]
for some of these concepts that we have
a very poor understanding of like
intelligence like consciousness I think
the best we can do right now in terms of
quantifying and having a measure of
something we have to look at the
external performance of the system as

[51:31]
external performance of the system as
opposed to some properties of the
internal processes another challenge for
the Turing test as Scott our instance
conversation we gene Guzman indicates is
that the skill of the interrogator is

[51:45]
that the skill of the interrogator is
really important here that's both on the
just the conversational skill of how
much you can stretch and challenge the
conversation with
and to on the human side of it the
ability of the interrogator identified

[52:00]
ability of the interrogator identified
the humaneness of both the human and the
machine so the ability to have a
conversation that challenges the bot and
the ability to make the actual
identification of human or machine
those are both skills that are essential

[52:16]
those are both skills that are essential
to the Turing test also to me is really
interesting the anthropomorphize a ssin
of human to inanimate object interaction
I think is really fascinating and it's

[52:31]
I think is really fascinating and it's
an open question whether in some
construction of the Turing test whether
anthropomorphism is leveraged to
convince the human whether that's
cheating the Turing test or in fact
that's an essential element to
convincing us humans that something is

[52:46]
convincing us humans that something is
intelligent perhaps as a starting point
we have to anthropomorphize something
before we allow to be intelligent in our
subjective judgment of its intelligence
and finally another limitation of the

[53:01]
and finally another limitation of the
Turing test that could be narrowly
stated as why do we expect a bot to talk
what is it why what if it doesn't feel
like talking does it still fail I think
a more general way to phrase that is why

[53:15]
a more general way to phrase that is why
do we judge the performance of a system
on such a narrow window of time I think
as I mentioned before this there could
be something interesting on expanding
the window of time over which we analyze

[53:31]
the window of time over which we analyze
the intelligence of the system looking
not just at the average performance but
the growth of its performance as it
interacts with you as the individual I
think one key aspect of intelligence is
a social aspect and a social connection

[53:49]
a social aspect and a social connection
I think in part may require getting to
know the person and there's something to
rethink in the Turing test that relies
on us building a relationship with a
person as part of the test so you could

[54:02]
person as part of the test so you could
think of it as kind of the ex machina
Turing test where they
spent a series of conversations together
several days together all those kinds of
things that feels like an interesting

[54:15]
things that feels like an interesting
extension of the Turing test which could
reveal the significant limitation of the
current construction of the Turing test
which is a limited window of time one
time at the end interrogator judgment of
whether it's human or machine now my

[54:32]
whether it's human or machine now my
view overall on the Turing test is that
yes something like the Turing test as
originally constructed so the natural
language conversation is close to the

[54:45]
language conversation is close to the
ultimate test of intelligence and
moreover this is where I disagree I
think I disagree with Francois shalay
and other world-class researchers in the
areas through it Russell and so on that
I think the Turing test is not a
distraction for us to think about it

[55:01]
distraction for us to think about it
doesn't pull us away from actually
making progress in the field I think it
keeps us honest I think truly analyzing
where we stand in natural language
conversation will help us understand how

[55:15]
conversation will help us understand how
far away we are and more than that I
think there should be active research on
this field I think the love the prize
type of formulations the elect surprise
formulations should be more popular than
they are and I think researchers should
take them very seriously now that

[55:32]
take them very seriously now that
doesn't mean that the the work of the
the arc benchmark with the IQ test type
of intelligent tests is not also going
to be fruitful potentially very fruitful
but I think ultimately the real and test

[55:48]
but I think ultimately the real and test
of human level intelligence will occur
in something like the construction of
the Turing test with natural language
open domain conversation the results in
deep meaningful connection between human

[56:02]
deep meaningful connection between human
and machine zooming out a little bit I
think in general I think AI researchers
don't like and try to avoid the
messiness of human beings as is captured

[56:16]
messiness of human beings as is captured
by the human robot interaction field and
set of problems I think
more than just embracing the Turing test
I think we should embrace the messiness
of the human being in all the different
domains of computer vision of natural

[56:32]
domains of computer vision of natural
language of robotics autonomous vehicles
I've been a longtime advocate that semi
autonomous vehicles are here to stay for
a long time we're going to have to
figure out the human robot interaction
problem and for that we have to embrace

[56:48]
problem and for that we have to embrace
perceiving everything about the human
inside the car perceiving everything
about the humans outside the car as I
mentioned this presentation of the paper
is actually part of our paper reading

[57:00]
is actually part of our paper reading
club focused on artificial intelligence
where we discuss a couple of times a
week on the discord server called Lex
plus AI podcast they you're welcome to
join we have an amazing community of
brilliant people there that discuss all

[57:15]
brilliant people there that discuss all
kinds of topics in artificial
intelligence and beyond this particular
illustration that I just love is from
will Scobie who's an illustrator from
United Kingdom who is part of this
discord community so he contributed it

[57:30]
discord community so he contributed it
and in general aside from the amazing
conversations I encourage and hope to
see other members of the community
contribute art code visualizations
slides ideas for these kinds of videos
I'm really excited by the kind of

[57:47]
I'm really excited by the kind of
conversations I've seen if you're
watching this video I want to join in
click on a discord link in the
description on the slide
join the conversation new paper every
week it's fun just to give you a little

[58:00]
week it's fun just to give you a little
sense of the ideas behind this AI paper
reading Club like what the goals are so
what is it I think the goal is to take a
seminal paper in the field that doesn't
just focus in on the specific sort of
paragraph to paragraph section of

[58:16]
paragraph to paragraph section of
section analysis what the papers saying
but actually use the paper to discuss
the history the big-picture development
of the field within the context of that
paper now that could be philosophical
papers like the storm-tossed paper or it

[58:30]
papers like the storm-tossed paper or it
could be very specific papers in the
field again physics mathematics compete
science and probably quite a bit of deep
learning so the hope is to prioritize
beautiful powerful impactful insights as
opposed to full coverage of all the

[58:47]
opposed to full coverage of all the
contents of the paper and the actual
meanings on this chord hopefully are
less one person presenting and more
discussion there's a lot of brilliant
people there civil so you can have 300

[59:01]
people there civil so you can have 300
400 people on voice chat which is a
really intimate setting and yet people
aren't interrupting each other it's not
chaos it's quite an amazing community
the other goal I'd love to see is even
if we cover technical papers the goal is

[59:16]
if we cover technical papers the goal is
for it to be accessible to everyone
so both high school students people
outside of all of these fields in
general but also I'd love to make it be
useful to experts in the field expert

[59:30]
useful to experts in the field expert
researchers so avoid using technical
jargon but still try to discover
insights that are new that are
interesting that are important for the
researchers in the field that's what I
would love to achieve here with this
paper Reading Club if you're interested

[59:46]
paper Reading Club if you're interested
join in listening or contribute to the
conversation suggest papers suggest
content visualizations code always
welcome it's an amazing community thanks
for watching this excessively long
presentation if you have suggestions let

[1:00:02]
presentation if you have suggestions let
me know otherwise hope to see you next
time
you