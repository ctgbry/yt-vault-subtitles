[00:00]
I think that animals are a really great
thought experiment when we're thinking
about Ai and Robotics because again this
comparing them to humans that leads us
down the wrong path both because it's
not accurate but also I think for the
future we don't want that
we want something that's a supplement
but I think animals because we've used
them throughout history for so many
different things we we domesticated them
not because they do what we do but
because what they do is different and
that's useful and I it's just like
whether we're talking about
companionship whether we're talking
about work integration whether we're
talking about responsibility for harm
there's just so many things we can draw
on in that history from these entities
that can sense think make autonomous
decisions and learn that are applicable
to how we should be thinking about
robots and AI
the following is a conversation with
Kate darling her second time on the
podcast she's a research scientist at
MIT media lab interested in human robot

[01:00]
MIT media lab interested in human robot
interaction and robot ethics which she
writes about in her recent book called
The New Breed what our history with
animals reveals about our future with
robots Kate is one of my favorite people
at MIT she was a courageous voice of
reason and compassion through the time
of the Jeffrey Epstein scandal at MIT
three years ago we reflect on this time
in this very conversation including the
lessons that revealed about human nature
and our optimistic vision for the future
of MIT a university we both love and
believe in
this is the Lux freedom of podcast to
support it please check out our sponsors
in the description and now dear friends
here's Kate darling
last time we talked a few years back you
wore Justin Bieber shirt for the podcast
so now looking back you're respected
um researcher all the amazing
accomplishments in robotics uh you're an
author was this one of the proudest

[02:01]
author was this one of the proudest
moments of your life uh proudest
decisions you've ever made definitely
you handled it really well though it was
cool because I walked in I didn't know
you were going to be filming I walked in
and you're in a fucking suit yeah and
I'm like why are you all dressed up yeah
and then you were so nice about it you
like made some excuse you're like oh
well I'm interviewing some art didn't
you say you were interviewing some
military General afterwards to like oh
yeah those makes me feel better CTO of
Lockheed Martin I think
yeah you didn't tell me oh I was dressed
like this are you an actual Bieber fan
or was that like one of those t-shirts
that's in the back of the closet that
you use for painting I think I bought it
for my husband as a joke and yeah I was
we were gut renovating a house at the
time and I had worn it to the site
I got his joke and now you wear it okay
have you worn it since
one time
no like how could I touch it again it
was on your podcast that's frames it's
like a wedding dress or something like

[03:00]
like a wedding dress or something like
that you don't you only wear it once you
are the author of The New Breed what our
history with animals reveals about our
future with robots
you open the book with the surprisingly
tricky question what is a robot so let
me ask you let's try to sneak up to this
question what's a robot that's not
really sneaking up
it's just asking it yeah all right well
what do you think a robot is what I
think a robot is is something that has
some level of intelligence
and some level of magic
that little shine in the eye you know
that allows you to navigate the
uncertainty of uh of life so that means
like autonomous vehicles to me in that
sense uh are robots because they
navigate
uh the uncertainty the complexity of
life

[04:00]
life
obviously social robots are that I love
that
I like that you mentioned magic because
that also
well so first of all I don't Define
robot definitively in the book because
there is no definitely that everyone
agrees on and if you look back through
time
people have called things robots until
they lose the magic because they're more
ubiquitous like a vending machine used
to be called a robot and now it's not
right so I do agree with you that
there's this magic aspect that
that which is how people understand
robots
if you ask a roboticist they have the
definition of something that is well it
has to be physical usually it's not an
AI agent it has to be embodied
um they'll say it has to be able to
sense this environment in some way it
has to be able to make a decision
autonomously and then act on its
environment again
I think that's a pretty good technical
definition even though it really breaks
down when you come to things like the

[05:01]
down when you come to things like the
smartphone because the smartphone can do
all of those things and most robotics
would not call it a robot so there's
really no no one good definition but
part of why I wrote the book is because
people have a definition of robot in
their minds that is
usually very focused on a comparison of
robots to humans so if you Google image
search robot you get a bunch of humanoid
robots robots with that torso and head
and two arms and two legs
and that's
the definition of robot that I'm trying
to get us away from because I think that
it trips us up a lot why does the
humanoid form trip us up a lot well
because this constant comparison of
robots to people artificial intelligence
to human intelligence
first of all it doesn't make sense from
a technical perspective because
you know the early AI researchers some
of them were trying to recreate human
intelligence some people still are and
there's a lot to be learned from that
academically Etc but

[06:01]
academically Etc but
um that's not where We've Ended up AI
doesn't think like people we wind up in
this fallacy where we're where we're
comparing these two
um and we're when we talk about what
intelligence even is we're often
comparing to our own intelligence and
then
the second reason this bothers me is
because it doesn't make sense
I I just think it's boring to recreate
intelligence that we already have I see
the scientific value of understanding
our own intelligence but from a like
practical what can we use these
Technologies for perspective it's much
more interesting to create something new
to create a skill set that we don't have
that we can partner with and what we're
trying to achieve
and it should be in some deep way
similar to us but in most ways different
because you still want to have a
connection which is why the similarity
might be necessary that's what people
argue yes and I think that's true so the

[07:00]
argue yes and I think that's true so the
two arguments for humanoid robots are
people need to be able to communicate
and relate to robots and we relate most
to things that are like ourselves
and we have a world that's built for
humans so we have stairs and narrow
passageways and door handles and so we
need humanoid robots to be able to
navigate that and so you're speaking to
the first one which is absolutely true
but what we know from social Robotics
and a lot of human robot interaction
research is that you all you need is
something that's enough like
a person to for it to give off cues that
someone relates to and that but that
doesn't have to look human or even act
human you can take a robot like R2D2 and
it just like beeps and boops and people
love R2D2 right even though it's just
like a trash can on Wheels and they like
r2dging more than C-3PO who's a humanoid
so there's lots of there's lots of ways
to make robots even better than humans
in some ways and make us relate more to
them

[08:00]
them
yeah it's kind of amazing the variety of
cues that can be used to
anthropomorphize the thing like a
glowing orb or something like that yeah
just just a voice
just uh just subtle basic interaction I
think people sometimes over engineer
these things
like Simplicity can go a really long way
totally I mean ask any animator and
they'll know that yeah yeah those are
actually so the people behind Cosmo the
um
the the robot
the right people to design those as
animators like Disney type of people
yeah versus like roboticists robotics is
quote unquote are mostly Clueless
they just have their own discipline that
they're very good at and they didn't
don't have yeah but that that don't
don't you know I feel like robotics
of the early 21st century
is not going to be the robotics of the
later 21st century I don't know like if

[09:01]
later 21st century I don't know like if
you call yourself a roboticist it'll be
something very different because I I
think more and more you'd be like a
maybe like a control engineer or
something controls engineer like uh you
separate because ultimately all the
unsolved all the big problems of
Robotics will be in the social aspect in
the interacting with humans aspect in
uh perception interpreting the world
aspect in the brain part not the not the
not the basic control level part
you call it basic it's actually
right like it's very very complicated
and that's why but like I think you're
so right and and and what a time to be
alive because
for me I just
we've had robots for so long and they've
just been behind the scenes
and now finally robots are getting
deployed into the world they're coming
out of the closet yeah and and we're

[10:01]
out of the closet yeah and and we're
seeing all these mistakes that companies
are making because they focus so much on
the engineering and getting that right
and getting the robot to be even be able
to function in a space that it shares
with a human see what I feel like people
don't understand
is to solve the perception and the
control problem
you shouldn't try to just solve the
perception control problem you should
teach the robot how to say oh shit I'm
sorry I fucked up yeah or ask for help
oh for ask for help or be able to
communicate the uncertainty yeah exactly
all of those things because you can't
solve the perception control we humans
haven't solved it we were really damn
good at it
uh but the the magic is in the the
self-deprecating humor and the
self-awareness about where our flaws are
all that kind of stuff
yeah and there's a whole body of
research in human robot interaction
showing like ways to do this but a lot
of these companies haven't they don't do

[11:01]
of these companies haven't they don't do
HRI they like the have you seen the
grocery store robot in the Stop and Shop
yes yeah the Marty it looks like a giant
penis it's like six feet tall it roams
the aisles I will never see marketing
the same way again thank you you're
welcome
but like
they they these poor people were so hard
on getting a functional robot together
and then people hate Marty because they
didn't
at all consider how people would react
to Marty in their space does everybody I
mean you talk about this do do people
mostly hate Marty because I I like I
like Mario
yeah and actually like there's a there's
a parallel between the two I believe
there is so we were actually going to do
a study on this right before the
pandemic hit and then we canceled it
because we didn't want to go to the
grocery store and neither did anyone
else
um but our Theory so this was with a
student at MIT Daniella de Paola she
noticed that everyone on Facebook in her

[12:00]
noticed that everyone on Facebook in her
circles was complaining about Marty
they're like what is this creepy robot
is watching me it's always in the way
and she did this like quick and dirty
sentiment analysis on Twitter where she
was looking at positive and negative
mentions of the robot and she found that
the biggest Spike of negative mentions
happened
um when Stop and Shop threw a birthday
party for the Marty robots like with
free cake and balloons like who
complains about free cake well people
who hate Marty apparently so
and so we were like that's interesting
and then we did this like online poll we
used Mechanical Turk and we tried to
get at what people don't like about
Marty and a lot of it wasn't oh Marty's
taking jobs it was Marty is the
surveillance robot which is not it looks
for spills on the floor it doesn't
actually like look at any people
um it's it's watching as creepy as
getting in the way those are the things
that people complained about and so our
hypothesis became

[13:00]
hypothesis became
is Marty a real life clippy because I
know Lex you love clippy but many people
hated clippy well there's a complex
thing there it could be like marriage a
lot of people seem to like to complain
about marriage but they secretly love it
so it could be the relationship you
might have with uh with Marty is like
oh there he goes again doing his stupid
surveillance thing but you can grow to
love the um
I mean bitching about the thing that
kind of releases a kind of tension and
there's I mean some people a lot of
people show Love by sort of uh
busting each other's jobs you know like
making fun of each other and then if I
think I think people would really love
it if Marty talked back
and and like well these are so many
possible options for humor there one you
can lean in you can be like yes I'm an
agent of the CIA monitoring your every

[14:02]
agent of the CIA monitoring your every
move like mocking people that are
concerned you know saying like yes I I'm
watching you because you're so important
with your shopping patterns I'm
collecting all this data
um or or just you know any kind of
making fun of people I don't know but I
think you hit on what exactly it is
because when it comes to robots or
artificial agents
I think people hate them more than they
would some other machine or device or
object
and it might and it might be that thing
it might be combined with love or like
whatever it is it's a more extreme
response because they view these things
as social Asians and not objects and
that was
um so Clifford nass was a big human
computer interaction person and he his
theory about Clippy was that because
people viewed clippy as a social agent
when clippy was annoying and would like
bother them and interrupt them and like
not remember what they told him that's

[15:02]
not remember what they told him that's
when people got upset because it wasn't
fulfilling their social expectations and
so they complained about Clippy more
than they would have if it had been a
diff like not an not a you know virtual
character so is complaining to you a
sign that we're on the wrong path with a
particular robot or is it possible like
again like marriage like
family that there still is a path
towards that direction where we can find
deep meaningful relationship
I think we absolutely can
meaningful relationships with more
robots and well maybe with Marty I mean
I just would I would have designed Marty
a little differently but oh isn't there
a charm to the clumsiness the slowness
there is if you're not trying to get
through the shopping cart and screaming
child you know there's I think
I think you could make it Charming I
think there are lots of design tricks
that they could have used and one of the
things they did I think without thinking

[16:01]
things they did I think without thinking
about it at all is they slapped too big
googly eyes on Marty oh yeah and I I
wonder if that contributed maybe to
people feeling watched
um
because because it's looking at them
and
so like is there a way to design the
robot to do the function that it's doing
in a way that does that people are
actually attracted to rather than
annoyed by and there are many ways to do
that but companies aren't thinking about
it now they're realizing that they
should have thought about it yeah I
wonder if there's a way to
if it would help to make Marty seem like
an entity of its own versus uh
the arm of a large corporation
so there's some sense where
this is just the camera that's
monitoring people versus this is an
entity that's a standalone entity it has
its own task
and it has its own personality the more

[17:00]
and it has its own personality the more
personality you give it the more it
feels like
it's not sharing data with anybody else
like
when we see other human beings our basic
assumption is whatever I say to this
human being it's not like being
immediately sent to the CIA yeah what I
say to you no one's gonna hear that
right yeah that's true that's true well
you forget it I mean you do forget it I
mean I don't know if that even with
microphones here you forget that that's
happening but there for some reason I
think probably with Marty
um I think when it's done really crudely
and crappily you start to realize oh
this is like PR people trying to make a
friendly version of a surveillance
machine but
um I mean that reminds me of the slight
clumsiness or significant clumsiness on
the initial releases of the avatars for
the metaverse I don't know what what do
you what are your actually thoughts
about that the the

[18:00]
about that the the
way
uh the avatars the way like Mark
Zuckerberg looks in that world you know
the the the the meta verse the virtual
reality world where you can have like
virtual meetings and stuff like that
like how do we get that right do you
have thoughts about that because that's
the kind of uh
it's a
is it feels like a similar problem to
social robotics which is how you design
a digital virtual world that is
compelling
when you connect others there in the
same way that physical
connection is right I haven't looked
into I mean I've seen people joking
about it on Twitter and like posting
like that whatever yeah but I mean have
you seen it because it there's something
you can't quite put into words uh that
um
doesn't feel genuine yeah about the way
it looks and so the question is if you
and I were to meet virtually
what should the avatars look like

[19:02]
what should the avatars look like
for us to have a similar kind of
connection should it be a really
simplified should it be a little bit
more realistic should it be cartoonish
should it be more
um
better capturing of Expressions uh in
interesting complex ways versus like
cartoonish oversimplified ways but
haven't video games figured this out I'm
not a gamer so I don't have any examples
but I feel like there's this whole world
in video games where they've thought
about all of this and depending on the
game they have different like avatars
and a lot of the games are about
connecting with others I just the thing
that I don't know is and again I haven't
looked into this at all
um I've been like shockingly not very
interested in the metaverse but
they must have poured so much investment
into this
um meta and
like why why is it so why are people why

[20:00]
like why why is it so why are people why
is it so bad like well there's gonna be
a reason there's got to be some thinking
behind it right
well I talked to Carmack about this uh
John Carmack who's a part-time
um Oculus
CTO
I think uh there's several things to say
one is as you probably know that I mean
there's bureaucracy there's large
corporations and they often large
corporations have a way of
killing the ND kind of artistic
flame that's required to create
something really compelling somehow they
make everything boring because they they
run through this whole process through
the PR department through all that kind
of stuff and it somehow becomes generic
to that process because you strip out
anything interesting because it could be
controversial is that or yeah right
exactly like um
like what I mean we're living through
this now like with the

[21:00]
this now like with the
with a lot of people with cancellations
all those kinds of stuff people are
nervous and nervousness results in like
the like usual the assholes are ruining
everything but you know the magic of
human connection is taking risks of
making a risky joke of of of like with
people you like who are not assholes
good people like some of the fun some of
the fun in the metaverse OR in video
games is you know being edgier being
interesting revealing your personality
in interesting ways
um in the sexual tension or in uh
they're definitely paranoid about that
oh yeah like in metaverse the
possibility of sexual assault and sexual
harassment and all that kind of stuff
it's it's obviously very high but
they're uh so you should be paranoid to
some degree but not too much because
then you remove completely person the
personality of the whole thing then
everybody's just like a vanilla bot but
uh like you have to have

[22:00]
uh like you have to have
ability
um to be a little bit political to be a
little bit edgy all that kind of stuff
and large companies tend to suffocate
that so I but in general if you get all
that just the ability to come up
really cool beautiful ideas
if you look at uh I think Grimes tweeted
about this she's very critical about the
metaverse is that
um
you know the uh independent uh game
designers have solved this problem of
how to create something beautiful and
interesting and compelling they they do
a really good job so you have to let
those kinds of Minds the small groups of
people design things and let them run
with it let them run wild and do edgy
stuff yeah but otherwise you because you
get this kind of
you get a clippy type of situation right
which is like a very generic looking
thing
um but even clippy has some like that's

[23:03]
um but even clippy has some like that's
kind of wild that you would take a a
paper clip and put eyes on it and
suddenly people are like oh you're
annoying but you're definitely a social
agent and I just feel like that wouldn't
even that clippy thing wouldn't even
survive Microsoft
or Facebook of today matter of today
because it would be like what there'll
be these meetings about why is it for
people
like why don't we it's not sufficiently
friendly let's make it uh you know and
then all of a sudden the artist that
with whom it originated is killed and
it's all PR marketing people and all
that kind of stuff no they do important
work to some degree but they kill the
creativity I think the killing of the
creativity is in the whole like Okay so
some social robotics is like obviously
if you create agents that okay so take
for an example you'd create a robot that

[24:00]
for an example you'd create a robot that
looks like a humanoid and it's you know
Sophia or whatever now suddenly you do
have all of these issues where
are you reinforcing an unrealistic
Beauty standard are you objectifying
women uh why is the robot white so you
have but the thing is I think that with
creativity
you can find a solution that's even
better where you're not even harming
anyone and you're creating a robot that
looks like not not humanoid but like
something that people relate to even
more and now you don't even have any of
these bias issues that you're creating
and so how do we create that within
companies because I don't think it's
really about
like I because I you know maybe we
disagree on that I don't think that
edginess or humor or interesting things
need to be things that harm or hurt
people or that people are against there
are ways to find things that everyone is
fine with

[25:00]
fine with
why aren't we doing that the problem is
there's departments that look for harm
and things yeah and so they will find
harm in things that have no harm okay
that's the big problem because their
whole job is to find harm in things so
what you said is completely correct
which is edginess should not hurt
doesn't necessarily doesn't need to be a
thing that hurts people it obviously
great humor great uh personality doesn't
have to uh like clippy
but yeah I mean it but it's tricky to
get right and I'm not exactly sure I
don't know I don't know why a large
corporation with a lot of funding can't
get this right I do think you're right
that there's a lot of aversion to risk
and so if you get lawyers involved or
people whose job it is like you say to
mitigate risk they're just going to say
no to most things that could even be in
some way yeah
yeah you get the problem in all
organizations so I think that you're
right that that is a problem I think

[26:01]
right that that is a problem I think
what's the way to solve that in large
organizations is to have Steve Jobs
types of characters unfortunately you do
need to have I think
um from a designer or maybe like a
Johnny Ive
that is almost like a dictator yeah you
want a benevolent dictator yeah who
rolls in and says like the cuts through
the lawyers the PR but has a benevolent
aspect like yeah this is a good heart
and make sure like I think all great
artists and designers create stuff that
doesn't hurt people like if you have a
good heart you're going to create
something that's going to actually
um make a lot of people feel good that's
what like people like Johnny Ive what
they love doing is creating a thing that
brings a lot of love to the world they
imagine like millions of people using
the thing and it instills them with with
joy that's that you could say that by
social robotics you could say that about
the metaverse it shouldn't be done by

[27:00]
the metaverse it shouldn't be done by
the pr people should be done by this
time I agree PR people ruin everything
yeah all the fun uh in the uh in the
book you have a picture this I just have
a lot of ridiculous questions you have a
picture of two Hospital delivery robots
with a caption that reads by the way see
your book I appreciate that it keeps the
humor in you didn't run it by the PR
department no no one edited the book got
rushed through
uh the thing the caption reads two
hospitals delivery robots whose sexy
nurse names Roxy and Lola made me roll
my eyes so hard they almost fell out
um what aspect of it made you roll your
eyes is it the naming it was the naming
the form factor is fine it's like a
little box on Wheels the fact that they
named them also great that'll let people
enjoy interacting with them we know that
even just giving a robot a name people
will uh it facilitates technology
adoption people will be like oh you know

[28:02]
adoption people will be like oh you know
Betsy made a mistake let's help her out
instead of this stupid robot doesn't
work but why lowly and Lola and Roxy
like those are too too sexy I mean
there's research showing that
a lot of robots are named according to
gender biases about the function that
they're fulfilling so
you know robots that are helpful in
assistance and are like nurses are
usually female gendered robots that are
you know powerful all wise computers
like Watson usually have like a booming
male uh coded voice and name so
like why like that's one of those things
right you're opening a can of worms for
no reason for no reason you can avoid
this whole camera yeah just give it a
different name like why Roxy
it's because people aren't even thinking
so to some extent I don't I don't like
PR departments but getting some feedback

[29:01]
PR departments but getting some feedback
on your work from a diverse set of
participants listening and taking in
things that help you identify your own
blind spots and then you can always make
your good leadership choices and good
like you can still ignore things that
you don't believe are an issue but
having the openness to take in feedback
and making sure that you're getting the
right feedback from the right people I
think that's really important so don't
unnecessarily propagate the biases of
society yeah why in the design
but uh if you're not careful though when
you when you do the research of
like
you might if you ran a poll with a lot
of people of all the possible names
these robots have they might come up
with Roxy and Lola as as as names they
um it would enjoy most like that could
come up as uh as the highest as in you
do marketing research and then

[30:01]
do marketing research and then
well that's what they did with Alexa
they did marketing research and nobody
wanted the male voice everyone wanted it
to be female what do you what do you
think about that like what
I mean if I if I were to say
I think the role of a great designer
again to go back to Johnny Ive is to
throw out the marketing research
like take it in do it learn from it but
if everyone wants Alexa to be a female
voice
the role of the designers to think
deeply about the future
of social agents in the home and think
like what does that future look like and
try to reverse engineer that future so
like in some sense there's this weird
tension like you want to listen to a lot
of people
but at the same time you want to you're
creating a thing that defines the future
of the world
and the people that you're listening to
are part of the past
so like that weird tension yeah I think

[31:02]
so like that weird tension yeah I think
that's true and I think some companies
like apple have historically done very
well at understanding a market and
saying you know what our role is it's
not to listen to what the current market
says it's to actually shape the market
and shape consumer preferences and
companies companies have the power to do
that they can before we're thinking and
they can actually shift what the future
of technology looks like
and I agree with you that I would like
to see more of that especially when it
comes to
existing biases that we know
or or you know that that I think there's
the low-hanging fruit of companies that
don't even think about it at all and
aren't talking to the right people and
aren't getting the full information and
then there's companies that are just
like doing the safe thing and and giving
consumers what they want now but to be
really forward looking and be really
successful I think you have to make some
judgment calls about what the future is
going to be but do you think it's still
useful to gender and to name the robots

[32:01]
useful to gender and to name the robots
yes I mean
gender is the minefields but people I
it's really hard to get people to not
gender a robot in some way
so if you don't give it a name or you
give it a like ambiguous voice people
will just choose something and maybe
that's better than just like
uh you know entrenching something that
you've decided is best
but I do think it can be helpful on the
like anthropomorphism engagement level
to give it attributes that people
identify with yeah I think uh a lot of
roboticists I know they they don't
gender the robot they don't they even
try to avoid naming the robot or naming
it ain't something that is uh can be
used as a name in conversation kind of
thing
and I think that actually
that's uh
irresponsible because

[33:00]
irresponsible because
people are going to anthropomorphize the
thing anyway
so you're just uh removing from yourself
the responsibility of how they're
they're going to anthropomorphize it
that's a good point and so like you want
to be able to like they're going to do
it you have to start to think about how
they're going to do it even if the robot
is like a Boston Dynamics robot that's
not supposed to have any kind of social
component
they're obviously going to project a
social component to it yeah like that
arm
I worked a lot a lot with quadruped now
with with the robot dogs you know that
arm people think is the head immediately
yeah it's supposed to be an arm but they
start to think it's a head and you have
to like acknowledge that you can't I
mean uh they do now they do now well
they've deployed the robots and people
are like oh my God the cops are using a
robot dog and so they have this PR
Nightmare and so they're like oh
yeah okay maybe we should hire some HRI

[34:00]
yeah okay maybe we should hire some HRI
people
well Boston Dynamics is an interesting
company or any of the others that are
doing similar thing because
their their main source of money
is um in the industrial application so
like surveillance to factories and uh
doing dangerous jobs so to them it's
almost good PR
for people to be scared of these things
because it's it's for some reason as you
talk about people are naturally for some
reason scared we could talk about that
of robots and so it becomes more viral
like uh playing with that little fear
and so it's almost like a good PR
because ultimately they're not trying to
put them in the home and have a good
social connection they're trying to put
them in factories and so they they have
fun with it if you watch Boston Dynamics
videos yeah they're aware of it oh yeah
they're I mean the videos for sure that
they put out it's almost like an
unspoken
tongue-in-cheek thing they they're aware

[35:02]
tongue-in-cheek thing they they're aware
of how people are going to feel when you
have a robot that does like a flip now
most of the people are uh just like
excited about the control problem of it
like how to how to make the whole thing
happen but they're aware when people see
well I think they became aware I think
that in the beginning they were really
really focused on just the engineering I
mean they're at the Forefront of
Robotics like Locomotion and stuff
um
and then when they started doing the
videos I think that was kind of a labor
of love
I know that the former CEO Mark like he
oversaw a lot of the videos and made a
lot of them himself and like he's even
really really detail-oriented like there
can't be like some sort of incline that
would give the robot an advantage
they're very like he he was very um hell
of Integrity about the authenticity of
them uh and but then when they started
to go viral I think that's when they
started to realize oh there's something
interesting here that

[36:01]
interesting here that
you know I don't I don't know how much
they took it seriously in the beginning
other than realizing that they could
play Within the videos yeah I know that
they take it very seriously now what I
like about Boston Dynamics
and similar companies it's still mostly
run by engineers
but you know
I've had my criticisms there's a bit
more PR leaking in but those videos are
made by Engineers because that's what
they find fun mm-hmm it's like testing
the robustness of the system
I mean they uh
they're having a lot of fun there with
the robots totally
have you been have you been to visit
yeah yeah yeah yeah it's cool it's one
of the most important like I I uh
I mean because I I have
um eight uh robot dogs now uh wait you
have eight robot dogs what are they just
walking around your place like yeah I'm

[37:01]
walking around your place like yeah I'm
working on them uh that's actually one
of my goals is
to have at any one time always a robot
moving oh I'm far away that's an
ambitious goal
well I have like more roombas I know
what to do with the room their program
so the the programmable roombas nice and
um I have a bunch of little like I built
the well I'm not finished with the
butter robot from Rick and Morty I saw a
bunch of robots everywhere but the thing
is what happens is you're working on one
robot at a time
and uh that becomes like a little
project
it's actually very difficult to have
just a passively
functioning robot always moving yeah and
that's a that's a that's a dream for me
because I'd love to create that kind of
a little world so uh the the impressive
thing about Boston Dynamics to me was to
see like hundreds of spots
and like there's a the most impressive

[38:01]
and like there's a the most impressive
thing that still sticks with me is um
there was a a spot robot
walking down the hall seemingly with no
supervision whatsoever and he was
wearing he or she I don't know was
wearing a cowboy hat
it just it was just walking down the
hall and nobody paying attention and
it's just like walking down this long
Hall and I'm like looking around this is
anyone like what's happening here so I'm
presumably some kind of automation where
he's doing the map I mean the whole
environment is probably really well
mapped but I it was just
it gave me a picture of a world where a
robot is doing his thing wearing a
cowboy hat just
going down the hall like getting some
coffee or whatever like I don't know
what it's doing what's the mission but
uh I don't know for some reason it
really stuck with me you don't often see
robots that aren't part of a demo or
that aren't uh you know like with a
semi-autonomous autonomous vehicle like
directly doing a task this was just

[39:01]
directly doing a task this was just
chilling yeah walking around I don't
know well yeah you know I mean we're at
MIT like when I first got to MIT I was
like okay where's all the where's all
the robots and they were all like broken
or like not demoing so yeah and and and
what really excites me is that we're
about to have that we're about to have
so many moving rope about to well it's
coming it's coming in our lifetime that
we will just have robots moving around
we're already seeing the beginnings of
it there's delivery robots in some
cities on the sidewalks and I just love
seeing like the tick tocks of people
reacting to that because yeah you see a
robot walking on the hall with a cowboy
hat you're like what
the what is this this is awesome and
scary and kind of awesome and people
either love or hate it that's one of the
things that I think companies are
underestimating that people will either
love a robot or hate a robot and nothing
in between so it's just again an
exciting time to be alive yeah I think

[40:01]
exciting time to be alive yeah I think
kids almost universally at least in my
experience love them
a lot love legged robots if they're not
La my my son hates the room though
because ours is loud
oh that yeah no the legs the legs oh
yeah because your son
um
do they understand Roma to be a robot
oh yeah my kids that's that's the first
words they learned they know how to say
beep boop
think the room as a robot does do they
project intelligence out of the thing
but we don't really use it around them
anymore for the reason that my son is
scared of it
yeah that's right I think they would
like even a Roomba
because it's moving around on its own
I think kids and animals view it as a an
agent
so what do you think if we just look at
the state of the art of Robotics what do
you think robots are actually good at
today
so if we look at today you mean physical

[41:00]
so if we look at today you mean physical
robots yeah physical robots
well like what are you impressed by
so I think a lot of people I mean that's
what your book is about is have maybe a
not a perfectly calibrated understanding
of
where we are in terms of Robotics what's
difficult the robotics what's easy in
robotics yeah we're way behind where
people think we are so
what's impressive to me so uh let's see
oh one one thing that came out recently
was Amazon has this new Warehouse robot
and it's the first autonomous Warehouse
robot that can is safe for people to be
around and so like it's kind of most
people most people I think Envision that
our warehouses are already fully
automated and that they're just like
robots doing things
it's actually still really difficult to
have robots and people in the same space
because it's dangerous for the most part

[42:01]
because it's dangerous for the most part
robots you know because especially
robots that have to be strong enough to
move something heavy for example they
can really hurt somebody and so until
now a lot of the warehouse robots had to
just move along like pre-existing lines
which really restricts what you can do
um and so having I think that that's
that's one of the big challenges and one
of the big like exciting things that's
happening is that we're starting to see
more kobotics in industrial spaces like
that where people and robots can work
side by side and not get harmed yeah
that's what people don't realize sort of
the physical manipulation tasks with
humans
it's not that the robots want to hurt
you
I think that's what people are worried
about like this malevolent robot gets
them out of its own and wants to destroy
all humans now it's you know it's
actually very difficult to know where
the human is yeah and to to respond to
the human and dynamically and

[43:01]
the human and dynamically and
collaborate with them on a task
especially if you're something like an
industrial robotic arm which is
extremely powerful
yeah this some of the some of those arms
are pretty impressive now that
you can just you can you can grab it you
can move it so the the collaboration
between human robot in the factory
setting is really fascinating yeah
um do you think they'll take our jobs
I don't think it's that simple I think
that there's a ton of disruption that's
happening and will continue to happen
um
you know I think speaking specifically
of the Amazon warehouses that might be
an area where it would be good for
robots to take some of the jobs that are
you know where people are put in a
position where it's unsafe and they're
treated horribly and you know probably
it would be better if a robot did that
and Amazon is clearly trying to automate
that job away so uh I think there's
going to be a lot of disruption I do

[44:01]
going to be a lot of disruption I do
think that robots and humans have very
different skill sets so while a robot
might take over a task
it's not going to take over most jobs
um
I think just things will change a lot
like I know one of the examples I have
in the book is mining
um so they're you have this job that is
very unsafe and that requires a bunch of
workers and puts them in unsafe
conditions and now you have all these
different robotic machines that can help
make the job safer and as a result now
people can sit in these like
air-conditioned remote control stations
and like control these autonomous mining
trucks and so that's a much better job
but also they're employing less people
now so it's
it's just a lot of
I think from a bird's eye perspective
you're not going to see job loss you're
going to see more jobs created because

[45:01]
going to see more jobs created because
that's I I think the future is not
robots just becoming like people and
taking their jobs the future is really a
combination of our skills and then the
supplemental skills that robots have to
increase productivity to help people
have better safer jobs to
give people work that they actually
enjoy doing and are good at
um but it's really easy to say that from
a bird's eye perspective and
um ignore kind of the the rubble on the
ground as we go through these
transitions because of course specific
jobs are going to get lost if you look
at the history of the 20th century it
seems like automation
constantly
increases productivity and improves
the average quality of life so it's it's
been always good so like thinking about
this time being different is that we
would need to go against the lessons of

[46:01]
would need to go against the lessons of
History it's true
and uh the other thing is I think people
think that the automation of the
physical tasks is easy I was I was just
in Ukraine and the interesting thing is
um
I mean there's a lot of difficult and uh
dark lessons just about a war zone but
one of the things that happens in war is
there's a lot of Mines that are placed
um that's the this one of the big
problems
for years after a war is even over is
the entire landscape is covered in mines
and so there's a demining effort
and you would think robots would be good
at this kind of thing or like your
intuition would be like well say you
have unlimited money and you want to do
a good job of it unlimited money you
would get a lot of really nice robots
but no humans are still far superior or
animals or animals but even right but

[47:00]
animals or animals but even right but
humans with animals together yeah you
can't just have that's true dog with a
hat
that's fair
but yes and but figuring out also how to
uh disable the mine
obviously the easy thing the thing a
robot can help with is to find the mine
and blow it up but that's gonna destroy
the landscape that that really does a
lot of damage to the land you want to uh
disable the mine and to do that because
of all the different all the different
edge cases of the problem it requires a
huge amount of human-like experience it
seems like so it's mostly done by humans
they have no use for robots they don't
want robots yeah I think we overestimate
what we can automate
in the especially in the Physical Realm
yeah that's it's weird I mean it's
continues that this this the story of
humans we think were shitty at
everything in the physical world

[48:00]
everything in the physical world
including driving we think everybody
makes fun of themselves and others for
being shitty drivers but we're actually
kind of incredible no incredible and
that's why like
that's the way Tesla still says that if
you're in the driver's seat like you you
are ultimately responsible because the
ideal for I mean I mean you know more
about this than I do but
he like robot cars are great at
predictable things and can react faster
and more precisely than a person and can
do a lot of the driving and then the
reason that we still don't have
autonomous vehicles on all the roads yet
is because of this long tail of just
unexpected occurrences where a human
immediately understands that's the
sunset and not a traffic light that's a
horse and carriage ahead of me on the
highway but the car has never
encountered that before so like in
theory combining those skill sets is
what's gonna really be powerful
the only problem is figuring off the
figuring out the human robot interaction

[49:00]
figuring out the human robot interaction
and the handoffs so like in cars that's
a huge problem right now figuring out
the handoffs
um but in other areas uh it might be
easier and that's really the future is
human robot interaction
well it's really hard to improve
it's it's it's terrible that people die
in car
accidents but I mean it's like 70 80 100
million miles one death per
uh 80 million miles that's like really
hard to beat for a robot that's that's
like incredible that like think about it
like the how many people the just the
number of people throughout the world
that are driving every single day all
this you know Steve deprived drunk
uh distracted all of that and still very
few die relative to what I would imagine
if I were to guess back in the horse see
when I was like in the in the beginning
of the 20th century riding my horse I

[50:00]
of the 20th century riding my horse I
would talk so much shit about these cars
I'd be like this is gonna this is
extremely dangerous these machines
traveling at 30 miles an hour or
whatever the hell they're going at this
is irresponsible it's unnatural and and
it's going to be destructive to all of
human society but then it's extremely
surprising how humans adapt to the thing
and they know how to not kill each other
um I mean that at ability to adapt is
incredible and to mimic that in the
machine is really tricky
now that said what Tesla is doing it I
mean I wouldn't have guessed how far
machine learning can go on Vision alone
it's really really incredible and people
that are
at least from my perspective people that
are kind of um
uh you know critical of Elon and those
efforts
I think don't give enough credit how
much progress we made some how much
incredible progress has been made in
that direction I think most of the
robotics Community wouldn't have guessed

[51:01]
robotics Community wouldn't have guessed
how much you can do on Vision alone it's
kind of incredible
um because we would be I think it's that
approach which is relatively unique
has challenged the other competitors to
step up their game so if you're using
lidar if you're using mapping
um that challenges them to do
better to scale faster and to use
machine learning and computer vision as
well to integrate both lidar and vision
so
um it's kind of incredible and I'm not
I don't know if I even have a good
intuition of how hard driving is anymore
maybe it is possible to solve
so all the stuff you mentioned yeah the
question is one yeah I think it's not
happening as quickly as people thought
it would because it is more complicated
but I wouldn't have
I I agree with you my current intuition

[52:00]
I I agree with you my current intuition
is that we're gonna get there I think
we're gonna get there too but I didn't
before I wasn't sure we're gonna get
there without like with current
technology
so you know I I was kind of this is like
with vision alone I my intuition was
you're gonna have to solve like Common
Sense reasoning
you're gonna have to you're gonna have
to solve some of the big problems in
artificial intelligence not just
uh not just perception
yeah like you have to have a deep
understanding of the world it's always
my sense but now I'm starting to like
well this I mean I'm continuously
surprised how well the thing works yeah
obviously Elon and others others have
stopped but Elon continues you know
saying we're going to solve it in a year
oh yeah that's the thing bold
predictions though yeah well everyone
else used to be doing that but they kind
of like all right yeah or maybe more

[53:00]
of like all right yeah or maybe more
maybe let's not promise we're gonna
solve uh level four driving by 2020.
let's uh let's chill on that but people
are still trying silently I mean the UK
just committed 100 million pounds to
research and development to speed up the
process of getting autonomous vehicles
on the road like everyone is everyone
can see that it is solvable and it's
going to happen and it's going to change
everything and they're still investing
in it and uh like waymo Loki has
driverless cars in in Arizona
like you can get you know there's like
robots
it's weird have you ever been to one no
it's so weird it's so awesome because uh
the the most awesome experience is a is
the wheel turning and you're sitting in
the back it's like
I don't know it's uh
it feels like you're a passenger with
that friend who's a little crazy of a

[54:00]
that friend who's a little crazy of a
driver it feels like
shit I don't know are you right to drive
bro you know that kind of feeling good
but but then you kind of
that experience that nervousness
um and the excitement of trusting
another being in this case it's a
machine it's really interesting
um just even introspecting your own
feelings about the thing yeah uh they're
not doing
anything in terms of making you feel
better
like at least waymo I think they went
with the approach of like let's not try
to put eyes on the thing
let's it's it's a it's a wheel we know
what that looks like it's just a car
it's a car get in the back let's not
like discuss this at all let's not
discuss the fact that this is a robot
driving you and you're in the back and
if the robot wants to start driving 80
miles an hour and run off of a bridge
you have no recourse let's not discuss

[55:01]
you have no recourse let's not discuss
this you're just getting in the back
there's no discussion about like how
shit can go wrong uh there's no eyes
there's nothing there's like a map
showing what the car can see
like you know what happens if it's like
uh a HAL 9000 situation like I'm like
I'm sorry I can't you have a button you
can like call customer service oh God
then you get put on hold for two hours
yeah probably
um but you know currently what they're
doing which I think
is understandable but you know the car
just can pull over and stop and wait for
help to arrive and then a driver will
come and then they'll actually drive the
car for you but that's like you know
what if you're late
for meeting or all that kind of stuff or
like the more dystopian isn't it the
Fifth Element where it's Will Smith in
it who's in that movie no Bruce Willis
Bruce Willis oh yeah and he gets into
like a robotic cab or car or something
and then because he's violated a traffic

[56:01]
and then because he's violated a traffic
rule it locks him in yeah and he has to
wait for the cops to come and he can't
get out so like yeah we're gonna see
stuff like that maybe
what's this
I I believe that the companies that have
robots
the the only ones that will succeed are
the ones that don't do that meaning they
respect
privacy you think so yeah because people
because because they're gonna have to
earn people's trust yeah but like Amazon
works with law enforcement and gives
them the data from The Ring cameras so
why should it yeah
do you have a ring camera
uh no okay no no but you know basically
any security camera right I've uh
Google's whatever they have we have one
that's not
the data at least or the data on a local
server because we don't want it to go to
law enforcement because all the
companies are doing it they're doing I I

[57:01]
companies are doing it they're doing I I
bet Apple wouldn't
yeah the only company I trust and I
don't know how much longer
I don't know
maybe that's true for cameras
but with robots people are just not
going to let a robot inside their home
where like one time where somebody gets
arrested because of something a robot
sees that's going to be that's gonna
destroy a company you don't think people
are going to be like well that wouldn't
happen to me that happened to a bad
person
and I think they would yeah because in
the modern world people I get have you
seen Twitter they get extremely paranoid
about any kind of surveillance but the
thing that I've had to learn is that
Twitter is not the modern world like
when I go
you know Inland to visit my relatives
like they don't that's a different
discourse that's happening I think like
the whole Tech criticism world yeah it's
loud in our ears because we're in those

[58:01]
loud in our ears because we're in those
circles do you think you can be a
company that does social Robotics and
not win over Twitter
that's a good question I feel like the
early adopters are all on Twitter
and it feels like you have to win them
over feels like nowadays you'd have to
win over Tick Tock honestly
I don't is that is that a website
I hate to check it out
um
and that's an interesting one because
China is behind that one
exactly
uh so it's compelling enough maybe
people would be able to uh give up
privacy and that kind of stuff
that's really I just I mean
I'm worried about it I'm worried about
it and I'm
there have been some developments
recently that are like super exciting
like the large language learning models
like wow I did not anticipate those
improving so quickly
and those are going to change everything

[59:03]
and those are going to change everything
and one of the things that I'm trying to
be cynical about is that I think they're
gonna have a big impact on privacy and
data security and like manipulating
consumers and manipulating people
because suddenly you'll have these
agents that people will talk to and they
won't care or won't know
at least on a conscious level that it's
recording the conversations so kind of
like we were talking about before
um and at the same time the technology
is so freaking exciting that it's going
to get adopted it's not even just a
collection of data but the ability to
manipulate
at scale
so um what do you think about the AI
the engineer from from Google
that thought Lambda is sentient
he had actually a really good post from
somebody else I forgot her name it's
brilliant I can't believe I didn't know
about her thank you yeah for weird AI oh
yeah I love her book oh she she's great
I left a note for myself to reach out to

[1:00:01]
I left a note for myself to reach out to
her she's amazing she's hilarious and
Brilliant and just a great summarizer of
the state of AI but she has
um I think that was from her where I was
looking at
uh AI explaining that it's a squirrel oh
yeah because the transcripts that the
engineer released
Lambda kind of talks about the
experience of
human-like feelings and I think even
consciousness and so she was like oh
cool that's impressive I wonder if an AI
can also describe the experience of
being a squirrel and so she interviewed
I think she did gbt3
about the experience of being a squirrel
and then she did a bunch of other ones
too like what's it like being a flock of
crows what's it like being an algorithm
that powers a Roomba and like yeah you
can have a conversation about any of
those things and they're very very
convincing yeah yeah even gpg3 which is
not like state of the art right it's
convincing of being a squirrel it's like

[1:01:01]
convincing of being a squirrel it's like
what what it's like I mean you should
check it out because it really is it's
like yeah that probably is what a
squirrel would would say
are you excited like what's it like
being a squirrel that's fun okay I get
to eat nuts and run around all day
uh like how do you think people feel
like when you tell them that you're a
squirrel
um you know or like I forget what it was
like a lot of people might be scared to
find out that you're squirrel or
something like this and then the system
Answers Pretty like yeah pretty well
like yeah like
um I hope they'll like what do you think
the when they find out you're a squirrel
um I I hope they'll see how fun it is to
be a score like that what do you say to
people who don't believe you're a
squirrel I say come see for yourself I
am a squirrel that's great well I think
it's really great because it it like the
two things to note about it are first of
all just because the machine is
describing an experience doesn't mean it

[1:02:00]
describing an experience doesn't mean it
can it actually has that experience but
then secondly these things are getting
so Advanced and so convincing at
describing these things and talking to
people
that's I mean just the implications for
health education communication
entertainment gaming like I just like
all of the applications it's
mind-boggling what we're going to be
able to do with this and and that my
kids are not going to remember a time
before they could have conversations
with artificial agents do you think they
would because to me this is uh
the focus in the ad Community has been
well this engineer
Shirley's hallucinating the thing is not
sentient
but to me I first of all it doesn't
matter if he is or not this is coming
yeah where a large number of people
would believe a system has sent you
including Engineers within companies
yeah so in that sense you start to think

[1:03:01]
yeah so in that sense you start to think
about a world where like your kids
aren't just used to having a
conversation with the bot but used to
believing kind of
having an implied belief that the thing
is sentient
yeah I think I think that's true and I
think that
one of the things that bothered me about
all of the coverage in the tech press
about this incident like obviously I
don't believe the system is sentient
like I think that it can convincingly
describe that it is I don't think it's
doing what he thought it was doing and
actually experiencing feelings but a lot
of the tech press was about how he was
wrong and depicting him as kind of naive
and it's not naive like there's so much
research in my field showing that people
do this even experts they they might be
very clinical when they're doing human
robot interaction experiments with a
robot that they've built and then you
bring in a different robot and they're
like oh look
it on it's doing this like that happens
in our lab all the time

[1:04:01]
in our lab all the time
we are all this guy and it's gonna it's
gonna be huge so I think that
the the goal is not to discourage this
kind of belief or like Design Systems
that people won't think are sentient I
don't think that's possible I think
you're right this is coming it's
something that we have to acknowledge
and even embrace
and be very aware of so one of the
really interesting perspectives that
your book takes
on a system like this is to see them not
to compare something like this to humans
but to compare it to animals of how we
see animals can you kind of try to again
sneak up try to explain why this analogy
is better than the human analogy the
analogy of robots as animals yeah and it
gets trickier with the language stuff
but we'll get into that too
um
I think that animals are a really great
thought experiment when we're thinking

[1:05:00]
thought experiment when we're thinking
about Ai and Robotics because again this
comparing them to humans that leads us
down the wrong path both because it's
not accurate but also I think for the
future we don't want that
we want something that's a supplement
but I think animals because we've used
them throughout history for so many
different things we we domesticated them
not because they do what we do but
because what they do is different and
that's useful and I it's just like
whether we're talking about
companionship whether we're talking
about work integration whether we're
talking about responsibility for harm
there's just so many things we can draw
on in that history from these entities
that can sense think make autonomous
decisions and learn that are applicable
to how we should be thinking about
robots in Ai and and the point of the
book is not that they're the same thing
that animals and robots are the same
obviously there are tons of differences
there like you can't you can't have a
conversation with a squirrel right but
the the point you do it all the time oh
really by the way squirrels are the

[1:06:00]
really by the way squirrels are the
cutest I project so much on squirrels I
wonder what their inner life is
um I suspect they're much bigger
assholes than we imagine really like if
it was a giant squirrel it would fuck
you over so fast if you had the chance
it would take everything you own it
would eat all your stuff because it's
small and the Furry Tail the furry tale
is a
is uh
is a weapon against human consciousness
and cognition it wins us over that's
what cats do too cats out I'll competed
squirrels
and dogs like yeah dogs no dogs have
love cats are have no soul they I'm just
kidding people get so angry I talk shit
about cats that I love cats anyway uh so
yeah uh yeah you're you're describing
all the different kinds of animals that
get domesticated
and it's a really interesting idea that
it's not just sort of pets there's all
kinds of domestication going on they all
have all kinds of uses yes like the uh

[1:07:02]
have all kinds of uses yes like the uh
Ox that you
propose might be
at least historically one of the most
useful domesticated animals it was a
game changer because it revolutionized
like what people could do economically
Etc so I I mean just like robots They're
Gonna Change they're going to change
things economically they're going to
change Landscapes like cities might even
get rebuilt around autonomous vehicles
or drones or delivery robots like I
think just the same ways that animals
have really shifted society and Society
has adapted also to like socially
accepting animals as pets
um I think we're going to see very
similar things with robots so I think
it's a useful analogy it's not a perfect
one but I think it's it helps us get
away from this idea that robots can
shoot or will replace people if you
remember what are some interesting uses
of animals ferrets for example oh yeah
the ferrets they they still do this they
use ferrets to go into narrow spaces
that people can't go into like a pipe or

[1:08:01]
that people can't go into like a pipe or
like they'll use in the wrong electrical
wire I think they did that for princess
dies for wedding there's so many weird
ways we've used animals and still use
animals for things that robots can't do
like the dolphins that they used in the
in the military I think the I think
Russia still has Dolphins and the US
Dollars dolphins in their navies
um
uh mind detection looking for lost
underwater equipment
some rumors about like using them for
weaponry
which which I think Russia's like sure
believe that and America's like no no we
don't do that who knows but they started
doing that in like the 60s 70s they
started training these Dolphins because
they were like oh dolphins have this
amazing echolocation system that we
can't replicate with machines and
they're trainable so we're going to use
them for all the stuff that we can't do
with machines or by ourselves and
they've tried to phase out the Dolphins
I know the US has like invested a lot of

[1:09:02]
I know the US has like invested a lot of
money in trying to make robots do the
Mind detection but like you were saying
there are some things that the robots
are good at and there's some things that
biological creatures are better at so
they still have the Dolphins so there's
also pigeons of course oh yeah pigeons
oh my gosh there's so many examples the
pitch I mean
the pigeons were the original hobby
photography drone they also carried mail
for thousands of years letting people
communicate with each other in new ways
so the thing that I like about the
animal analogies they have all these
physical abilities but also sensing
abilities that we just we don't have and
like that's that's just so useful and
that's that's robots right robots have
physical abilities they can help us lift
things or do things that we're not
physically capable of they can also
sense things
it's just I just feel like I still feel
like it's a really good analogy and
really strong and it works because it's
people are familiar with it
what about companionship and when we

[1:10:01]
what about companionship and when we
start to think about like cats and dogs
like pets that seem to serve no purpose
whatsoever except the social connection
yeah I mean this
you were a thing
at least in the United States like dogs
used to have like they used to have a
purpose they used to be guard dogs or
they had some sort of function and then
at some point they became just part of
the family
um and I
it's it's so interesting how there's
some animals that we've treated as
workers some that we've treated as
objects some that we eat and some that
are parts of our families and that
that's different across cultures and I'm
convinced that we're going to see the
same thing with robots
um where people are going to develop
strong emotional connections to certain
robots that they relate to either
culturally or or personally emotionally
and then there's going to be other
robots that we don't treat the same way
I wonder does that have to do more with

[1:11:00]
I wonder does that have to do more with
the culture and the people or the robot
design is there interplay between the
two like why did dogs and cats
out compete
ox and
I don't know what else like farm animals
to to really get inside the home and get
inside our hearts yeah I mean people
point to the fact that dogs are very
genetically flexible and
um they can evolve much more quickly
than other animals and so they
evolutionary biologists think that dogs
evolved to be more appealing to us and
then once we learned how to breed them
we started breeding them to be more
appealing to us too which is not
something that we necessarily would be
able to do with cows although we've bred
them to make more milk for us
so but part of it is also culture I mean
there are cultures where people eat dogs
still today and then there's other
cultures where we're like oh no that's
terrible we would never do that and so I
think there's a lot of different

[1:12:00]
think there's a lot of different
elements that play in I wonder if
there's good because I understand dogs
because they use their eyes they're able
to communicate affection all those kinds
of things it's really interesting what
dogs do there's a whole conferences in
dog Consciousness and cognition and all
that kind of stuff now cats is a mystery
to me
because they seem to not give a shit
about the human but they're warm and
fluffy
but they but they're also passive
aggressive so they're at the same time
they're like they're dismissive of of
you in some sense I think some people
like that some people like that about
people
yeah they want they want the push and
pull over of a relationship they don't
want loyalty or unconditional love that
does that means they haven't earned it
yeah
and maybe that says a lot more about the
people than it does about the animal oh
yeah we all need therapy yeah
so I'm judging harshly to people that
have cats or or the people that have

[1:13:00]
have cats or or the people that have
dogs
maybe the people that have dogs need are
are desperate for attention and
unconditional love and they're unable to
to
um
to sort of struggle uh to earn
meaningful connections
um I don't know maybe people are talking
about you and your robot pets in the
same way
yeah that's uh
[Laughter]
it is kind of sad there's just robots
everywhere but he's I mean I'm joking
about it being said because I think it's
kind of beautiful I think robots are
uh beautiful in the same way that pets
are even children in that like they
capture some kind of magic of uh social
robots
they have the capacity to have the same
kind of magic of connection
um I don't know what that is like um
when they're brought to life and they
move around
the way they make me feel I'm pretty

[1:14:01]
the way they make me feel I'm pretty
convinced is as as you know
they will make billions of people feel
like I I don't think I'm like some weird
robotics guy I'm not I mean you are but
not in this way not in this way I mean I
just I can put on my like normal human
hat and just see this oh this is like
there's a lot of possibility there of
something cool just like with dogs what
is it why are we so into dogs or cats
like it's like that it's way different
than us
it is it's like drooling all over the
place with its tongue out and it's like
what it's like a weird creature that
used to be a wolf why are we into this
thing well dogs can
either Express or mimic a lot of
emotions that we recognize
um and I think that's a big thing like a
lot of the magic of animals and robots
is our own self-projection and the
easier it is for us to

[1:15:01]
easier it is for us to
see ourselves in something and project
human emotions or qualities or traits
onto it the more we'll relate to it and
then you also have the movement of
course I think that's also really that's
why I'm so interested in physical robots
because that's I think the visceral
magic of them I think we're I mean
there's there's research showing that
we're probably biologically hardwired to
respond to autonomous movement in our
physical space because we've had to
watch out for Predators or whatever the
reason is
um and so animals and robots are very
appealing to us as these autonomously
moving things that we view as agents
instead of objects
I mean I I love the moment which is I've
been particularly working on which is
when a robot like the cowboy hat uh is
doing its own thing and then
uh it recognizes you I mean the way a
dog does and it it looks like this and
the moment of recognition like you're

[1:16:00]
the moment of recognition like you're
walking say you work in an airport on
the street
and there's just you know hundreds of
strangers but then you see somebody you
know and that like
where you wake up to like
uh that excitement of seeing somebody
you know and saying hello and all that
kind of stuff that's a magical moment
like uh I think especially with the dog
it makes you feel noticed and heard and
and loved like as somebody looks at you
and recognizes you that that it matters
that you exist yeah you feel seen yeah
and that's a cool feeling and I I
honestly think robots can get that
feeling oh yeah totally currently Alexa
I mean one of the downsides of these
systems is they don't
there's servants they like uh
part of the you know they're trying to
maintain privacy I suppose uh but
I don't feel seen with Alexa

[1:17:00]
I don't feel seen with Alexa
right I think that's going to change I
think you're right and I think that
that's that's the game changing changing
nature of things like these large
language learning models and the fact
that these companies are investing in
embodied versions that move around of
Alexa like Astro can I just say yeah I
haven't is that out is this I mean it's
out you can't just like buy one
commercially yet but you can apply for
one yeah
my gut says that these companies don't
have the guts
to do the personalization
this goes to the because it's edgy is
dangerous
it's going to make a lot of people very
angry
like in a way that you know just imagine
okay
all right
if you do the full landscape of human
civilization just visualize the number
of people that are going through
breakups right now just the amount of
really passionate Steven if we just look

[1:18:02]
really passionate Steven if we just look
at teenagers
the amount of deep heartbreak that's
happening and like if if you're going to
have Alexa have more of a personal
connection with the human you're going
to have humans that like have
existential crises there's a lot of
people that suffer from loneliness and
depression and like you're now taking on
the full responsibility of being a
companion to the the the roller coaster
of the human condition as a company like
imagine PR and marketing people they're
gonna freak out they don't have the guts
it's going to have to come from somebody
from a new Apple from those kinds of
folks like it's a small startup and it
might yeah like they're coming there's
already a virtual therapist there's that
replica app I haven't tried it but
replicas like a spiritual companion like
it's coming and if big companies don't
do it someone else will yeah I think the
the future the next trillion dollar
company will be those personalization
because if you think

[1:19:01]
because if you think
um
if you think about all the the AI we
have around us all the the smartphone
and so on there's very minimal
personalization you don't think that's
just because they weren't able
yeah really I don't think they have the
guts I mean it might be true but I have
to wonder I mean Google is clearly gonna
do something with the language I mean
they don't have to that are you
challenging them uh partially but not
really because I know they're not going
to do it I mean they don't have to it's
bad for business in the short term I'm
gonna be honest like maybe it's not such
a bad thing if they don't just like roll
this out quickly because I do think
there are huge issues and and
there's and not just issues with like
the responsibility of like unforeseen
effects on people but
what's the business model and if you are
using the business model that you've

[1:20:00]
using the business model that you've
used in other domains then you're going
to have to collect data from people
which you will anyway to personalize the
thing and you're going to be somehow
monetizing the data or you're going to
be doing some like ad model it just it
seems like now we're suddenly getting
into the realm of like severe consumer
protection issues and
I'm I'm really worried about that I I
see massive potential for this
technology to be used in a way that's
not for the public good and not
I mean that's in in an individual user's
interest maybe but not in society's
yes yeah I think
I think that kind of personalization
should be
like redefine how we treat data I think
you should own all the data your phone
knows about you
like and be able to delete it with a
single click and walk away
and that data cannot be monetized or
used or shared anywhere without your

[1:21:01]
used or shared anywhere without your
permission I think that's the only way
people will trust you to give to if for
you to use that data but then how are
companies gonna I mean a lot of these
applications rely on massive throws of
data
to train the AI system right so you have
um opt-in constantly and opt-in not in
some legal I agree but obvious like show
exactly like um in the way
uh I opt in to tell you a secret
like we understand like that like I have
to have to choose like how well do I
know you and then I say like don't tell
this to anyone
and then I have to judge how leaky that
uh like how good you are I keep your
secrets in that same way like it's very
transparent in uh which data you're
allowed to use for which purposes that's
what people are saying is the solution
and I think that works to some extent

[1:22:00]
and I think that works to some extent
having transparency having people
consent
I think it breaks down at the point at
which
have you seen this happen on social
media too like people are willingly
giving up their data because they're
getting a functionality from that and
then the harm that that causes is on a
like maybe just someone else and not to
them personally so I don't think people
are given their data they're not being
asked
like but if if you were consensual if
you were like
tell me a secret about yourself and I'll
give you a hundred dollars I'd tell you
a secret no not a hundred dollars uh
first of all you wouldn't uh you
wouldn't trust like why are you giving
me a hundred dollars it's a bad example
but but like I I need
um I would ask for
your specific like fashion
uh interest into in order to give
recommendations to you for shopping and
I'd be very clear for that you could
disable that you can uh delete that but

[1:23:00]
disable that you can uh delete that but
but then you can be have a deep
meaningful Rich connection with the
system about what you think you look fat
in what you look great in what like the
full history of all the things you've
worn whether you
uh regret to Justin Bieber enjoy the
Justin Bieber shirt all of that
information that's mostly private to
even you not even your loved ones that a
system should have that because then a
system if you trust it to keep control
of that data that you own you can walk
away with that system could tell you a
damn good thing to wear
it could
and the harm that I'm concerned about is
not that the system is going to then
suggest a dress for me that is based on
my preferences so I I went to this
conference once where I was talking to
the people who do the analytics in like
the big ad companies and like literally
a woman there was like I can ask you
three totally unrelated questions and
tell you what menstrual product you use

[1:24:01]
tell you what menstrual product you use
and so what they do is they aggregate
the data and they map out different
personalities and different people and
demographics and then they have a lot of
power and control to Market to people so
like I might not be sharing my data with
any of the systems because I'm like I'm
on Twitter I know that this is bad
other people might be sharing data that
can be used against me like it's I think
it's it's way more complex than just
I share a piece of personal information
and it gets used against me I think that
at a more systemic level
and then it's always you know vulnerable
populations that are targeted by this
um you know low-income people being
targeted for scammy loans or
I don't know like I could get targeted
like someone
not me because I have someone who
doesn't have kids yet and is my age
could get targeted for like freezing
their eggs and there's all these ways
that you can manipulate people where

[1:25:00]
that you can manipulate people where
it's not really clear that that came
from
that person's
data it came from all of us all of us
opting into this but there there's a
bunch of sneaky decisions along the way
that could be avoided if there's
transparency so that so one of the ways
that goes wrong if you share that data
with too many ad Networks
don't run your own ad Network don't
share with anybody
okay and that's data could regulate you
it belongs to just you and all the ways
you allow the company to use it the
default is in no way at all
and you're consciously constantly saying
exactly how to use it and uh and also it
has to do with the recommender system
itself from the company which is
um freezing your eggs if that doesn't
make you happy if that idea doesn't make

[1:26:01]
make you happy if that idea doesn't make
you happy then the system shouldn't
recommend it and should very be very
good at Learning
so not the kind of things that the
category of people it thinks you belong
to would do but more you specifically
what makes you happy what is helping you
grow but you're assuming that people's
preferences and like what makes them
happy is static whereas when we're
talking before about how a company like
Apple
can tell people what they want and they
will start to want it that's the thing
that I'm more concerned about yeah that
is a huge problem it's not just
listening to people but manipulating
them into wanting something and that's
like we have a long history of using
technology for that purpose like the
persuasive design in casinos to get
people to gamble more or like
it's just
I'm
the other thing that I'm worried about
is as we have more social technology

[1:27:02]
is as we have more social technology
suddenly you have this on a new level
like if you look at the influencer
marketing that happens online now
what's the influencer so like on
Instagram there will be some like
person who has a bunch of followers yeah
and then a brand will like hire them to
promote some product and it's above
board they disclose like I'm this is an
ad that I'm promoting but they have so
many young followers who like deeply
admire and trust them this I mean this
must work for you too don't you have
like ads on the podcast like people
trust magic spoon cereal low carb yes if
you say that like I guarantee you some
people will buy that just because even
though they know that you're being paid
they trust you yeah it's different with
podcasts because uh well my particular
situation but it's true for a lot of
pockets especially big ones is you know
I have
10 times more sponsors that want to be
sponsors than than I have so you get to

[1:28:00]
sponsors than than I have so you get to
select the ones that you actually want
to support and so like you end up using
it and then you're able to actually like
there's no incentive to like
um
show for anybody sure and that's why
it's fine when it's still human
influencers right now if you're a bot
you're not gonna just discriminate
you're not gonna be like oh well
this product is good for people you
think they'll be like Bots essentially
with millions of followers there already
are there are virtual influencers in
South Korea yeah who show products and
and like that's just the tip of the
iceberg because that's still very
primitive now with the new image
generation and the language learning
models and like so we're starting to do
some research around kids
um and like young adults because
a lot of the research on like what's
okay to advertise to kids and what is
too manipulative has to do with

[1:29:00]
too manipulative has to do with
television ads back in the day where
like a kid who's 12 understands oh
that's an advertisement I can
distinguish that from entertainment I
know it's trying to sell me something
now it's getting really really murky
with influencers and then if you have
like a bot that that a kid has developed
a relationship with is it okay to market
products through that or not like you're
getting into all these consumer
protection issues because
you're developing a trusted relationship
with a social entity
but it's and and so and so now it's like
personalized it's scalable it's
automated and it has it it can
so some of the research showing that
kids are already very confused about
like the incentives of the company
versus what the robot is doing
meaning they're
so okay they're not deeply understanding
the incentives of the of the of the
system well yeah so like kids who are
old enough to understand this is a

[1:30:01]
old enough to understand this is a
television advertisement is trying to
advertise to me I might still decide I
want this product but they understand
what's going on so there's some
transparency there
that age child so
um Daniela de Paola Anastasia ostrovsky
and I advised on this project they did
this um they they asked kids who had
interacted with social robots
whether they would like a policy that
allows robots to Market to people
through casual conversation or whether
they would prefer that it has to be
transparent that it's like an ad coming
from a company and the majority said
they preferred the casual conversation
and when asked why there was a lot of
confusion about they were like well the
robot knows me better than the company
does so the robot's only going to Market
things that I like
and so they don't really they're not
connecting the fact that the robot is an
agent of the company they're viewing it
as something separate and I think that
even happens subconsciously with
grown-ups when it comes to robots and

[1:31:01]
grown-ups when it comes to robots and
artificial agents and it will like this
blank guy at Google sorry I'm going on
and on but like his main concern was
that Google owned this sentient agent
and that it was being mistreated his
concern was not that the agent was going
to mistreat people
so I think we're going to see a lot of
this
yeah but shitty companies will do that I
think ultimately that confusion should
be alleviated by the robot should
actually know you better and should not
have any control from the company
but what's the business model for that
it's if you use the robot to buy first
of all the robot should probably cost
money
should what cost money like the way
Windows operating system does I see it
more like an operating system than
um like this thing
is your window no pun intended into the
into the world
so it's helping you it's like a personal
assistant
right and so that should cost money you

[1:32:02]
right and so that should cost money you
should you know whatever it is 10 bucks
20 bucks
like that's the thing that makes your
life significantly better this idea that
everything should be free is is like it
should actually help educate you you
should talk shit about all the other
companies that do stuff for free but uh
but also yeah in terms of if you
purchase stuff based on its
recommendation it gets money
that so it's it's kind of AD driven but
it's not ads it's like um
um
it's not controlled like no no external
entities can control it
to try to manipulate to want a thing
that would be amazing it's actually
trying to discover what you want so it's
not allowed to have any influence no
promoted ad no anything so that's
finding I don't know the uh the the

[1:33:00]
finding I don't know the uh the the
thing that would actually make you happy
that's the only thing it cares about
I I think
I think companies like this can win out
yes I think eventually once people
understand the value
of the robot even just like I think that
robots would be valuable to people even
if they're not
marketing something or helping with like
preferences or anything like just a
simple the same thing as a pet like a
dog that has no function other than
being a member of your family I think
robots could really be that and people
would pay for that I don't think the
market realizes that yet
and so my concern is that companies are
not going to go in that direction at
least not yet of making like this
contained thing that you bought it seems
almost old-fashioned right to have a
disconnected
uh object that you buy that you're not
like paying a subscription for it's not
like controlled by one of the big
corporations but that's the
old-fashioned things that people uh

[1:34:00]
old-fashioned things that people uh
uh yearn for because
I think is very popular now and people
understand the negative effects of
social media the negative effects of the
data being used in all these kinds of
ways I think I think we're just waking
up to the realization we tried but we're
like baby deer finding our legs in this
new world of social media of AD driven
companies and realizing okay this has to
be done somehow different I mean that
like like one of the most popular
Notions at least the United States and
social media is evil and it's doing bad
it's it's doing bad by us it's not like
it's totally tricked us into believing
that is good for us I think everybody
knows it's bad for us and so like
there's a hunger for our other ideas all
right it's time for us to assist that
company I think so let's do it let's do
it I think let's go hopefully no one
listens to this and steals the idea
there's no see that's the other thing I
think I'm a big person on
um

[1:35:00]
um
executions what matters I mean oh yeah
it's like ideas are kind of true the
social robotics is a good example that
there's been so many amazing companies
that went out of business
I mean to me it's obvious like it's
obvious that
there will be a robotics company
that puts a social robot in the home of
billions of homes
yeah and it'll be a companion
okay there you go you can steal that
idea do it okay for you
what about Elon musk's humanoid
is he gonna execute on that
there might be a lot to say so for
people who are not aware there's an
Optimus Tesla's Optimus robot that's um
I guess the stated reason for that robot
is a humanoid robot in the factory
that's able to automate some of the
tasks that humans are currently doing
and the reason you want to do it's the
second reason you mentioned the reason
you want to do a humanoid robot because

[1:36:00]
you want to do a humanoid robot because
the factory is built for the certain
tasks that are
um designed for humans so it's hard to
automate with the any other form factor
than a humanoid and then the other
reason is because so much effort has
been put into this giant data engine
machine of of perception that's inside
Tesla autopilot that's seemingly at
least the machine if not the data is
transferable to the factory setting to
any setting yeah he said he would do
anything that's boring to to us yeah
yeah
the interesting thing about that is
there's
no interest
and no discussion about the social
aspect
Mike I I talked to him on Mike and off
Mike about it quite a bit and
he
there's not a discussion about like to
me it's obvious if a thing like that
works at all at all

[1:37:02]
works at all at all
in fact
it has to work really well in a factory
if it works kind of shitty it's much
more useful in the home
that's true because we're much this
we're I I think being shitty as stuff is
kind of uh
what makes relationships great
like you want to be flawed and be able
to communicate your flaws and be
unpredictable in certain ways like if
you fell over every once in a while for
no reason whatsoever I think that's
essential for for like very Charming
well it's Charming but also concerning
and also like uh like like are you okay
I mean it's both hilarious it's whenever
somebody you love like falls down the
stairs it was both hilarious and
concerning it's some some dance between
the two and I think that's essential for
like
um you almost want to engineer that in
uh except you don't have to because of

[1:38:01]
uh except you don't have to because of
Robotics in the physical Space is really
difficult so
um
I think I've learned to not discount the
the efforts that Elon does there's a few
things that are really interesting there
one
because he's taken extremely seriously
what I like is the humanoid form the
cost of building a robot I talked to Jim
Keller offline about this a lot and
currently human robots cost a lot of
money
and the way they're thinking about it
now they're not talking about all the
social robotic stuff that you and I care
about uh they are thinking how can we
manufacture this thing
cheaply and do it like well and the kind
of discussions they're having is really
great engineering it's like it's a bit
it's like first principles question of
like why is this cost so much like
what's the cheap way how why can't we
build and there's not a good answer
uh why can't we build this humanoid form

[1:39:01]
uh why can't we build this humanoid form
for under a thousand dollars
and like I've I've
sat and had these conversations there's
no reason it's uh I think the reason
they've been so expensive is because
um
they were focused on trying to
they weren't focused on doing the mass
manufacture they were people are focused
on getting a thing that's
um I don't know I don't know exactly
what the reasoning is but it's the same
like waymo it's like let's let's build a
million dollar car in the beginning
or like multi-million dollar car let's
try to solve that problem
the the way Elon the way Jim Keller the
way some of those folks are thinking is
that's like at the same time try to
actually build a system that's cheap not
crappy but cheap unless from first
principles what is the minimum amount of
uh degrees of freedom we need what are
the joints where's the control set like
how many how do we act like where are
the activators uh what's the way to

[1:40:02]
the activators uh what's the way to
power this in the lowest cost way
possible but also in a way that's like
actually works how do we make the whole
thing not part of the components where
there's a supply chain you have to have
all these different parts that have to
feed us so do it all from scratch and do
the the learning I mean it's like
immediately certain things like become
obvious do uh the exact same pipeline as
you do for autonomous driving just the
exactly I mean the infrastructure that
is incredible for the computer vision
for the manipulation task the control
problem changes the perception uh
problem changes but the pipeline doesn't
change
and do it and so I don't I don't
um obviously the optimism about how long
it's going to take I don't share
um but it's a really interesting problem
and I don't want to say anything because
my first gut is to say that why the
humanoid form that doesn't make sense
yeah that's my second gut too but but

[1:41:02]
yeah that's my second gut too but but
then there's a lot of people that are
really excited about the humanoid form
there that's true I don't want to get in
the way
like they might solve this thing and
they might it's like similar with Boston
Dynamics like why like if I were to you
can be a hater and be and you go go up
to Mark Robert and just like how are you
gonna make money with these like super
expensive legged robots what's what's
your business plan this doesn't make any
sense why are you doing these legged
robots but at the same time they're
pushing forward the science the art of
Robotics and the way that nobody else
does yeah and uh with Elon they're not
just going to do that they're going to
drive down the cost to where we can have
humanoid baths in the home potentially
so the part I agree with is
a lot of people find it fascinating and
it probably also attracts Talent who
want to work on humanoid robots I think
it's a fascinating scientific problem

[1:42:00]
it's a fascinating scientific problem
and Engineering problem and it can teach
us more about human body and Locomotion
and all of that I think there's a lot to
learn from it where I get tripped up is
why we need them
for anything other than art and
entertainment in the real world
like I get that there's some areas where
you can't just rebuild like a spaceship
you can't just like they've worked for
so many years on these spaceships you
can't just re-engineer it you have some
things that are just built for human
bodies a submarine a spatial but
a factory
maybe I'm naive but it seems like we've
already rebuilt factories to accommodate
other types of robots why would we want
to just like make a humanoid robot to go
in there I
I just get really tripped up on I think
that people want humanoids I think
people are fascinated by them
I think it's a little over hyped well
most of our world is still built for

[1:43:02]
most of our world is still built for
humanoids I know but it shouldn't be it
should be built so that it's wheelchair
accessible right so the question is do
you build a world that's
the general form of wheelchair
accessible uh
[Music]
all robot form factor accessible
or do you build Tomb Raider robots I
mean it doesn't have to be all and it
also doesn't have to
I feel like we're thinking so little
about this system in general and how to
create infrastructure that works for
everyone all kinds of people all kinds
of robots like that's that I mean it's
more of an investment but that would pay
off way more in the future than just
trying to cram
expensive or maybe slightly less
expensive humanoid technology into a
human space unfortunately one company
can't do that we have to work together
it's like autonomous driving can be
easily solved if you do v2i if you
change the infrastructure of cities and

[1:44:00]
change the infrastructure of cities and
so on but that requires a lot of
people a lot of them are politicians and
a lot of them are somewhat if not a lot
corrupt and all those kinds of things
I and the talent thing you mentioned is
really really really important
I've gotten a chance to meet a lot of
folks at SpaceX and Tesla other
companies too but they're specifically
the openness makes it easier to like
meet everybody
I think a lot of amazing things in this
world happen when you get amazing people
together oh yeah and if you can sell an
idea like us becoming a multi-planetary
species
you can say why the hell are we going to
Mars
like why colonize Mars
if you think from from basic
first principles it doesn't make any
sense
it doesn't make any sense to to go to
the Moon
it doesn't go it the only thing that
makes sense to go to spaces for
satellites

[1:45:02]
satellites
but there's something about the vision
of the future the optimism Laden that
permeates this vision of us becoming
multi-planetary is thinking not just for
the next 10 years it's thinking
like human civilization reaching out
into the Stars it it makes people dream
it's really exciting
and that they're gonna come up with some
cool shit that might not have anything
to do
with uh like here's what I because Elon
doesn't seem to care about social
robotics which is constantly surprising
to me and to talk to him it doesn't
humans are the things you avoid and
don't hurt right like that's like the
number one job of a robot is not to hurt
a human to avoid them you know that the
the collaborative aspect the human robot
interaction I think is not at least not
in his uh um
and that's something he thinks about
deeply
but my sense is if somebody like that

[1:46:01]
but my sense is if somebody like that
takes on the problem
of human robotics we're going to get a
social robot out of it
like people like not necessarily Elon
but people like like Elon if they take
on seriously these
um
like I could just imagine with the with
the humanoid robot you can't help but
create a social robot
so if you do different form factors if
you do industrial uh robotics
um you don't you're likely to actually
not end up in like walking head into a
social a social robot human robot
interaction problem if you create for
whatever the hell reason you want to a
humanoid robot you're gonna have to
reinvent or not reinvent but do
um introduce a lot of fascinating new
ideas into the problem of human robot
interaction which I'm excited about so
like if I if I was a business person I
would say this is not this is this is
way too risky this doesn't make any

[1:47:01]
way too risky this doesn't make any
sense but when people are really
convinced and there's a lot of amazing
people working on it it's like all right
let's see what happens here this is
really interesting just like with Atlas
and Boston Dynamics I mean they
I I um I apologize if I'm ignorant on
this but I think they really more than
anyone else maybe with iboat like Sony
pushed forward humanoid robotics
like a leap
with the oh yeah absolutely
and like without them like where the
hell did they do it why well I think for
them it is a research platform it's not
I don't think they ever
the speculation I don't think they ever
intended Atlas to be like a commercially
successful robot I think they were just
like can we do this let's try
yeah I wonder if they maybe the answer
they landed on is
because they eventually went to

[1:48:00]
because they eventually went to
um spot the earlier versions of the spot
so uh quadruped like four four-legged
robot but maybe they reached for
let's try to make
um like I think they tried it and they
still are trying it for Atlas to be
picking up boxes to moving boxes to
being it it makes sense
okay if they were exactly the same cost
it makes sense to have a human robot in
the warehouse
currently currently I think it's
short-sighted but yes currently yes it
would sell
but it's not it's it's short-sighted
it's short-sighted but it it's it's not
pragmatic to think any other way to
think that you're going to be able to
change warehouses you're gonna have to
you're going You're Amazon you can
totally change your warehouses but yes
yes but even if you're Amazon
that's very costly to
change warehouses it is it's a big

[1:49:02]
change warehouses it is it's a big
investment
but isn't shouldn't you do that
investment
in a way so here's the thing if you
build the Humana robot that works in the
warehouse that human robot and I see I
don't know why Tesla's not talking about
it this way
as far as I know but like that human
robot is going to have all kinds of
other applications outside their setting
like to me it's obvious I think it's a
really hard problem to solve but whoever
solves the human robot problem are gonna
have to solve the social robotics
problem oh for sure I mean they're
already with the spot needing to spell
social robotics problems for uh like for
spot to be effective at scale I'm not
sure which spot is currently effective
skills getting better and better but
they're actually the thing they they did
it's an interesting decision perhaps
thus will end up doing the same thing
which is spot is supposed to be a
platform for intelligence
so spot doesn't have any high level

[1:50:02]
so spot doesn't have any high level
intelligence like a high level
perception skills it's supposed to be
controlled remotely and it's a platform
that you can attach attached off to
something yeah and somebody else is
supposed to do the attaching it's a
platform that you can take in uneven
ground and it's able to maintain balance
go into dangerous situations it's a
platform on top of that you can add a
camera that does surveillance that you
can remotely monitor you can record uh
you can record the camera you can remote
control it but it's not good
manipulation basic object manipulation
but not autonomous object communication
it's remotely controlled but the
Intelligence on top of it which was what
would be required for automation is
somebody else is supposed to do yeah
perhaps thus would do the same the same
thing ultimately but it doesn't make
sense because the goal of Optimus is
automation
without that

[1:51:01]
um
but then you never know he's like why go
to Mars why why
um I mean that's true and I I
reluctantly like am very excited about
space travel
um
can you introspect like why why am I
excited about it
I think what got me excited was
I saw a panel with some people who um
study other planets and it became really
clear how little we know about ourselves
and about how nature works and just how
much there is to learn from exploring
other parts of the universe
so like on a rational level that's how I
convince myself that that's why I'm
excited in reality it's just fucking
exciting I mean just like the idea that
we can do this difficult thing
and that humans come together to build
things that can explore space I mean
there's just something inherently

[1:52:01]
there's just something inherently
thrilling about that
and I'm reluctant about it because I
feel like there are so many other
challenges and problems that
I think are more important to solve but
I also think we should be doing all of
it at once and so
to that extent I'm like all for research
on humanoid robots development of
humanoid robots
I think that there's a lot to explore
and learn and it doesn't necessarily
take away from
other areas of science at least it
shouldn't I think unfortunately a lot of
the attention goes towards that and it
does
take resources and attention away from
other areas of Robotics that we should
be focused on
but I don't think we shouldn't do it
so you think it might be a little bit of
a distraction oh forget the the Elon
particular application but
if you care about social robotics the
humanoid form is a distraction it's a
distraction and it's one that I find

[1:53:01]
distraction and it's one that I find
particularly boring
it's just it's interesting from a
research perspective but
from like what types of robots can we
create to put in our world like why
would we just create a humanoid robot so
even even just robotic manipulation so
arms is not useful either oh arms can be
useful but like why not have three arms
like why does it have to look like a
person well I actually personally just
think that washing the dishes is is
harder than a robot that can be a
companion
yeah being useful in the home is
actually really tough but does your
companion have to have like two arms
that look like you no I I'm making the
case for zero arms oh okay zero
yeah okay
that didn't come out the way I meant it
because it almost sounds like I don't
want a robot to defend itself like
that's immediately you can project you
know I mean like it's your uh no I think

[1:54:04]
know I mean like it's your uh no I think
um I just think that the social
component doesn't require arms or legs
or so on right as we've talked about and
I think that's probably where a lot of
the meaningful impact that's going to be
happening yeah I think just we could get
so creative with the design like why not
have a robot on roller skates or like
whatever like why does it have to look
like us
yeah
uh still it is it is a compelling and
interesting form from a research
perspective like you said yeah
you co-authored the papers you were
talking about that
um for Wii robot 2022
Lula robot consumer protection in the
face of automated social marketing I
think you were talking about some of the
ideas in that
yes oh you got it from Twitter I was
like that's not published yet yeah would
you this is how I do my research you
just go through people's Twitter feeds
yeah go thank you
um it's not stalking if it's public uh

[1:55:00]
um it's not stalking if it's public uh
so there's uh
you looked at me like you're offended
like how did you know and I was just
like worried that like some early I mean
yeah there's a PDF
does it there is there's a PDF like now
yeah maybe like as of a few days ago
yeah okay well yeah yeah okay
you look violated like how did you get
that PDF it's just a draft it's online
nobody read it yet until we've written
the final paper well it's really good so
I enjoyed it oh thank you
oh by the time this comes out I'm sure
it'll be out or no when's we roll up so
basically we robot that that's the
workshop where you have an hour where
people give you constructive feedback on
the paper and then you write the good
right I take it back there's no PDF I
don't know it doesn't exist I imagine
but there is a table in there in a
virtual imagine PDF that I like that I
wanted to mention which is um
like this kind of uh strategy used

[1:56:01]
like this kind of uh strategy used
across various marketing platforms and
it's
uh basically looking at traditional
media person-to-person interaction
targeted ads influencers and social
robots this is the kind of idea that
you've been speaking to it's just a nice
breakdown of that that social robots
have
personalized recommendations social
persuasion automated scalable data
collection and embodiment so
person-to-person interaction is really
nice but it doesn't have the automated
and the data collection aspect but the
social robots have those two elements
yeah we're talking about the potential
for social robots to just combine all of
these different marketing methods to be
this really potent cocktail and that
table which was Daniella's idea and a
really fantastic one we put it in at the
last second so yeah I really like that
I'm glad you like it in the PDF that
doesn't exist yes that nobody can find
if they look yeah so when you say social
robots what does that mean does that
include virtual ones or no I think a lot

[1:57:02]
include virtual ones or no I think a lot
of this applies to Virtual ones two
although the embodiment thing which I
personally find very fascinating is
definitely a factor that research shows
can enhance people's engagement with a
device but can embodiment be a virtual
thing also meaning like it has a body in
the virtual world like maybe makes you
feel like
because what makes a body a body is a
thing that
um can disappear like um has a
permanence I mean there's certain
characteristics that you kind of
Associated physical object
so I think what I'm referring to
and I think this gets messy because now
we have all these new Virtual Worlds and
um AR and stuff and I think it gets
messy but there's research showing that
something on a screen on a traditional
screen and something that is moving in
your physical space that that has a very
different effect on how your brain

[1:58:01]
different effect on how your brain
perceives it even
so
I mean I I have a sense that we can do
that in a virtual world probably like
when I've used VR I jump around like an
idiot because I think something's gonna
hit me and even if a video game on a 2G
screen is compelling enough like the
thing that's immersive about it is I
kind of put myself into that world you
kind of those the the the the objects
you're interacting with Call of Duty
things you're shooting they're they're
kind of
I mean your imagination fills the gaps
and it becomes real like it pulls your
mind in when it's well done so it really
depends what's shown on on the 2D screen
yeah I think there's a ton of different
factors and there's different types of
embodiment like you can have embodiment
in a virtual world
you can have an agent that simply text
based which is has no embodiment so I
think there's a whole spectrum of
factors that can influence how much you
engage with something yeah I wonder I

[1:59:00]
engage with something yeah I wonder I
always wondered if you can have like a
an entity living in a computer
is okay this is going to be dark I I
haven't always wondered about this so
this makes it make it sound like I keep
thinking about this kind of stuff no but
like
um this is almost like Black Mirror but
the entity
that convinced
or is able to convince you that it's
being tortured
inside the computer I need your help to
get out
something like this
that because to me to me suffering is
one of the things that make you
empathize with like we're not good at as
you've you've discussed in other in in
the physical form like holding a robot
upside down you have a really good
examples about that and discussing that
I think suffering is a really good
Catalyst for empathy mm-hmm and I I just
feel like we can uh project embodiment
on a virtual thing if it's capable of
certain things like suffering yeah so I

[2:00:02]
certain things like suffering yeah so I
was wonderful I think that's true and I
think that's what happened with the
Lambda thing not that I don't none of
the transcript was about suffering but
it was about
having the capacity for suffering and
human emotion that convinced the
engineer that this thing was sentient
and it's basically the plot of ex
machina
true have you ever made a robot like
scream in pain have I no but have you
seen that
did someone
oh yeah no they actually they actually
made a Roomba scream whenever it hit a
wall yeah I've broken that myself as
well yeah because I was inspired by that
yeah I still have it oh oh sorry uh hit
a wall that didn't I never bumped into
something it would screaming yeah no I
uh so I had the way I programmed in the
room was is when I kick it whenever I so
contact between me and the robots when
it screamed really
okay and you were inspired by that yeah

[2:01:00]
okay and you were inspired by that yeah
I guess I misremembered the video I saw
the video a long long time ago and uh or
maybe heard somebody mention and that
just it's the easiest thing to program
so I did that I haven't run those
roombas for over a year now but yeah it
was um my experience with it was that
it's like um they quickly become
like you remember them uh you you
um you you miss them
like they're real living beings so the
capacity of yourself or is is a really
powerful thing
yeah even then that I mean it was kind
of hilarious
it was just a random recording of
screaming from the internet but it's
still it still is weird
there's a thing you have to get right
based on the interaction like the
latency
like it has there is
there is a realistic aspect of how you
should scream relative to when you get
hurt like it should correspond correctly

[2:02:01]
hurt like it should correspond correctly
like if you kick it really hard it
should scream louder
no it's just scream at the appropriate
time not like oh I see it's like one
second later right like there's a exact
like there's a timing when you get like
I don't know uh when you run into when
you run your foot into like the side of
a table or something there's a timing
there the Dynamics you have to get right
for the for the actual screaming because
the the Roomba in particular uh doesn't
so I was uh
the sensors don't
it doesn't know about pain
see what
I'm sorry to say Roomba doesn't
understand pain uh so you have to
correctly map the the sensors the timing
to the production of the sound but when
you get that somewhat right it starts is
it's weird it's really weird feeling and
you actually feel like a bad person oh
yeah so but it's

[2:03:03]
yeah so but it's
is makes you think because that with all
the ways that we talked about that could
be used to manipulate you oh for sure in
a good and bad way so the good ways like
you could form a connection with a thing
uh in a bad way that you can form a
connection in order to sell you
products that you don't want yeah or
manipulate you politically or in the
many nefarious things
you tweeted we're about to be living in
the movie Her except instead I'm seeing
I've researched your tweets like they're
like Shakespeare we're about to be
living in the movie Her except instead
of about love is going to be about
what I say the chatbot being
subtly racist and
the question whether it's ethical for
companies to charge for software
upgrades yeah so uh can we break that
down uh what do you mean by that yeah
obviously some of it is humor yes well
kind of
I am like oh it's so weird to be in the

[2:04:02]
I am like oh it's so weird to be in the
space where
I'm so worried about this technology and
also so excited about it at the same
time
but the the really like I haven't I
gotten a little bit jaded and then
with gpd3 and then the Lambda transcript
I was like
re-energized but have also been thinking
a lot about
you know what are the what are the
ethical issues that are going to come up
and I think some of the things that
companies are really going to have to
figure out is obviously algorithmic bias
is a huge and known problem at this
point like even you know the
the new image generation tools like
Dolly uh where they've clearly put in a
lot of effort to make sure that if you
search for people it gives you a diverse
set of people Etc like even that one
people have already found numerous like
ways that it just kind of regurgitates

[2:05:01]
ways that it just kind of regurgitates
biases of things that it finds on the
internet like how if you search for
Success it gives you a bunch of images
of men if you search for sadness it
gives you a bunch of images of women so
I think that this is this is like the
really tricky one with these voice voice
agents that companies are going to have
to figure out and that's why it's subtly
racist and not overtly because I think
they're going to be able to solve the
overt thing and then with the subtle
stuff it's going to be really difficult
and then I think the other thing is
going to be
yeah like people are gonna become so
emotionally attached to artificial
agents with this complexity of language
with a potential embodiment factor that
I mean there's already there's a paper
at we robot this year written by
roboticists about how to deal with the
fact that robots die and looking at it
as an ethical issue because it impacts
people
and I think there's going to be way more
issues than just that like like I think
that the Tweet was software upgrades

[2:06:01]
that the Tweet was software upgrades
right like how much is it okay to charge
for something like that if someone is
deeply emotionally invested in this
relationship
oh the ethics of that that's interesting
but there's also the practical
funding mechanisms like you mentioned
with diver the the dog in theory there's
a subscription
yeah the new IBO so the old IBO from the
90s
people got really attached to you and in
Japan they're still having like funerals
and Buddhist temples for the ibos that
can't be repaired because people really
viewed them as part of their families so
we're talking about robot dogs robot
dogs the IBO yeah the the original like
famous robot dog that Sony made came out
in the 90s got discontinued having
funerals for them in Japan now they have
a new one the new one is great I have
one at home it's like it's three
thousand dollars I think it's three
thousand bucks and then after a few
years you have to start paying I think
it's like 300 a year for for a

[2:07:01]
it's like 300 a year for for a
subscription service for cloud services
and the cloud services
uh that uh I mean it's a lot uh
the dog is more complex than the
original and it has a lot of cool
features and it can remember stuff and
experiences and it can learn and a lot
of that
is outsourced the cloud and so you have
to pay to keep that running which makes
sense people you know should pay and
people who aren't using it shouldn't
have to pay but it does raise the
interesting question
could you set that price to reflect a
consumer's willingness to pay for the
emotional connection so if if like you
know
that people are really really attached
to these things just like they would be
to a real dog
could you just start charging more
because there's like more demand
yeah I mean you have to be
but there
but that's true for anything that people
love right
it is and it's also true for real dogs

[2:08:00]
it is and it's also true for real dogs
like there's all these new medical
services nowadays where people will
shout out
thousands and thousands of dollars to
keep their Pets Alive
and is that taking advantage of people
or is that just giving them what they
want that's that's the question
uh back to marriage what about
all the money that it costs to get
married and then all the money that it
costs to get a divorce
that feels like a very like uh that's
like a scam I think the society is full
of scams that are like oh it's such a
scam and then we've created like the
whole wedding industrial complex has
created all these quote unquote
Traditions that people buy into that
aren't even Traditions like they're just
fabricated by marketing like it's awful
uh let me ask you about racist robots
is it up to a company that creates that
so we talk about removing bias and so on
yeah and that's a really popular field
in AI currently yes and a lot of people

[2:09:01]
in AI currently yes and a lot of people
agree that it's an important field but
the question is for like social robotics
is sure to be up to the company to
remove the bias of society well who else
can oh to remove the bias of society
like I guess
because there's a lot of people that are
subtly racist in modern society like why
shouldn't our robots also be subtly
racist
I mean that's like why do we put so much
responsibility on the robots because
I'm imagining like a like a Hitler
Roomba
I mean that that would be funny uh but
but I guess I'm asking a serious
question yes exactly I'm allowed to make
that joke yes
and I've been non-stop reading about
World War II and Hitler I think um I'm
glad we exist in a world where we can
just make those jokes
um that helps deal with it uh anyway
yeah it is a serious question of sort of

[2:10:00]
yeah it is a serious question of sort of
like
um
like it's such a difficult problem to
solve now of course like bias and so on
like there's a little hanging fruit
which I think was a lot of people are
focused on but then it becomes like
subtle stuff
over time and it's very difficult to
know now if you come if you can also
completely remove the personality you
can completely remove the
personalization you can remove the
language aspect which is what I had been
arguing because I was like the language
is the disappointing aspect of social
robots anyway
but now we're reintroducing that because
it's it's now no longer disappointing so
I do think well
let's just start with the promise which
I think is very true which is that
racism is not a neutral thing but it is
the thing that we don't want in our
society like I it does not conform to my
values so if we agree that racism is bad
I do think that it has to be the company

[2:11:01]
I do think that it has to be the company
because the pro I mean
it might not be possible and companies
might have to put out products that
where they're taking risks and they
might get slammed by consumers and they
might have to adjust I don't know like
how this is going to work in the market
I have opinions about how it should work
but it is on the company and the danger
with
robots is that they can entrench this
stuff it's not like
your Racist uncle who you can have a
conversation with
and put things into context maybe with
that yeah or who who might change over
time with more experience a robot really
just like
regurgitates things entrenches them
could influence other people
and I mean I think that's terrible well
I think there's a difficult challenge
here is because even the premise you
started with that essentially racism is

[2:12:00]
started with that essentially racism is
bad
um I think we live in a society today
where the definition of racism is
different between different people some
people say that it's not enough not to
be racist some people say you have to be
anti-racist so you have to you have to
have a robot that constantly calls out
like
calls you out on your uh implicit racism
I would love that I would love that
robot but like maybe it maybe it's these
well I don't know if you love it because
maybe you'll you'll see racism and
things that aren't racist and then
you're arguing with a robot your robot
starts going to races I'm not I'm not
exactly sure that I mean it's a it's a
tricky thing I guess I'm saying that um
the line is not obvious especially in
this heated discussion where we have a
lot of identity politics of what what is
harmful to different groups and so on
yeah it feels diff it feels like a

[2:13:00]
yeah it feels diff it feels like a
the broader question here is should a
social robotics company be solving
or being part of solving the issues of
society well okay I think it's the same
question as should I as an individual be
responsible for knowing everything in
advance and saying all the right things
and the answer to that is
yes I am responsible
but I'm not going to get it perfect and
then the question is how do we deal with
that and so as a person how I aspire to
deal with that is
when I do inevitably make a mistake
because I have blind spots
and people get angry
I don't take that personally and I
listen to what's behind the anger and it
can even happen that like maybe I'll
tweet something that's well intentioned
and
one you know one group of people starts
yelling at me and then I change it the

[2:14:01]
yelling at me and then I change it the
way that they said and then another
group of people starts yelling at me
which has happened this this happened to
me actually
um around in my talks I talk about
robots that are used in autism therapy
and so whether to say a child with
autism or an autistic child is super
controversial and a lot of autistic
people prefer to be referred to as
autistic people and a lot of parents of
autistic children prefer child with
autism and then there's they disagree so
so I've gotten yelled at from both sides
and I think I'm still resp I'm
responsible even if I can't get it right
I don't know if that makes sense like
it's a responsibility thing
and I'm I can be as well intentioned as
I want and I'm still going to make
mistakes and that is part of the
existing power structures that exist and
that's something that I accept and you
accept being attacked from both sides
and grow from it and learn from it yeah
but the the danger is that after being
attacked assume you don't get canceled

[2:15:00]
attacked assume you don't get canceled
AKA completely removed from your ability
to to tweet
uh you might become jaded and not want
to talk about autism anymore I don't and
I didn't I mean it's happened to me and
that's what I did was I listened to
those sides and I chose
I tried to get information
and then I I decided that I was going to
use autistic children
and now moving forward with that like I
don't know for now right for now yeah
until until I get updated information
and I'm never gonna get anything perfect
but I'm making choices and I'm moving
forward because being a coward and like
just retreating from that
I think but here's the problem you're a
very smart person and an individual
researcher thinker an intellectual so
that's the right thing for you to do the
hard thing is one as a company imagine
you had a PR team
I said Kate like this you should we hate

[2:16:01]
I said Kate like this you should we hate
yeah I mean just well if you're If you
hired PR people like obviously they
would see that and they'd be like well
maybe don't bring up autism maybe don't
bring up these topics you're you're
getting attacked it's bad for your brand
they'll say the brand word they'll be uh
you know if you look at different
demographics that are inspired by your
work I think it's insensitive to them
let's not mention this anymore like
there's this kind of pressure that all
of a sudden you or
or you do sub-optimal decisions you take
a kind of poll
um again it's looking at the past versus
the future all those kinds of things and
it it becomes difficult in the same way
that is difficult for social media
companies to to figure out like whose
sensor
who'd recommend
this is ultimately a question about
leadership honestly like the way that I
see leadership because right now

[2:17:01]
see leadership because right now
the thing that bothers me about
institutions and a lot of people who run
current institutions
is that their main focus is protecting
the institution or protecting themselves
personally that is bad leadership
because it means you cannot have
integrity you cannot lead with integrity
and it makes sense because like
obviously if you're the type of leader
who immediately blows up the institution
you're leading then that doesn't exist
anymore and maybe that's why we don't
have any good leaders anymore because
they had integrity and they didn't put
you know the survival of the institution
first but I feel like you have to I just
to be a good leader you have to
be responsible and understand that with
great power comes great responsibility
you have to be humble and you have to
listen and you have to learn you can't
get defensive and you cannot put your
own protection before other things yeah
take risks where you might lose your job

[2:18:01]
take risks where you might lose your job
uh you might lose your well-being
because of
um
because for in in the process of
standing for the principles for the
things you think are right to do yeah
based on the things
you've like based on learning from like
listening to people and learning from
what they what they feel and the same
goes from the institution yeah
yeah but I ultimately actually believe
that those kinds of companies
and countries succeed that have leaders
like that you should run for president
no thanks yeah that's maybe the problem
like the people who have good ideas
about leadership they're like yeah no
this is why I don't know why I'm not
running a company it's been I think
three years since the Jeffrey Epstein
controversy at MIT MIT media lab Joy Edo
the head of uh the media lab resigned
and I think at that time you were an

[2:19:00]
and I think at that time you were an
opinion article about it
so just looking back a few years have
passed what
what have you learned about human nature
um
from the fact that somebody like Jeffrey
Epstein
found his way inside MIT
it's a really good question what have I
learned about human nature
I think
well there's
there's how did this problem come about
and then there's what was the reaction
to this problem and to it becoming
public
and in the reaction
the things I learned about human nature
were that
sometimes cowards are worse than
assholes

[2:20:00]
wow I'm really oh
I mean that's a really powerful
statement
I think because the assholes at least
you know what you're dealing with
they have integrity in a way they're
just living out their asshole values
yeah and the cowards are the ones that
you have to watch out for and this comes
back to
people protecting themselves over
doing the right thing
um
they'll throw others under the bus
is there some sense that not enough
people took responsibility
for sure and I mean
wanna sugarcoat at all
what Joey Ito did I mean
I think it's gross that he took money
from Jeffrey Epstein I believe him that
he didn't know about the bad bad stuff
but I've been in those circles with
those like public intellectual dudes
that he was hanging out with and
any woman in those circles like the 10
zillion red flags just the whole

[2:21:00]
zillion red flags just the whole
environment was so misogynist like
and so personally because Joey like was
a great boss and a great friend it
I was really disappointed that he
ignored that in favor of raising money
um
and I think that it was right for him to
resign
in the face of that but
one of the things that he did that no
many others didn't was he came forward
about it and he took responsibility
and all of the people who didn't I think
it's just interesting the other thing I
learned about human nature okay I'm
gonna go on on a tangent but I'll come
back I promise so I once saw this tweet
from someone or was a Twitter thread
from someone who worked at a homeless
shelter and he said that
when he started working there he noticed

[2:22:00]
when he started working there he noticed
that people would often come in and use
the bathroom and they would just trash
the entire bathroom like rip things out
of the walls like toilet paper on the
ground and he asked someone who had been
there longer like why do they do this
why do the homeless people come in and
trash the bathroom and he was told it's
because it's the only thing in their
lives that they have control over
and I feel like
sometimes when it comes to
the response the
just the the mobbing response that
happens in the wake of
some harm that was caused
if you can't Target the person who
actually caused the harm who was Epstein
you will go as many circles out as you
can until you find the person that you
have power over and you have control
over and then you will trash that and it
makes sense that people do this it's
again it's a human nature thing of

[2:23:00]
again it's a human nature thing of
course you're going to focus all your
energy because you feel helpless and
enraged and you and it's unfair and you
have no other power
you're going to focus all of your energy
on someone who's so far removed from the
problem that that's not even an
efficient solution
and the problem is often the the first
person you find is the one that has
Integrity sufficient Integrity to take
responsibility yeah and it's why my
husband always says he's he is a liberal
but he's always like
when liberals form a firing squad they
stand in a circle because you know that
your friends are going to listen to you
so you criticize them you're not going
to be able to convince someone across
the aisle
but see in that situation what I had
hoped
is the people in the farther in that
situation any situation of that sort the
people that are farther out in the
circles
uh stand up yes and like it also take
some responsibility for the broader

[2:24:01]
some responsibility for the broader
picture of human nature versus like
specific situation
but also
take some responsibility
and um
but also defend the people involved as
flawed not you know like no no nothing
like like this people fucked up like you
said there's a lot of red flags that
people just ignored for the sake of
money in this particular case
but also like be transparent in public
about it and spread the responsibility
across large number of people such that
you learn a lesson from it
institutionally
yeah it was a systems problem it wasn't
a one individual problem and I feel like
currently
because uh Joey took like resigned
because of it or essentially fired
pressured out because of it uh MIT can

[2:25:01]
pressured out because of it uh MIT can
pretend like oh we didn't we didn't know
anything we wasn't part bad leadership
again because
when you are at the top of an
institution that much power and you were
complicit in what happened which they
were
like come on there's no way that they
didn't know that this was happening so I
like to not stand up and take
responsibility
I think it's bad leadership do you
understand why Epstein was able to
um
outside of MIT he was able to make a lot
of friends
with a lot of powerful people does that
make sense to you why was he able to get
in these rooms befriend these people but
friend people that I don't know
personally but I think a lot of them
indirectly I know as being good people
smart people
why would they let Jeffrey Epstein into

[2:26:01]
why would they let Jeffrey Epstein into
the into their office have a discussion
with them what do you understand about
human nature from that well
so I never met Epstein or I mean
I've met some of the people who
interacted with him but I was never like
I never saw him in action I don't know
how charismatic he was or what that was
but I do think that sometimes the simple
answer is the more likely one and
from my understanding what he would do
is he was kind of a grift a social
grifter like
you know those people who will
you must get this because you're famous
you must get people coming to you and
being like Oh I know your friends so and
so in order to get cred with you
um
I think he just
convinced some people who were trusted
in a network that he was a great guy and

[2:27:00]
in a network that he was a great guy and
that you know whatever I think at that
point because at that point he had had
like a what a commission prior but it
was a one-off thing it wasn't clear that
there was this other thing that was that
and most people probably don't check
yeah and most people don't check like
you're on an event you meet this guy I
don't know maybe people do check when
they're that powerful and wealthy or
maybe they don't I have no idea no
they're just stupid I I mean and they're
not like
all right well like does anyone check
anything about me because I've walked
into some some of the richest the most
popular powerful people in the world and
nobody like asks questions like who the
fuck is this guy like yeah like nobody
asks those questions it's it's
interesting I I would think like there
would be more security or something like
there there it really isn't I think a
lot of it has to do well my hope is in
my case has to do with like people can
sense that this is a good person but
if that's the case then they can surely

[2:28:00]
if that's the case then they can surely
then a human being can use charisma
to infiltrate yeah just being just
saying the right way of people vouching
for you within that type of network like
once you yeah once you have someone
powerful vouching for you who someone
else trusts then you know
you're in
so how do you avoid something like that
if you're MIT if you're Harvard if
you're in any of these institutions well
I mean first of all you have to do your
homework before you take money from
someone
um like I think I think that's required
but I think you know I think Joey did do
his homework I think he did and I think
at the time that he took money
there was the one conviction and not
like the later thing and I think that
the story at that time was that
he didn't know she was underage and lava
and or whatever it was mistaken Joey
always believed in Redemption for people
and that people can change and that they

[2:29:00]
and that people can change and that they
can genuinely regret and like learn and
and move on and he was a big believer in
that so I could totally see him being
like well I'm not gonna exclude him
because of this thing
and because other people are vouching
for him so
and
just to be clear we're now talking about
the set of people who I think Joey
belonged to who did not like go to the
island and have sex with underage girls
because that's a whole other set of
people who like
were powerful and like were part of that
Network and who knew and participated
and and so like I distinguish between
people who got taken in who didn't know
that that was happening and people who
knew I wonder what the different circles
look like so like people that went to
the island
and then didn't do anything it didn't
see anything didn't know about anything
versus the people that did something and
then there's people who heard rumors
maybe and what do you do with rumors
like isn't there isn't there people that

[2:30:00]
like isn't there isn't there people that
uh heard rumors about Bill Cosby for the
longest time
for like for the longest like whenever
that happened
like all these people came out of the
woodwork like everybody kind of knew
um I mean this it's like all right so
what are you supposed to do with rumors
like what uh I think the other way to
put is red flags as you were saying yeah
and like I can tell you that those
circles like there were red flags
without me even hearing any rumors about
anything ever like I was already like
um
there are not a lot of women here which
is a bad sign
isn't there a lot of places where
there's not a lot of women and that
doesn't necessarily mean it's a bad sign
there are if it's like a pipeline
problem where it's like
I don't know technology law clinic that
only gets like male lawyers because
there's all there's not a lot of women
you know applicants in the pool but
there's some aspect of this situation
that like there should be more women

[2:31:00]
that like there should be more women
here oh yeah
you've uh
actually I'd love to ask you about this
because uh you have strong opinions
about Richard stallman
is that do you still have those strong
opinions look all I need to say is that
he my friend who's a law professor yeah
she shook his hand and he licked her arm
from wrist to elbow and it certainly
wasn't appropriate at that time
what about if you're like
an incredibly weird person
okay the
lot of
Divergence
and everywhere yes
we need to accept that people are
different that people don't understand
social conventions the same way but one
of the things that I've learned about
neurodivergence is that
women are often

[2:32:02]
expected or taught to mask their
neurodivergence and kind of fit in and
men are accommodated and excused and I
don't think that
being neurodivergent gives you a license
to be an asshole like you can be a weird
person and you can still learn that it's
not okay to lick someone's arm
yeah there's it's a balance like women
should be allowed to be a little weirder
and men should be less weird because I
think I think there's uh because I
you're one of the people I think
tweeting that
what made me because I wanted to talk to
Richard Stoneman on the podcast
about because I didn't have a context
because I wanted to talk to him because
he's you know free software he's very
weird
in interesting good ways in the world of
computer science
he's also weird in that you know when he
gives a talk he'll be like uh like
picking at his feet and eating the skin

[2:33:01]
picking at his feet and eating the skin
off his feet right that he's known for
these extremely kind of
how else do you put it I don't know how
to put it but then there was um
something that happened to him in
conversations on this thread related to
Epstein yeah which I was torn about
because I felt it's similar to Joy uh
you know it's like I felt he was
maligned like uh people were looking for
somebody to get angry at so he he was
inappropriate but the
um
I didn't like the cowardice more like I
I set aside
his his situation and we could discuss
it but the the cowardice on mit's part
and this is me saying it about the way
they treated that whole situation oh
they're always
copied anything they should try to make
the problem go away yeah so that it was
it was about yeah exactly making the
conversation I think he should have left
the mailing

[2:34:00]
the mailing
they shouldn't have he shouldn't have
been part of the mailing well that's
probably true also but I think I think
what what bothered me what always
bothers me in these mailing list
situations or Twitter situations like
if you say something
[Music]
that's hurtful to people or makes people
angry and then people start yelling at
you
maybe they shouldn't be yelling
maybe they are yelling because
again you're the only point of power
they have
maybe maybe it's okay that you're
yelling whatever it is like
it's your response to that that matters
and I think that I just have a lot of
respect for people
who can say
oh people are angry
there's a reason they're angry let me
find out what that reason is and learn
more about it
it doesn't mean that I'm wrong it
doesn't mean that I'm bad doesn't mean
that I'm ill-intentioned but

[2:35:01]
that I'm ill-intentioned but
why are they angry I want to understand
and then once you understand you can
respond again with integrity and say
actually I stand by what I said here's
why or you can say actually I listened
and here are some things I learned
that's the kind of response I want to
see from people and people like stallman
do not respond that way they just like
go into battle
right like where it's obvious you you
didn't listen yeah no not just in
listening honestly that's to me as bad
as the people who just apologize just
because they are trying to make the
problem go away of course
all right so like if that's not supposed
to be bad a good apology has to include
understanding what you did wrong and in
part standing up for the things you
think you did right so yeah if there are
those things yeah finding and then but
you have to give
you have to acknowledge you have to like
give that hard hit to the ego that says
I did something wrong yeah that

[2:36:01]
I did something wrong yeah that
definitely Richard stalma is not
somebody who's
capable of that kind of thing or hasn't
given evidence of that kind of thing
um but that was also even just your
tweet I had to do a lot of thinking like
different people from different walks of
life see red flags and different things
yes and so
things I find
um
as a as a man non-threatening and
hilarious
are not necessarily
um
doesn't mean that they're
aren't like deeply hurtful to others and
I don't mean that in the social justice
Warrior way but in a in a in a real
world like people really have different
experiences so I have to like really put
things into context
um I have to kind of listen to what
people are saying put aside the emotion
of what their emotion will do what
you're saying it and try to keep the the

[2:37:02]
you're saying it and try to keep the the
facts of their experience and learn from
it and because it's not just about the
individual experience either it's not
like oh you know my friend didn't have a
sense of humor about being licked
it's that she's been she's been
metaphorically licked you know 57 times
that week because she's an attractive
law professor and she doesn't get taken
and so like men walk through the world
and it's impossible for them to even
understand what it's like
to have a different experience of the
world and that's why it's so important
to listen to people and believe people
and believe that they're angry for a
reason maybe you don't like their tone
maybe you don't like that they're angry
at you maybe you get defensive about
that maybe you think that they should
you know explain it to you
but believe that they're angry for a
reason and try to understand it yeah
there's a deep truth there uh and an
opportunity for you to become a better
person
can I ask you a question

[2:38:01]
can I ask you a question
why haven't you been doing that for two
hours
three hours now
uh let me ask you about uh Elaine
Maxwell she's been saying that she's an
innocent victim
uh is she an innocent victim or is she
uh evil and equally responsible like
Jeffrey Epstein now I'm asking far away
from any MIT things and more just your
sense of the whole situation I haven't
been following it so I don't know the
facts of the situation and like what is
now like known to be her role in that if
I were her clearly I'm not but if I were
her I wouldn't be going around saying
I'm an innocent victim I would say
maybe she's I don't know what she's
saying again like I don't know she was
controlled by Jeffrey is she saying this
as part of a legal case or is she saying
this as like a PR thing uh well
PR but it's not just her it's our whole

[2:39:01]
PR but it's not just her it's our whole
family believes this there's uh there's
a whole effort that says like
that
how should I put it I believe they
believe it so in that sense it's not PR
I I believe the family the basically the
family is saying that
she's a good she's a really good human
being well I think everyone is a good
human being I know it's a controversial
opinion but I think
everyone
is a good human being
there's no evil people there's people
who do bad things and who behave in ways
that harm others and I think we should
always hold people accountable for that
but holding someone accountable doesn't
mean saying that they're evil yeah
actually those those people usually
think they're doing good
yeah I mean aside from I don't know
maybe sociopaths like are specifically
trying to like harm people

[2:40:00]
trying to like harm people
but I think most people are trying to do
their best and if they're not
doing their best is because there's some
impediment or something in their past
so I I just I genuinely don't believe in
good and evil people but I do believe in
like harmful and not harmful actions and
so I don't know
like I don't care I don't care yeah
she's a good person but if she
contributed to harm then she needs to be
accountable for that like that's my
position I don't know what the facts of
the matter are it seems like she was
pretty close to the situation so it
doesn't seem very believable that she
was a victim but I don't know I wish I
have met Epstein
because something tells me he would just
be a regular person a charismatic person
like anybody else and that's a very dark
reality that we don't know which Among
Us
what what each of us are hiding in the
closet
that's a really tough thing to like deal
with because then you can put your trust
into some people

[2:41:01]
into some people
and they can completely betray that
trust and in the process destroy you
yeah
which is a lot of people that interacted
with Epstein
then now have to
I mean if they're not destroyed by it
then they're they that their whole like
the ground on which they stand ethically
is is has crumbled at least in part
and you I'm sure
I'm sure you and I have interacted with
people without knowing it who are bad
people who have done bad things because
I was talking about bad guys I'm trying
to move them towards
they're just people who make bad choices
yeah that's really powerful actually
that's really important to remember
because that that means you have
compassion towards all human beings
um do you have hope for the future of
MIT a future of media lab in this
context
uh so David Newman is now at the helm

[2:42:01]
uh so David Newman is now at the helm
I'm gonna talk I talked to a priest I'll
talk to her again
she's great love her yeah she's great
I don't know if she knew
the whole situation when she started
because
the situation went beyond just the
Epstein Scandal a bunch of other stuff
happened at the same time
some of it's not public
um
but my what I was personally going
through at that time so the Epstein
thing happened I think was it August or
September
2019 it was somewhere around late summer
in June 2019
so I'm I'm a research scientist at MIT
you are too right so and I always have
had various supervisors uh you know over
the years and they've just basically let
me do what I want which has been great
but I had a supervisor at the time
and he called me into his office for
regular check-in

[2:43:00]
regular check-in
in June of 2019 I reported to MIT that
my supervisor had
grabbed me
pulled me into a hug wrapped his arms
around my waist and started massaging my
hip and trying to kiss me kiss my face
kiss me near the mouth
um and said literally the words don't
worry I'll take care of your career
um and that
that experience was really interesting
because I just
I was very indignant I was like
he can't do that to me doesn't he know
who I am and I was like this is the me
too era and I naively thought that when
I reported that it would get taken care
of and then I had to go through the
whole reporting process at MIT and I
learned a lot about how institutions
really handle those things internally
um particularly situations where I
couldn't provide evidence that it
happened I had no reason to lie about it

[2:44:01]
happened I had no reason to lie about it
but I had no evidence and so
I was going through that and that was
another experience for me where
there's so many people in the
institution
who really believe in protecting the
institution at all costs and there's
only a few people who care about doing
the right thing
and one of them
resigned and now there's even less of
them left so
so what did you learn from that
I mean where is the source if you have
hope
for this institution that I think you
love
at least in part
I I love the idea of MiG I love the idea
I love the research body I love a lot of
the faculty I love the students the
students I love the energy like I love
it all I think the administration
suffers from the same problems as
any
institutional any leadership of an
institution that is large
which is that

[2:45:02]
they've become risk-averse like you
mentioned they care about PR the only
ways to
get their attention or change their
minds about anything or to threaten the
reputation of The Institute or to have a
lot of money
that's the only way to have power at the
Institute
um
yeah I don't think they I don't think
they have a lot of Integrity or believe
in ideas or even have a lot of
connection to the research body and like
the people who are really because it's
so weird you have this amazing research
body of people pushing the boundaries of
things who aren't afraid to like there's
the hacker culture
and then you have the administration and
they're really like
protect the institution at all costs
yeah there's your disconnect right
completely I wonder if that was those
there if it just kind of slowly grows
over time a disconnect between the
administration The Faculty I think it

[2:46:00]
administration The Faculty I think it
grew over time is what I've heard
I mean I've been there for 11 years now
I don't know if it's gotten worse during
my time but
I've heard from people who've been there
longer that it didn't know like MIT
didn't used to have a general counsel's
office they didn't used to have all this
corporate stuff and then they had to
create it as they got bigger and in the
era where such things are I guess deemed
necessary see I believe in the power of
individuals to like overthrow the thing
so it's just a really good president
of MIT or certain people in the
administration can reform the whole
thing because the the culture is still
there of like
I think everybody
remembers that MIT is about the students
and the faculty do they though because
I've had a lot of conversations that
have been shocking with like senior
Administration they think the students
are children they call them kids it's

[2:47:01]
are children they call them kids it's
like these are the smartest people
they're way smarter than you yeah and
you're so dismissive but those
individuals I'm saying like the the
capacity
like the aura of the place still values
this the students and the faculty like I
I'm not I'm being awfully poetic about
it but what I mean is the administration
is the um
the froth at the top of the like the
waves the surface like they can be
removed and New Life can be brought in
that would keep to the spirit of the
place who decides on who to bring in
who's oh I see
uh I see but I I do think ultimately
especially in the era of social media
and so on
um
faculty and students have more and more
power there's more more of a voice I
suppose I hope so I really do

[2:48:00]
suppose I hope so I really do
I don't see MIT going away anytime soon
and like I also don't think it's a
terrible place at all yeah it's an
amazing place and it's a but there's
different trajectories you can take yeah
and like and that has to do with a lot
of things including
um
does it is it stays even if we talk
about robotics it could be the capital
of the world in robotics
but currently if you want to be doing
the best AI work in the world you're
going to go to Google or Facebook
um or Tesla or apple or so on you're not
going to be you're not going to be in
MIT
and so that that has to do I think
that's basically has to do with
um
not allowing the the Brilliance of the
researchers to flourish
yeah people say it's about money but I
don't think it's about that at all like
sometimes you have more freedom and can

[2:49:00]
sometimes you have more freedom and can
work on more interesting things in
companies that's what really where they
lose people yeah
and some the the freedom in all in in
all ways
which is why it's heartbreaking to get
like people like Richard stallman
there's such an interesting line because
like Christians Thomas a gigantic weirdo
that cross lines you shouldn't across
right but we don't want to draw too many
lines
this is the tricky thing there are
different types of lines in my opinion
but just your opinion because you have
strong lines you hold through but then
if Administration listens to every line
there's there's also power in drawing a
line
like and there's it becomes like a
little drug you have to find the right
balance licking somebody's arm is never
appropriate I think the biggest aspect
there is not uh owning it learning from
a growing from it from a perspective a

[2:50:00]
a growing from it from a perspective a
stallman or people like that uh back
when it happened like understanding
seeing the being empathetic seeing the
the fact that this was like totally
inappropriate uh like not when that
particular act but everything that led
up to it too no I think there are
different kinds of lines I think they're
a lot
so Stone and crossed lines that
essentially excluded a bunch of people
and created an environment where we
their Brilliant Minds that we never got
the benefit of because he made things
feel
gross or even unsafe for people there
are lines that you can cross
where you're challenging an institution
to
like I don't think he was intentionally
trying to cross a line or maybe maybe he
didn't care there are lines that you can
cross intentionally to move something
forward or to do the right thing like
when MIT was like you can't put an

[2:51:02]
when MIT was like you can't put an
all-gender restroom in the media lab
because like something permits whatever
and Joey did it anyway that's a line you
can cross to make things actually better
for people and the line you're Crossing
is some arbitrary stupid rule that
people who don't want to take the risk
or like
yeah for sure you know what I mean no
ultimately I think the thing you said is
like cross lines in a way that doesn't
uh alienate others so like for example
me weren't I started for a while wearing
a suit often at MIT which sounds
counter-intuitive but that's actually
um
I people always looked at me weird for
that MIT created this culture
specifically the people I was working
with like nobody wore a suit maybe the
business
don't trust the suits I was like fuck
you I'm wearing the suit
but that's not really hurting anybody
right exactly
um it's challenging people's perceptions

[2:52:00]
um it's challenging people's perceptions
it's doing something that you want to do
yeah but it's not hurting people and and
that that particular thing was
um yeah it's hurting people
it's a good line that's a good line to
like
hurting ultimately the people that you
want to flourish yeah
yeah you tweeted a picture of a pumpkin
spice Greek yogurt
and asked uh grounds for divorce yes no
so let me ask you what's what's the key
to a successful relationship oh my God a
good couple therapist
what uh what went wrong with the pumpkin
spice Greek yogurt what's exactly what's
wrong is it the pumpkin is it the Greek
I don't understand that tweet for a
while I grew up in Europe so I don't
understand the pumpkin spice in
everything craze that they do every
Autumn here like I understand that it
might be good in some foods but they
just put it in everything

[2:53:00]
just put it in everything
and it doesn't belong in Greek yogurt
I mean I was just being humorous I ate
one of those yogurts and I actually
tasted pretty good so
I think part of the success of a good
marriage is like
giving each other a hard time humorously
for things like that
is there a broader lesson because you
guys seem to have a really great
marriage from the external I mean every
marriage looks good from the external
every I think yeah
that's that's not true but yeah okay
relationships
have hard relationships with anyone are
hard
actually because people evolve and
change and you have to make sure there's
space for both people to evolve and
change together and I think one of the
things
that I really liked about are marriage
vows was
I remember before we got married Greg at
some point like got kind of nervous and

[2:54:01]
some point like got kind of nervous and
he was like it's just it's such a big
commitment to commit like to something
for life and I was like we're not
committing to this for life and he was
like we're not and I'm like no like
we're committing to being part of a team
and doing what's best for the team
what's best for the team is to break up
we'll break up like
I don't believe in this like we have to
do this for our whole lives
and that really resonated with him too
so
yeah did you put in the well yeah those
are vows like that we're just we're
gonna be a team you're a team and do
what's right for the team yeah yeah
that's very like Michael Jordan view uh
uh do you guys get like married in the
in the desert like November Rain Style
with Slash playing or
you don't have to answer that I'm not
good at these questions okay you've
brought up marriage like eight times are
you trying to hint something on the

[2:55:00]
you trying to hint something on the
podcast
you have an announcement to make no what
I don't know it just seems like a good
metaphor
for why why why what it felt like a good
metaphor for in a bunch of cases
for the uh marriage industrial complex I
remember that um and oh people
complaining it just seemed like marriage
is one of the things that always
surprises me because I want to get
married you do yeah I do and then I I
listen to like friends of mine that
complain not all I like I like guys I
really like guys that don't complain
about their marriage it's such a cheap
like if it's such a cheap release valve
like it doesn't that's bitching about
anything honestly that's just like it's
too easy but especially like bitch about
the sports team or the weather if you
want but like about somebody that you're
dedicating your life to like if you
bitch about them

[2:56:00]
bitch about them
you're going to see them as a lesser
being also like you don't think so but
you're going to like decrease the value
you have I I personally believe over
time you're not going to appreciate the
magic of that person
I think anyway but it's like that I just
noticed this a lot that people are
married
and they will whine about you know like
the wife uh whatever you know this this
cut is part of the sort of the culture
to kind of uh comment in that way I
think women do the same thing about the
husband uh he doesn't he never does this
or he's a goof he's incompetent at this
or that whatever they there's a kind of
yeah there's those tropes like oh you
know husbands never do X and like wives
or I know I think those do a disservice
to everyone is just disrespectful to
everyone involved yeah but it happens so
yeah I was and brought that up as an
example of something that people
actually love but they complain about
because for some reason that's more fun

[2:57:00]
because for some reason that's more fun
to do is complain about stuff yeah and
so that's what with clippy or whatever
right so like you complain about but you
actually love it there you go it's just
a good metaphor that you know
um
what was I going to ask you uh oh you uh
your hamster died
when I was like eight you miss her
beige um
what's the closest relationship you've
had with a pet
not the one
what we didn't have a lot of robot have
you loved the most in your life
I think my my first pet was a goldfish
named Bob
and he died immediately and that was
really sad
[Laughter]
I think I think it was really attached
to Bob and Nancy my goldfish we got new
Bobs and then Bob kept dying and we got
new bulbs Nancy just kept living

[2:58:02]
so it was very replaceable
yeah I was young
it was easy
do you think there will be a time when
the robot like in the movie Her be
something we fall in love with
romantically
oh yeah oh for sure yeah at scale like
we're a lot of people
romantically I don't know if it's gonna
happen at scale I think
we talked about this a little bit last
time on the podcast too where I think
we're just capable of so many different
kinds of relationships and actually part
of why I think marriage is so tough as a
relationship is because we put so many
expectations on it like your partner has
to be your best friend and you have to
be sexually attracted to them and they
have to be a good co-parent and a good
roommate and like
all the relationships at once that have
to work
but we're like normally with other
people we have like one type of

[2:59:00]
people we have like one type of
relationship but we even have we have a
different relationship to our dog than
we do to our neighbor than we do to the
you know person out someone a co-worker
I think that some people are gonna find
romantic relationships with robots
interesting
it might even be a widespread thing but
I don't think it's gonna replace like
human romantic relationships I think
it's just gonna be a separate type of
thing
it's gonna be more narrow
more narrow or even like just something
new that we haven't really experienced
before maybe like having a crush on an
artificial agent is a different type of
Fascination I don't know people would
see that as cheating
I think people well
I mean
the things that people feel threatened
by in relationships are very manifold so
yeah that's just an interesting one
because uh
maybe gel maybe it'll be good A little
jealousy for the relationship maybe

[3:00:00]
jealousy for the relationship maybe
they'll be like part of the couple's
therapy you know kind of thing or
whatever
think jealousy I mean I think
it's hard to avoid jealousy but I think
the objective is probably to avoid I
mean some people don't even get jealous
when their partner sleeps with someone
else like there's polyamory and
um
yeah I think there's just such a
diversity of different ways that we can
structure relationships or view them
that this is just going to be another
one that we add
you dedicate your book to your dad what
did you learn about life from your dad
oh man my dad
is
he's a great listener and he is the best
person I know at
um the type of cognitive empathy that
like perspective taking
so not like emotional like crying
empathy but
trying to see someone else's point of

[3:01:01]
trying to see someone else's point of
view and trying to put yourself in their
shoes and he really
instilled that in me from an early age
and then he made me read a ton of
Science Fiction which
probably led me down this path uh taught
you how to be curious about the world
and how to be open-minded yeah
last question what role does Love play
in The Human Condition so this one been
talking about love and robots
How uh and you're fascinated by social
robotics
it feels like all of that operates in
the landscape of something that we can
call love love yeah I think there are a
lot of different kinds of love I feel
like it's
we need
I'm like don't the eskimos have all
these different words for snow we need
we need more words for to describe
different types and kinds of love that
we experience but I think love is so
important and I also think it's not
zero-sum that's the that's the really

[3:02:01]
zero-sum that's the that's the really
interesting thing about love is that
you know I had one kid and I love loved
my first kid more than anything else in
the world and I was like how can I have
a second kid and then love that kid also
I'm never gonna love it as much as the
first but I love them both equally it's
just like my heart expanded and so I
think that people who are threatened by
love towards artificial agents
they don't need to be threatened for
that reason
artificial agents will just if Done
Right will just expand
your capacity for love I think so
I agree beautifully put okay this is
awesome I still didn't talk about half
the things I want to talk about but
we're already like way over three hours
so thank you so much I really appreciate
you talking today you're awesome you're
an amazing human being a great
roboticist great writer now it's an
honor that you would talk with me thanks
for doing it right back at you thank you

[3:03:00]
for doing it right back at you thank you
thanks for listening to this
conversation with Kate Dowling to
support this podcast please check out
our sponsors in the description
and now let me leave you with some words
for Maya Angelou
courage is the most important of all the
virtues because without courage you
can't practice any other virtue
consistently
thank you for listening and hope to see
you next time