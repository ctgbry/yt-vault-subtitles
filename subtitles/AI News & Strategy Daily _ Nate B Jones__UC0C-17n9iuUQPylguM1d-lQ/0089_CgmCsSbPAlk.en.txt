[00:00]
you know one of the biggest debates
right now is the value of synthetic data
or data that's generated by artificial
intelligence I saw a really interesting
application for that in election result
prediction this is from a paper that was
published out of Wuhan uh Wuhan
University in November specifically
November 3rd so before the election and
what they did was the researchers
generated a bunch of synthetic data that
was demographically tuned to particular
States de graphic makeup and that was
weighted by the state's voting history
and then they generated a bunch of
synthetic data off of the tuned uh
Baseline knowledge base that they fed to
chat
gp40 and so they would do things like
say okay you are a 35-year-old white
woman in
Vermont who are you voting for in this
presidential election and then they
would see what synthetic data was
generated by chat
gp40 based on what the model could read

[01:02]
gp40 based on what the model could read
of the state's voting preferences Broken
Out by demographics and you might think
well that's super reductive how
informative is it they were able to
correctly forecast Trump's victory in
the Electoral College they got within
depending on their exact approach within
about uh 5 to 10 Electoral College votes
so about one state off so it was
surprisingly accurate actually I was I
was a little bit shocked I wasn't
expecting it to be that useful and I
think that as we continue to run into a
world where traditional polling has more
and more questions around it because
people don't answer their phones all the
time internet polling has a lot of other
issues we may see in future electoral
Cycles more and more focus on how
synthetic data that is tuned can help us
get more reliable estimates of what's
going on so I actually thought about
like how would I replicate this you have

[02:00]
like how would I replicate this you have
to get a large data set you have to get
the cross tabs broken out uh across
multiple electoral Cycles across all 50
states in the US so that you understand
how different demographics have changed
their votes over time on average and
then you're going to have to in a very
clear and structured way prepare chat
GPT 40 with that data so you can ask it
questions and start to generate
synthetic data it's not a light
undertaking but I would think after sort
of seeing their General approach that we
will see a lot of follow-up papers that
seek to take this and fine-tune it for
example this didn't include inflation or
economic data as far as I can see and
yet everyone who was leaving the polls
or talking about the election like
inflation was a major topic and so I
would expect that we will start to see
more sophisticated use of the context
window to set up these chat Bots to
generate this synthetic data and I would
guess that that would make synthetic

[03:00]
guess that that would make synthetic
data even more predictive but to be
honest getting within five or 10
electoral votes on a very crude sort of
demographic basis is pretty good so we
will see what happens but I thought I
would share that approach I think it's
an interesting example of how synthetic
data can be valuable and even predictive
in certain situations I'll put the paper
in the link underneath