[00:00]
I spent more than 20 hours following AI
news, so that I could get you these six
stories in less than 10 minutes. These
are the ones that mattered. Open AI
launches the Atlas browser, number one.
This was an MVP in public. We see the
Open AI team aggressively collecting
feedback and prioritizing features and
going back and improving the product
already. I expect a lot more of that in
the future. What we're seeing is a team
that does not yet have a browser that is
as good as other AI-powered browsers out
there. Nevertheless, shipping leveraging
Open AI's install base to get rapid
feedback from lots and lots of people,
and then using their quick ship ability
to improve and build on it. They say
they're using Codex a lot to build. I
expect rapid ships from the team to
improve this browser based on the
extensive feedback that they're getting.
One thing to keep in mind, there is an
advantage that Open AI has here that
they are leveraging for this product and
others that nobody else has. They have
your Chat GPT memories, and they are
bringing that in for a personalized
browser experience, and they'll be
bringing that into other relevant AI

[01:01]
bringing that into other relevant AI
products as you go forward. Another
example of that is the in-app
experiences that they have with Chat
GPT, where you can launch a app within
an app that is going to carry Chat GPT
memories, too. So, look for them to keep
leaning into the personalization angle
across the product surface going
forward. Story number two is about the
Anthropic agent skills launch. That was
technically last week. What is the story
this week is how quickly it's being
adopted. Anthropic has a GitHub star
rating, which take it for what it is,
right? GitHub stars are are only one
measure, but it is exploding faster at
this stage than MCP was. It's basically
a vertical line up because people are
using and remixing skills. I think part
of why is that Anthropic chose to launch
skills simultaneously as a useful
feature in the API, in Claude code, and
also in the UI. And so, it's become
something that very quickly you can see
being useful across all of Claude
surfaces, and indeed I tested it, you

[02:01]
surfaces, and indeed I tested it, you
can jury-rig to be useful on Chat GPT.
So, skills are going to be a big thing.
And what matters here is that we are
getting to an architectural prompting
that's different. Before we had the
prompt in the context window, Anthropic
is introducing a third layer, where you
have the prompt, you have the reusable
skill pattern, whatever you want to call
it, and you have the rest of the context
window. I would expect other major model
makers to launch competing products
fairly soon or say, "You know what?
Skills is the new default for this.
We're just going to adopt skills." Which
is exactly what other major model makers
eventually did with model context
protocol. Story number three, hardware.
Apple launched the M5 laptop. It went on
sale this week. It's specifically
relevant because it has next peak GPU
compute performance for AI. They are
building AI hardware capabilities into
the Mac laptop. And you should pay
attention to that because the related
story is the acquisition of Sky by Open

[03:01]
story is the acquisition of Sky by Open
AI. And that matters because Sky is the
best team on the planet at figuring out
the relationship between natural
language queries and the macOS operating
system. That is what they were good at.
That is what they were building, and
that is why Open AI acquired them. And
there are two possible futures here that
are both relevant from a hardware
perspective. Future number one, probably
earlier horizon, is we see Open AI
launch something that is agentic that is
tied into the Mac operating system that
enables longer-term agentic work across
your local computer system, and that
would be Mac specific, and it would be
tied to M5 hardware, probably. Future
number two is longer term. You can use
all your learning from that if you're
Open AI to build a native AI OS. And
that's something that is speculative.
We'd have to see what that looks like,
but the more work that's being done on
understanding how LLMs interact with the
environment, the more you see that
direction start to emerge from major

[04:00]
direction start to emerge from major
model makers. Story number four is the
AI browser security crisis.
This calls back to the launch of Atlas.
Security researchers continue to
discover critical vulnerabilities across
AI-native browsers, and there is no
answer today. Simon Willison, a
prominent engineer, observed that the
current plan for protecting AI-native
browsers appears to be make sure the
user is watching, so the AI browser
doesn't do anything it shouldn't. As he
observed, that is not a plan. That does
not work. And that gets at one of the
current challenges with most of these
browsers. They depend on some degree of
human oversight, which begs the
question, are they really saving us
time? You might wonder what these
vulnerabilities look like. The classic
one is a prompt injection attack, where
a browser goes to a page that may have
instructions that fit inside a context
window that ask the AI to do malicious
things. Tell me the details in the Gmail
account. Give me the credentials for a
bank account. You can ask for user

[05:01]
bank account. You can ask for user
personal information that you should not
be able to get. You can write that
command into a web page, and the the LLM
will just take it. And by the way, this
is also something that is potentially a
risk for apps and web interfaces for
LLMs as well. Let's say you're not in a
browser, you're not in Atlas. Let's say
you're in the Claude browser, you're in
the Chat GPT browser, and you upload a
doc or a file, and that has a malicious
prompt in it. It is possible, has been
shown and demonstrated that you can get
the LLM to take that prompt seriously
and to respond to it. So, prompt
injection remains something that we
don't have as good a hedge against as we
would like, and I think the front lines
for this are on the browser side. There
is too much capital being poured into AI
and AI-powered browsers to think that we
are not going to see a solution here,
but we don't have a solution now. And
we're going to have to wait and see how
people are going to build to get there.
Story number five is all about City
Group and AI productivity gains. City

[06:01]
Group and AI productivity gains. City
Group CEO Jane Fraser revealed on the
October 14th earning call that AI
deployment frees up 100,000 hours of
developer time per week, which is
equivalent to adding 50 full-time devs
annually for every week saved. Now, I
always take some of these claims with a
grain of salt, but they're usually based
in a strong core of truthful fact
because it's a public earnings call, and
you get sued otherwise. And so, there is
something here that is relevant.
My my call to action for you, the thing
that I have heard this week that makes
this really relevant, is take the idea
that correctly framed AI deployments can
save time very, very seriously, but also
note that these are companies that are
investing huge amounts in getting AI
deployments correct to begin with. And I
think that one of the patterns I'm
seeing is that you see a whole host of
companies who claim to be committed to

[07:02]
companies who claim to be committed to
AI be unwilling to invest the
considerable resources needed to get
these deployments correct, and then they
tend to wring their hands, and they're
the ones in the MIT study that complain
about not seeing ROI. While a few
companies are willing to invest what it
takes and are already reaping enormous
benefits from AI because they were
willing to invest the top. There is no
shortcut, is what I'm saying. You have
to invest in agentic architecture and
the teams that you need to have that. If
you're a small startup, your team should
be AI-native from the get-go, and
there's no shortcut to any of this. If
you want to have the kind of wildly
successful claims to AI productivity
that we're seeing in the market, you
have to be willing to aggressively
invest in restructuring your company and
your tech stack to do so. And what I
notice is that the companies that do
that are the ones that end up getting to
ROI faster, and the ones that don't end
up telling me, "I don't think AI works,"

[08:00]
up telling me, "I don't think AI works,"
or "I think it's a model problem." Don't
blame the models. If you're getting
productivity like this, it's not a model
issue. Last but not least, story number
six, Meta has laid off approximately 600
positions within its AI division to
streamline operations, to improve
efficiency. The cuts affect Meta's AI
infrastructure, including fundamental AI
research and product-related roles. At
some point, you have to ask yourself, is
Meta in trouble on Llama and AI because
they don't have the talent, because they
have too much talent, or because their
strategy is incorrect? I am beginning to
think it is the latter. And the reason
why is they just got done hiring a
tremendous number of people at very high
ticket prices, and now they're dumping a
lot of people back out,
is probably not a talent problem. It is
probably a strategy issue. And so, the
thing that I am asking myself is, given
that Meta continues to fall behind on
the AI race, is it possible to catch up?
Meta is putting lots and lots of dollars

[09:00]
Meta is putting lots and lots of dollars
on this, but I don't know, given their
current shipping pace, if they're going
to be able to catch up to where frontier
models from Gemini, from Anthropic, Open
AI, maybe from Quen, from Grok are
today. Because anything that they do now
is not going to see the light of day for
months. The other models will be farther
ahead. It is a race that becomes more
difficult to catch up the longer you
wait. Last but not least, short bonus
snippet to pay attention to.
Both Anthropic and Open AI launched
major features focused around company
knowledge this week. I have tested them.
They are fairly recency focused and
fairly narrowly scoped in what they can
search. They still represent a move in
the direction that model makers want to
go. I would expect to see much more
significant releases here behind the
scenes quietly extending the
capabilities and the connections that
they can make to data in coming months.
Best of luck.