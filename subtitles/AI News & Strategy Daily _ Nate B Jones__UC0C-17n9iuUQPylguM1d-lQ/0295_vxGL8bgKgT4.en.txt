[00:00]
One, guardrails are layers. They're not
switches. You cannot toggle safety on
and off with prompt changes. You need a
lot of different layers of defense, and
you need to be thoughtful about how you
have the effect of all of those layers
together on the artificial intelligence
system. So filtering and retrieval,
constraints and prompts, RLHF training,
output filtering, maybe human review.
All of those are layers and you need to
be intentional about using them as part
of a defensive structure to keep the AI
building trust for your customers, which
supports long-term enterprise value and
ultimately helps your customers get what
they want out of the system. Second, rag
amplifies platform risk. If you're
building retrieval systems, you're
importing all the problems in your data
sources. You have to filter before
retrieval hits the